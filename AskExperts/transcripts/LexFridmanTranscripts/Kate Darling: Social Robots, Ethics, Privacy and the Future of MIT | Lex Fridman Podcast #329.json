[
    {
        "text": "I think that animals are a really great thought experiment when we're thinking about Ai and Robotics because again this comparing them to humans that leads us down the wrong path both because it's not accurate but also I think for the future we don't want that we want something that's a supplement but I think animals because we've used them throughout history for so many different things we we domesticated them not because they do what we do but because what they do is different and that's useful and I it's just like whether we're talking about companionship whether we're talking about work integration whether we're talking about responsibility for harm there's just so many things we can draw on in that history from these entities that can sense think make autonomous decisions and learn that are applicable to how we should be thinking about robots and AI the following is a conversation with Kate darling her second time on the podcast she's a research scientist at MIT media lab interested in human robot interaction and robot ethics which she writes about in her recent book called The New Breed what our history with animals reveals about our future with robots Kate is one of my favorite people at MIT she was a courageous voice of reason and compassion through the time of the Jeffrey Epstein scandal at MIT three years ago we reflect on this time in this very conversation including the lessons that revealed about human nature and our optimistic vision for the future of MIT a university we both love and believe in this is the Lux freedom of podcast to support it please check out our sponsors in the description and now dear friends here's Kate darling last time we talked a few years back you wore Justin Bieber shirt for the podcast so now looking back you're respected um researcher all the amazing",
        "start": "00:00:00",
        "duration": 230.922,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "accomplishments in robotics uh you're an author was this one of the proudest moments of your life uh proudest decisions you've ever made definitely you handled it really well though it was cool because I walked in I didn't know you were going to be filming I walked in and you're in a [ __ ] suit yeah and I'm like why are you all dressed up yeah and then you were so nice about it you like made some excuse you're like oh well I'm interviewing some art didn't you say you were interviewing some military General afterwards to like oh yeah those makes me feel better CTO of Lockheed Martin I think yeah you didn't tell me oh I was dressed like this are you an actual Bieber fan or was that like one of those t-shirts that's in the back of the closet that you use for painting I think I bought it for my husband as a joke and yeah I was we were gut renovating a house at the time and I had worn it to the site I got his joke and now you wear it okay have you worn it since one time no like how could I touch it again it was on your podcast that's frames it's like a wedding dress or something like that you don't you only wear it once you are the author of The New Breed what our history with animals reveals about our future with robots you open the book with the surprisingly tricky question what is a robot so let me ask you let's try to sneak up to this question what's a robot that's not really sneaking up it's just asking it yeah all right well what do you think a robot is what I think a robot is is something that has some level of intelligence and some level of magic that little shine in the eye you know that allows you to navigate the uncertainty of uh of life so that means like autonomous vehicles to me in that sense uh are robots because they navigate",
        "start": "00:01:56",
        "duration": 239.94099999999995,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "uh the uncertainty the complexity of life obviously social robots are that I love that I like that you mentioned magic because that also well so first of all I don't Define robot definitively in the book because there is no definitely that everyone agrees on and if you look back through time people have called things robots until they lose the magic because they're more ubiquitous like a vending machine used to be called a robot and now it's not right so I do agree with you that there's this magic aspect that that which is how people understand robots if you ask a roboticist they have the definition of something that is well it has to be physical usually it's not an AI agent it has to be embodied um they'll say it has to be able to sense this environment in some way it has to be able to make a decision autonomously and then act on its environment again I think that's a pretty good technical definition even though it really breaks down when you come to things like the smartphone because the smartphone can do all of those things and most robotics would not call it a robot so there's really no no one good definition but part of why I wrote the book is because people have a definition of robot in their minds that is usually very focused on a comparison of robots to humans so if you Google image search robot you get a bunch of humanoid robots robots with that torso and head and two arms and two legs and that's the definition of robot that I'm trying to get us away from because I think that it trips us up a lot why does the humanoid form trip us up a lot well because this constant comparison of robots to people artificial intelligence",
        "start": "00:03:57",
        "duration": 217.13900000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "to human intelligence first of all it doesn't make sense from a technical perspective because you know the early AI researchers some of them were trying to recreate human intelligence some people still are and there's a lot to be learned from that academically Etc but um that's not where We've Ended up AI doesn't think like people we wind up in this fallacy where we're where we're comparing these two um and we're when we talk about what intelligence even is we're often comparing to our own intelligence and then the second reason this bothers me is because it doesn't make sense I I just think it's boring to recreate intelligence that we already have I see the scientific value of understanding our own intelligence but from a like practical what can we use these Technologies for perspective it's much more interesting to create something new to create a skill set that we don't have that we can partner with and what we're trying to achieve and it should be in some deep way similar to us but in most ways different because you still want to have a connection which is why the similarity might be necessary that's what people argue yes and I think that's true so the two arguments for humanoid robots are people need to be able to communicate and relate to robots and we relate most to things that are like ourselves and we have a world that's built for humans so we have stairs and narrow passageways and door handles and so we need humanoid robots to be able to navigate that and so you're speaking to the first one which is absolutely true but what we know from social Robotics and a lot of human robot interaction research is that you all you need is something that's enough like a person to for it to give off cues that someone relates to and that but that",
        "start": "00:05:45",
        "duration": 222.30100000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "doesn't have to look human or even act human you can take a robot like R2D2 and it just like beeps and boops and people love R2D2 right even though it's just like a trash can on Wheels and they like r2dging more than C-3PO who's a humanoid so there's lots of there's lots of ways to make robots even better than humans in some ways and make us relate more to them yeah it's kind of amazing the variety of cues that can be used to anthropomorphize the thing like a glowing orb or something like that yeah just just a voice just uh just subtle basic interaction I think people sometimes over engineer these things like Simplicity can go a really long way totally I mean ask any animator and they'll know that yeah yeah those are actually so the people behind Cosmo the um the the robot the right people to design those as animators like Disney type of people yeah versus like roboticists robotics is quote unquote are mostly Clueless they just have their own discipline that they're very good at and they didn't don't have yeah but that that don't don't you know I feel like robotics of the early 21st century is not going to be the robotics of the later 21st century I don't know like if you call yourself a roboticist it'll be something very different because I I think more and more you'd be like a maybe like a control engineer or something controls engineer like uh you separate because ultimately all the unsolved all the big problems of Robotics will be in the social aspect in the interacting with humans aspect in the uh perception interpreting the world aspect in the brain part not the not the not the basic control level part you call it basic it's actually right like it's very very complicated",
        "start": "00:07:36",
        "duration": 249.24000000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "and that's why but like I think you're so right and and and what a time to be alive because for me I just we've had robots for so long and they've just been behind the scenes and now finally robots are getting deployed into the world they're coming out of the closet yeah and and we're seeing all these mistakes that companies are making because they focus so much on the engineering and getting that right and getting the robot to be even be able to function in a space that it shares with a human see what I feel like people don't understand is to solve the perception and the control problem you shouldn't try to just solve the perception control problem you should teach the robot how to say oh [ __ ] I'm sorry I [ __ ] up yeah or ask for help oh for ask for help or be able to communicate the uncertainty yeah exactly all of those things because you can't solve the perception control we humans haven't solved it we were really damn good at it uh but the the magic is in the the self-deprecating humor and the self-awareness about where our flaws are all that kind of stuff yeah and there's a whole body of research in human robot interaction showing like ways to do this but a lot of these companies haven't they don't do HRI they like the have you seen the grocery store robot in the Stop and Shop yes yeah the Marty it looks like a giant penis it's like six feet tall it roams the aisles I will never see marketing the same way again thank you you're welcome but like they they these poor people were so hard on getting a functional robot together and then people hate Marty because they didn't at all consider how people would react to Marty in their space does everybody I",
        "start": "00:09:41",
        "duration": 220.01999999999995,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "mean you talk about this do do people mostly hate Marty because I I like I like Mario yeah and actually like there's a there's a parallel between the two I believe there is so we were actually going to do a study on this right before the pandemic hit and then we canceled it because we didn't want to go to the grocery store and neither did anyone else um but our Theory so this was with a student at MIT Daniella de Paola she noticed that everyone on Facebook in her circles was complaining about Marty they're like what is this creepy robot is watching me it's always in the way and she did this like quick and dirty sentiment analysis on Twitter where she was looking at positive and negative mentions of the robot and she found that the biggest Spike of negative mentions happened um when Stop and Shop threw a birthday party for the Marty robots like with free cake and balloons like who complains about free cake well people who hate Marty apparently so and so we were like that's interesting and then we did this like online poll we used Mechanical Turk and we tried to get at what people don't like about Marty and a lot of it wasn't oh Marty's taking jobs it was Marty is the surveillance robot which is not it looks for spills on the floor it doesn't actually like look at any people um it's it's watching as creepy as getting in the way those are the things that people complained about and so our hypothesis became is Marty a real life clippy because I know Lex you love clippy but many people hated clippy well there's a complex thing there it could be like marriage a lot of people seem to like to complain about marriage but they secretly love it so it could be the relationship you might have with uh with Marty is like oh there he goes again doing his stupid",
        "start": "00:11:31",
        "duration": 223.69799999999998,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "surveillance thing but you can grow to love the um I mean bitching about the thing that kind of releases a kind of tension and there's I mean some people a lot of people show Love by sort of uh busting each other's jobs you know like making fun of each other and then if I think I think people would really love it if Marty talked back and and like well these are so many possible options for humor there one you can lean in you can be like yes I'm an agent of the CIA monitoring your every move like mocking people that are concerned you know saying like yes I I'm watching you because you're so important with your shopping patterns I'm collecting all this data um or or just you know any kind of making fun of people I don't know but I think you hit on what exactly it is because when it comes to robots or artificial agents I think people hate them more than they would some other machine or device or object and it might and it might be that thing it might be combined with love or like whatever it is it's a more extreme response because they view these things as social Asians and not objects and that was um so Clifford nass was a big human computer interaction person and he his theory about Clippy was that because people viewed clippy as a social agent when clippy was annoying and would like bother them and interrupt them and like not remember what they told him that's when people got upset because it wasn't fulfilling their social expectations and so they complained about Clippy more than they would have if it had been a diff like not an not a you know virtual character so is complaining to you a sign that we're on the wrong path with a particular robot or is it possible like again like marriage like family that there still is a path",
        "start": "00:13:25",
        "duration": 246.54199999999992,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "towards that direction where we can find deep meaningful relationship I think we absolutely can meaningful relationships with more robots and well maybe with Marty I mean I just would I would have designed Marty a little differently but oh isn't there a charm to the clumsiness the slowness there is if you're not trying to get through the shopping cart and screaming child you know there's I think I think you could make it Charming I think there are lots of design tricks that they could have used and one of the things they did I think without thinking about it at all is they slapped too big googly eyes on Marty oh yeah and I I wonder if that contributed maybe to people feeling watched um because because it's looking at them and so like is there a way to design the robot to do the function that it's doing in a way that does that people are actually attracted to rather than annoyed by and there are many ways to do that but companies aren't thinking about it now they're realizing that they should have thought about it yeah I wonder if there's a way to if it would help to make Marty seem like an entity of its own versus uh the arm of a large corporation so there's some sense where this is just the camera that's monitoring people versus this is an entity that's a standalone entity it has its own task and it has its own personality the more personality you give it the more it feels like it's not sharing data with anybody else like when we see other human beings our basic assumption is whatever I say to this human being it's not like being immediately sent to the CIA yeah what I say to you no one's gonna hear that right yeah that's true that's true well",
        "start": "00:15:28",
        "duration": 226.8,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "you forget it I mean you do forget it I mean I don't know if that even with microphones here you forget that that's happening but there for some reason I think probably with Marty um I think when it's done really crudely and crappily you start to realize oh this is like PR people trying to make a friendly version of a surveillance machine but um I mean that reminds me of the slight clumsiness or significant clumsiness on the initial releases of the avatars for the metaverse I don't know what what do you what are your actually thoughts about that the the way uh the avatars the way like Mark Zuckerberg looks in that world you know the the the the meta verse the virtual reality world where you can have like virtual meetings and stuff like that like how do we get that right do you have thoughts about that because that's the kind of uh it's a is it feels like a similar problem to social robotics which is how you design a digital virtual world that is compelling when you connect others there in the same way that physical connection is right I haven't looked into I mean I've seen people joking about it on Twitter and like posting like that whatever yeah but I mean have you seen it because it there's something you can't quite put into words uh that um doesn't feel genuine yeah about the way it looks and so the question is if you and I were to meet virtually what should the avatars look like for us to have a similar kind of connection should it be a really simplified should it be a little bit more realistic should it be cartoonish should it be more um better capturing of Expressions uh in",
        "start": "00:17:22",
        "duration": 231.458,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "interesting complex ways versus like cartoonish oversimplified ways but haven't video games figured this out I'm not a gamer so I don't have any examples but I feel like there's this whole world in video games where they've thought about all of this and depending on the game they have different like avatars and a lot of the games are about connecting with others I just the thing that I don't know is and again I haven't looked into this at all um I've been like shockingly not very interested in the metaverse but they must have poured so much investment into this um meta and like why why is it so why are people why is it so bad like well there's gonna be a reason there's got to be some thinking behind it right well I talked to Carmack about this uh John Carmack who's a part-time um Oculus CTO I think uh there's several things to say one is as you probably know that I mean there's bureaucracy there's large corporations and they often large corporations have a way of killing the ND kind of artistic flame that's required to create something really compelling somehow they make everything boring because they they run through this whole process through the PR department through all that kind of stuff and it somehow becomes generic to that process because you strip out anything interesting because it could be controversial is that or yeah right exactly like um like what I mean we're living through this now like with the with a lot of people with cancellations all those kinds of stuff people are nervous and nervousness results in like the like usual the [ __ ] are ruining everything but you know the magic of human connection is taking risks of making a risky joke of of of like with",
        "start": "00:19:20",
        "duration": 236.33799999999997,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "people you like who are not [ __ ] good people like some of the fun some of the fun in the metaverse OR in video games is you know being edgier being interesting revealing your personality in interesting ways um in the sexual tension or in uh they're definitely paranoid about that oh yeah like in metaverse the possibility of sexual assault and sexual harassment and all that kind of stuff it's it's obviously very high but they're uh so you should be paranoid to some degree but not too much because then you remove completely person the personality of the whole thing then everybody's just like a vanilla bot but uh like you have to have ability um to be a little bit political to be a little bit edgy all that kind of stuff and large companies tend to suffocate that so I but in general if you get all that just the ability to come up really cool beautiful ideas if you look at uh I think Grimes tweeted about this she's very critical about the metaverse is that um you know the uh independent uh game designers have solved this problem of how to create something beautiful and interesting and compelling they they do a really good job so you have to let those kinds of Minds the small groups of people design things and let them run with it let them run wild and do edgy stuff yeah but otherwise you because you get this kind of you get a clippy type of situation right which is like a very generic looking thing um but even clippy has some like that's kind of wild that you would take a a paper clip and put eyes on it and suddenly people are like oh you're annoying but you're definitely a social agent and I just feel like that wouldn't even that clippy thing wouldn't even survive Microsoft",
        "start": "00:21:18",
        "duration": 243.84099999999998,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "or Facebook of today matter of today because it would be like what there'll be these meetings about why is it for people like why don't we it's not sufficiently friendly let's make it uh you know and then all of a sudden the artist that with whom it originated is killed and it's all PR marketing people and all that kind of stuff no they do important work to some degree but they kill the creativity I think the killing of the creativity is in the whole like Okay so some social robotics is like obviously if you create agents that okay so take for an example you'd create a robot that looks like a humanoid and it's you know Sophia or whatever now suddenly you do have all of these issues where are you reinforcing an unrealistic Beauty standard are you objectifying women uh why is the robot white so you have but the thing is I think that with creativity you can find a solution that's even better where you're not even harming anyone and you're creating a robot that looks like not not humanoid but like something that people relate to even more and now you don't even have any of these bias issues that you're creating and so how do we create that within companies because I don't think it's really about like I because I you know maybe we disagree on that I don't think that edginess or humor or interesting things need to be things that harm or hurt people or that people are against there are ways to find things that everyone is fine with why aren't we doing that the problem is there's departments that look for harm and things yeah and so they will find harm in things that have no harm okay that's the big problem because their whole job is to find harm in things so what you said is completely correct which is edginess should not hurt doesn't necessarily doesn't need to be a",
        "start": "00:23:19",
        "duration": 245.28099999999995,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "thing that hurts people it obviously great humor great uh personality doesn't have to uh like clippy but yeah I mean it but it's tricky to get right and I'm not exactly sure I don't know I don't know why a large corporation with a lot of funding can't get this right I do think you're right that there's a lot of aversion to risk and so if you get lawyers involved or people whose job it is like you say to mitigate risk they're just going to say no to most things that could even be in some way yeah yeah you get the problem in all organizations so I think that you're right that that is a problem I think what's the way to solve that in large organizations is to have Steve Jobs types of characters unfortunately you do need to have I think um from a designer or maybe like a Johnny Ive that is almost like a dictator yeah you want a benevolent dictator yeah who rolls in and says like the cuts through the lawyers the PR but has a benevolent aspect like yeah this is a good heart and make sure like I think all great artists and designers create stuff that doesn't hurt people like if you have a good heart you're going to create something that's going to actually um make a lot of people feel good that's what like people like Johnny Ive what they love doing is creating a thing that brings a lot of love to the world they imagine like millions of people using the thing and it instills them with with joy that's that you could say that by social robotics you could say that about the metaverse it shouldn't be done by the pr people should be done by this time I agree PR people ruin everything yeah all the fun uh in the uh in the book you have a picture this I just have a lot of ridiculous questions you have a picture of two Hospital delivery robots with a caption that reads by the way see your book I appreciate that it keeps the",
        "start": "00:25:22",
        "duration": 236.44100000000003,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "humor in you didn't run it by the PR department no no one edited the book got rushed through uh the thing the caption reads two hospitals delivery robots whose sexy nurse names Roxy and Lola made me roll my eyes so hard they almost fell out um what aspect of it made you roll your eyes is it the naming it was the naming the form factor is fine it's like a little box on Wheels the fact that they named them also great that'll let people enjoy interacting with them we know that even just giving a robot a name people will uh it facilitates technology adoption people will be like oh you know Betsy made a mistake let's help her out instead of this stupid robot doesn't work but why lowly and Lola and Roxy like those are too too sexy I mean there's research showing that a lot of robots are named according to gender biases about the function that they're fulfilling so you know robots that are helpful in assistance and are like nurses are usually female gendered robots that are you know powerful all wise computers like Watson usually have like a booming male uh coded voice and name so like why like that's one of those things right you're opening a can of worms for no reason for no reason you can avoid this whole camera yeah just give it a different name like why Roxy it's because people aren't even thinking so to some extent I don't I don't like PR departments but getting some feedback on your work from a diverse set of participants listening and taking in things that help you identify your own blind spots and then you can always make your good leadership choices and good like you can still ignore things that you don't believe are an issue but having the openness to take in feedback and making sure that you're getting the right feedback from the right people I think that's really important so don't unnecessarily propagate the biases of",
        "start": "00:27:22",
        "duration": 259.97799999999995,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "society yeah why in the design but uh if you're not careful though when you when you do the research of like you might if you ran a poll with a lot of people of all the possible names these robots have they might come up with Roxy and Lola as as as names they um it would enjoy most like that could come up as uh as the highest as in you do marketing research and then well that's what they did with Alexa they did marketing research and nobody wanted the male voice everyone wanted it to be female what do you what do you think about that like what I mean if I if I were to say I think the role of a great designer again to go back to Johnny Ive is to throw out the marketing research like take it in do it learn from it but like if everyone wants Alexa to be a female voice the role of the designers to think deeply about the future of social agents in the home and think like what does that future look like and try to reverse engineer that future so like in some sense there's this weird tension like you want to listen to a lot of people but at the same time you want to you're creating a thing that defines the future of the world and the people that you're listening to are part of the past so like that weird tension yeah I think that's true and I think some companies like apple have historically done very well at understanding a market and saying you know what our role is it's not to listen to what the current market says it's to actually shape the market and shape consumer preferences and companies companies have the power to do that they can before we're thinking and they can actually shift what the future of technology looks like and I agree with you that I would like",
        "start": "00:29:31",
        "duration": 232.26200000000003,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "to see more of that especially when it comes to existing biases that we know or or you know that that I think there's the low-hanging fruit of companies that don't even think about it at all and aren't talking to the right people and aren't getting the full information and then there's companies that are just like doing the safe thing and and giving consumers what they want now but to be really forward looking and be really successful I think you have to make some judgment calls about what the future is going to be but do you think it's still useful to gender and to name the robots yes I mean gender is the minefields but people I it's really hard to get people to not gender a robot in some way so if you don't give it a name or you give it a like ambiguous voice people will just choose something and maybe that's better than just like uh you know entrenching something that you've decided is best but I do think it can be helpful on the like anthropomorphism engagement level to give it attributes that people identify with yeah I think uh a lot of roboticists I know they they don't gender the robot they don't they even try to avoid naming the robot or naming it ain't something that is uh can be used as a name in conversation kind of thing and I think that actually that's uh irresponsible because people are going to anthropomorphize the thing anyway so you're just uh removing from yourself the responsibility of how they're they're going to anthropomorphize it that's a good point and so like you want to be able to like they're going to do it you have to start to think about how they're going to do it even if the robot is like a Boston Dynamics robot that's not supposed to have any kind of social",
        "start": "00:31:28",
        "duration": 229.68,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "component they're obviously going to project a social component to it yeah like that arm I worked a lot a lot with quadruped now with with the robot dogs you know that arm people think is the head immediately yeah it's supposed to be an arm but they start to think it's a head and you have to like acknowledge that you can't I mean uh they do now they do now well they've deployed the robots and people are like oh my God the cops are using a robot dog and so they have this PR Nightmare and so they're like oh yeah okay maybe we should hire some HRI people well Boston Dynamics is an interesting company or any of the others that are doing similar thing because their their main source of money is um in the industrial application so like surveillance to factories and uh doing dangerous jobs so to them it's almost good PR for people to be scared of these things because it's it's for some reason as you talk about people are naturally for some reason scared we could talk about that of robots and so it becomes more viral like uh playing with that little fear and so it's almost like a good PR because ultimately they're not trying to put them in the home and have a good social connection they're trying to put them in factories and so they they have fun with it if you watch Boston Dynamics videos yeah they're aware of it oh yeah they're I mean the videos for sure that they put out it's almost like an unspoken tongue-in-cheek thing they they're aware of how people are going to feel when you have a robot that does like a flip now most of the people are uh just like excited about the control problem of it like how to how to make the whole thing happen but they're aware when people see well I think they became aware I think that in the beginning they were really",
        "start": "00:33:23",
        "duration": 238.74000000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "really focused on just the engineering I mean they're at the Forefront of Robotics like Locomotion and stuff um and then when they started doing the videos I think that was kind of a labor of love I know that the former CEO Mark like he oversaw a lot of the videos and made a lot of them himself and like he's even really really detail-oriented like there can't be like some sort of incline that would give the robot an advantage they're very like he he was very um hell of Integrity about the authenticity of them uh and but then when they started to go viral I think that's when they started to realize oh there's something interesting here that you know I don't I don't know how much they took it seriously in the beginning other than realizing that they could play Within the videos yeah I know that they take it very seriously now what I like about Boston Dynamics and similar companies it's still mostly run by engineers but you know I've had my criticisms there's a bit more PR leaking in but those videos are made by Engineers because that's what they find fun mm-hmm it's like testing the robustness of the system I mean they uh they're having a lot of fun there with the robots totally have you been have you been to visit yeah yeah yeah yeah it's cool it's one of the most important like I I uh I mean because I I have um eight uh robot dogs now uh wait you have eight robot dogs what are they just walking around your place like yeah I'm working on them uh that's actually one of my goals is to have at any one time always a robot moving oh I'm far away that's an ambitious goal well I have like more roombas I know what to do with the room their program",
        "start": "00:35:22",
        "duration": 231.07999999999996,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "so the the programmable roombas nice and um I have a bunch of little like I built the well I'm not finished with the butter robot from Rick and Morty I saw a bunch of robots everywhere but the thing is what happens is you're working on one robot at a time and uh that becomes like a little project it's actually very difficult to have just a passively functioning robot always moving yeah and that's a that's a that's a dream for me because I'd love to create that kind of a little world so uh the the impressive thing about Boston Dynamics to me was to see like hundreds of spots and like there's a the most impressive thing that still sticks with me is um there was a a spot robot walking down the hall seemingly with no supervision whatsoever and he was wearing he or she I don't know was wearing a cowboy hat it just it was just walking down the hall and nobody paying attention and it's just like walking down this long Hall and I'm like looking around this is anyone like what's happening here so I'm presumably some kind of automation where he's doing the map I mean the whole environment is probably really well mapped but I it was just it gave me a picture of a world where a robot is doing his thing wearing a cowboy hat just going down the hall like getting some coffee or whatever like I don't know what it's doing what's the mission but uh I don't know for some reason it really stuck with me you don't often see robots that aren't part of a demo or that aren't uh you know like with a semi-autonomous autonomous vehicle like directly doing a task this was just chilling yeah walking around I don't know well yeah you know I mean we're at MIT like when I first got to MIT I was like okay where's all the where's all the robots and they were all like broken",
        "start": "00:37:17",
        "duration": 231.60000000000002,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "or like not demoing so yeah and and and what really excites me is that we're about to have that we're about to have so many moving rope about to well it's coming it's coming in our lifetime that we will just have robots moving around we're already seeing the beginnings of it there's delivery robots in some cities on the sidewalks and I just love seeing like the tick tocks of people reacting to that because yeah you see a robot walking on the hall with a cowboy hat you're like what the what is this this is awesome and scary and kind of awesome and people either love or hate it that's one of the things that I think companies are underestimating that people will either love a robot or hate a robot and nothing in between so it's just again an exciting time to be alive yeah I think kids almost universally at least in my experience love them a lot love legged robots if they're not La my my son hates the room though because ours is loud oh that yeah no the legs the legs oh yeah because your son um do they understand Roma to be a robot oh yeah my kids that's that's the first words they learned they know how to say beep boop think the room as a robot does do they project intelligence out of the thing but we don't really use it around them anymore for the reason that my son is scared of it yeah that's right I think they would like even a Roomba because it's moving around on its own I think kids and animals view it as a an agent so what do you think if we just look at the state of the art of Robotics what do you think robots are actually good at today so if we look at today you mean physical robots yeah physical robots well like what are you impressed by",
        "start": "00:39:12",
        "duration": 228.0390000000001,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "so I think a lot of people I mean that's what your book is about is have maybe a not a perfectly calibrated understanding of where we are in terms of Robotics what's difficult the robotics what's easy in robotics yeah we're way behind where people think we are so what's impressive to me so uh let's see oh one one thing that came out recently was Amazon has this new Warehouse robot and it's the first autonomous Warehouse robot that can is safe for people to be around and so like it's kind of most people most people I think Envision that our warehouses are already fully automated and that they're just like robots doing things it's actually still really difficult to have robots and people in the same space because it's dangerous for the most part robots you know because especially robots that have to be strong enough to move something heavy for example they can really hurt somebody and so until now a lot of the warehouse robots had to just move along like pre-existing lines which really restricts what you can do um and so having I think that that's that's one of the big challenges and one of the big like exciting things that's happening is that we're starting to see more kobotics in industrial spaces like that where people and robots can work side by side and not get harmed yeah that's what people don't realize sort of the physical manipulation tasks with humans it's not that the robots want to hurt you I think that's what people are worried about like this malevolent robot gets them out of its own and wants to destroy all humans now it's you know it's actually very difficult to know where the human is yeah and to to respond to the human and dynamically and collaborate with them on a task especially if you're something like an industrial robotic arm which is",
        "start": "00:41:08",
        "duration": 237.60100000000003,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "extremely powerful yeah this some of the some of those arms are pretty impressive now that you can just you can you can grab it you can move it so the the collaboration between human robot in the factory setting is really fascinating yeah um do you think they'll take our jobs I don't think it's that simple I think that there's a ton of disruption that's happening and will continue to happen um you know I think speaking specifically of the Amazon warehouses that might be an area where it would be good for robots to take some of the jobs that are you know where people are put in a position where it's unsafe and they're treated horribly and you know probably it would be better if a robot did that and Amazon is clearly trying to automate that job away so uh I think there's going to be a lot of disruption I do think that robots and humans have very different skill sets so while a robot might take over a task it's not going to take over most jobs um I think just things will change a lot like I know one of the examples I have in the book is mining um so they're you have this job that is very unsafe and that requires a bunch of workers and puts them in unsafe conditions and now you have all these different robotic machines that can help make the job safer and as a result now people can sit in these like air-conditioned remote control stations and like control these autonomous mining trucks and so that's a much better job but also they're employing less people now so it's it's just a lot of I think from a bird's eye perspective you're not going to see job loss you're going to see more jobs created because that's I I think the future is not robots just becoming like people and taking their jobs the future is really a",
        "start": "00:43:07",
        "duration": 246.17999999999998,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "combination of our skills and then the supplemental skills that robots have to increase productivity to help people have better safer jobs to give people work that they actually enjoy doing and are good at um but it's really easy to say that from a bird's eye perspective and um ignore kind of the the rubble on the ground as we go through these transitions because of course specific jobs are going to get lost if you look at the history of the 20th century it seems like automation constantly increases productivity and improves the average quality of life so it's it's been always good so like thinking about this time being different is that we would need to go against the lessons of History it's true and uh the other thing is I think people think that the automation of the physical tasks is easy I was I was just in Ukraine and the interesting thing is um I mean there's a lot of difficult and uh dark lessons just about a war zone but one of the things that happens in war is there's a lot of Mines that are placed um that's the this one of the big problems for years after a war is even over is the entire landscape is covered in mines and so there's a demining effort and you would think robots would be good at this kind of thing or like your intuition would be like well say you have unlimited money and you want to do a good job of it unlimited money you would get a lot of really nice robots but no humans are still far superior or animals or animals but even right but humans with animals together yeah you can't just have that's true dog with a hat that's fair but yes and but figuring out also how to uh disable the mine obviously the easy thing the thing a",
        "start": "00:45:09",
        "duration": 259.159,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "robot can help with is to find the mine and blow it up but that's gonna destroy the landscape that that really does a lot of damage to the land you want to uh disable the mine and to do that because of all the different all the different edge cases of the problem it requires a huge amount of human-like experience it seems like so it's mostly done by humans they have no use for robots they don't want robots yeah I think we overestimate what we can automate in the especially in the Physical Realm yeah that's it's weird I mean it's continues that this this the story of humans we think were shitty at everything in the physical world including driving we think everybody makes fun of themselves and others for being shitty drivers but we're actually kind of incredible no incredible and that's why like that's the way Tesla still says that if you're in the driver's seat like you you are ultimately responsible because the ideal for I mean I mean you know more about this than I do but he like robot cars are great at predictable things and can react faster and more precisely than a person and can do a lot of the driving and then the reason that we still don't have autonomous vehicles on all the roads yet is because of this long tail of just unexpected occurrences where a human immediately understands that's the sunset and not a traffic light that's a horse and carriage ahead of me on the highway but the car has never encountered that before so like in theory combining those skill sets is what's gonna really be powerful the only problem is figuring off the figuring out the human robot interaction and the handoffs so like in cars that's a huge problem right now figuring out the handoffs um but in other areas uh it might be easier and that's really the future is human robot interaction",
        "start": "00:47:18",
        "duration": 226.60100000000003,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "well it's really hard to improve it's it's it's terrible that people die in car accidents but I mean it's like 70 80 100 million miles one death per uh 80 million miles that's like really hard to beat for a robot that's that's like incredible that like think about it like the how many people the just the number of people throughout the world that are driving every single day all this you know Steve deprived drunk uh distracted all of that and still very few die relative to what I would imagine if I were to guess back in the horse see when I was like in the in the beginning of the 20th century riding my horse I would talk so much [ __ ] about these cars I'd be like this is gonna this is extremely dangerous these machines traveling at 30 miles an hour or whatever the hell they're going at this is irresponsible it's unnatural and and it's going to be destructive to all of human society but then it's extremely surprising how humans adapt to the thing and they know how to not kill each other um I mean that at ability to adapt is incredible and to mimic that in the machine is really tricky now that said what Tesla is doing it I mean I wouldn't have guessed how far machine learning can go on Vision alone it's really really incredible and people that are at least from my perspective people that are kind of um uh you know critical of Elon and those efforts I think don't give enough credit how much progress we made some how much incredible progress has been made in that direction I think most of the robotics Community wouldn't have guessed how much you can do on Vision alone it's kind of incredible um because we would be I think it's that approach which is relatively unique has challenged the other competitors to step up their game so if you're using",
        "start": "00:49:12",
        "duration": 250.85999999999996,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "lidar if you're using mapping um that challenges them to do better to scale faster and to use machine learning and computer vision as well to integrate both lidar and vision so um it's kind of incredible and I'm not I don't know if I even have a good intuition of how hard driving is anymore maybe it is possible to solve so all the stuff you mentioned yeah the question is one yeah I think it's not happening as quickly as people thought it would because it is more complicated but I wouldn't have I I agree with you my current intuition is that we're gonna get there I think we're gonna get there too but I didn't before I wasn't sure we're gonna get there without like with current technology so you know I I was kind of this is like with vision alone I my intuition was you're gonna have to solve like Common Sense reasoning you're gonna have to you're gonna have to solve some of the big problems in artificial intelligence not just uh not just perception yeah like you have to have a deep understanding of the world it's always my sense but now I'm starting to like well this I mean I'm continuously surprised how well the thing works yeah obviously Elon and others others have stopped but Elon continues you know saying we're going to solve it in a year oh yeah that's the thing bold predictions though yeah well everyone else used to be doing that but they kind of like all right yeah or maybe more maybe let's not promise we're gonna solve uh level four driving by 2020. let's uh let's chill on that but people are still trying silently I mean the UK just committed 100 million pounds to research and development to speed up the process of getting autonomous vehicles on the road like everyone is everyone can see that it is solvable and it's",
        "start": "00:51:17",
        "duration": 251.1,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "going to happen and it's going to change everything and they're still investing in it and uh like waymo Loki has driverless cars in in Arizona like you can get you know there's like robots it's weird have you ever been to one no it's so weird it's so awesome because uh the the most awesome experience is a is the wheel turning and you're sitting in the back it's like I don't know it's uh it feels like you're a passenger with that friend who's a little crazy of a driver it feels like [ __ ] I don't know are you right to drive bro you know that kind of feeling good but but then you kind of that experience that nervousness um and the excitement of trusting another being in this case it's a machine it's really interesting um just even introspecting your own feelings about the thing yeah uh they're not doing anything in terms of making you feel better like at least waymo I think they went with the approach of like let's not try to put eyes on the thing let's it's it's a it's a wheel we know what that looks like it's just a car it's a car get in the back let's not like discuss this at all let's not discuss the fact that this is a robot driving you and you're in the back and if the robot wants to start driving 80 miles an hour and run off of a bridge you have no recourse let's not discuss this you're just getting in the back there's no discussion about like how [ __ ] can go wrong uh there's no eyes there's nothing there's like a map showing what the car can see like you know what happens if it's like uh a HAL 9000 situation like I'm like I'm sorry I can't you have a button you can like call customer service oh God then you get put on hold for two hours yeah probably",
        "start": "00:53:24",
        "duration": 251.639,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "um but you know currently what they're doing which I think is understandable but you know the car just can pull over and stop and wait for help to arrive and then a driver will come and then they'll actually drive the car for you but that's like you know what if you're late for meeting or all that kind of stuff or like the more dystopian isn't it the Fifth Element where it's Will Smith in it who's in that movie no Bruce Willis Bruce Willis oh yeah and he gets into like a robotic cab or car or something and then because he's violated a traffic rule it locks him in yeah and he has to wait for the cops to come and he can't get out so like yeah we're gonna see stuff like that maybe what's this I I believe that the companies that have robots the the only ones that will succeed are the ones that don't do that meaning they respect privacy you think so yeah because people because because they're gonna have to earn people's trust yeah but like Amazon works with law enforcement and gives them the data from The Ring cameras so why should it yeah do you have a ring camera uh no okay no no but you know basically any security camera right I've uh Google's whatever they have we have one that's not the data at least or the data on a local server because we don't want it to go to law enforcement because all the companies are doing it they're doing I I bet Apple wouldn't yeah the only company I trust and I don't know how much longer I don't know I maybe that's true for cameras but with robots people are just not going to let a robot inside their home where like one time where somebody gets arrested because of something a robot",
        "start": "00:55:29",
        "duration": 229.73999999999998,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "sees that's going to be that's gonna destroy a company you don't think people are going to be like well that wouldn't happen to me that happened to a bad person and I think they would yeah because in the modern world people I get have you seen Twitter they get extremely paranoid about any kind of surveillance but the thing that I've had to learn is that Twitter is not the modern world like when I go you know Inland to visit my relatives like they don't that's a different discourse that's happening I think like the whole Tech criticism world yeah it's loud in our ears because we're in those circles do you think you can be a company that does social Robotics and not win over Twitter that's a good question I feel like the early adopters are all on Twitter and it feels like you have to win them over feels like nowadays you'd have to win over Tick Tock honestly I don't is that is that a website I hate to check it out um and that's an interesting one because China is behind that one exactly uh so it's compelling enough maybe people would be able to uh give up privacy and that kind of stuff that's really I just I mean I'm worried about it I'm worried about it and I'm there have been some developments recently that are like super exciting like the large language learning models like wow I did not anticipate those improving so quickly and those are going to change everything and one of the things that I'm trying to be cynical about is that I think they're gonna have a big impact on privacy and data security and like manipulating consumers and manipulating people because suddenly you'll have these agents that people will talk to and they",
        "start": "00:57:24",
        "duration": 222.10000000000002,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "won't care or won't know at least on a conscious level that it's recording the conversations so kind of like we were talking about before um and at the same time the technology is so freaking exciting that it's going to get adopted it's not even just a collection of data but the ability to manipulate at scale so um what do you think about the AI the engineer from from Google that thought Lambda is sentient he had actually a really good post from somebody else I forgot her name it's brilliant I can't believe I didn't know about her thank you yeah for weird AI oh yeah I love her book oh she she's great I left a note for myself to reach out to her she's amazing she's hilarious and Brilliant and just a great summarizer of the state of AI but she has um I think that was from her where I was looking at uh AI explaining that it's a squirrel oh yeah because the transcripts that the engineer released Lambda kind of talks about the experience of human-like feelings and I think even consciousness and so she was like oh cool that's impressive I wonder if an AI can also describe the experience of being a squirrel and so she interviewed I think she did gbt3 about the experience of being a squirrel and then she did a bunch of other ones too like what's it like being a flock of crows what's it like being an algorithm that powers a Roomba and like yeah you can have a conversation about any of those things and they're very very convincing yeah yeah even gpg3 which is not like state of the art right it's convincing of being a squirrel it's like what what it's like I mean you should check it out because it really is it's like yeah that probably is what a squirrel would would say are you excited like what's it like",
        "start": "00:59:17",
        "duration": 231.482,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "being a squirrel that's fun okay I get to eat nuts and run around all day uh like how do you think people feel like when you tell them that you're a squirrel um you know or like I forget what it was like a lot of people might be scared to find out that you're squirrel or something like this and then the system Answers Pretty like yeah pretty well like yeah like um I hope they'll like what do you think the when they find out you're a squirrel um I I hope they'll see how fun it is to be a score like that what do you say to people who don't believe you're a squirrel I say come see for yourself I am a squirrel that's great well I think it's really great because it it like the two things to note about it are first of all just because the machine is describing an experience doesn't mean it can it actually has that experience but then secondly these things are getting so Advanced and so convincing at describing these things and talking to people that's I mean just the implications for health education communication entertainment gaming like I just like all of the applications it's mind-boggling what we're going to be able to do with this and and that my kids are not going to remember a time before they could have conversations with artificial agents do you think they would because to me this is uh the focus in the ad Community has been well this engineer Shirley's hallucinating the thing is not sentient but to me I first of all it doesn't matter if he is or not this is coming yeah where a large number of people would believe a system has sent you including Engineers within companies yeah so in that sense you start to think about a world where like your kids aren't just used to having a conversation with the bot but used to",
        "start": "01:01:13",
        "duration": 227.499,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "believing kind of having an implied belief that the thing is sentient yeah I think I think that's true and I think that one of the things that bothered me about all of the coverage in the tech press about this incident like obviously I don't believe the system is sentient like I think that it can convincingly describe that it is I don't think it's doing what he thought it was doing and actually experiencing feelings but a lot of the tech press was about how he was wrong and depicting him as kind of naive and it's not naive like there's so much research in my field showing that people do this even experts they they might be very clinical when they're doing human robot interaction experiments with a robot that they've built and then you bring in a different robot and they're like oh look it on it's doing this like that happens in our lab all the time we are all this guy and it's gonna it's gonna be huge so I think that the the goal is not to discourage this kind of belief or like Design Systems that people won't think are sentient I don't think that's possible I think you're right this is coming it's something that we have to acknowledge and even embrace and be very aware of so one of the really interesting perspectives that your book takes on a system like this is to see them not to compare something like this to humans but to compare it to animals of how we see animals can you kind of try to again sneak up try to explain why this analogy is better than the human analogy the analogy of robots as animals yeah and it gets trickier with the language stuff but we'll get into that too um I think that animals are a really great thought experiment when we're thinking about Ai and Robotics because again this",
        "start": "01:03:08",
        "duration": 228.722,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "comparing them to humans that leads us down the wrong path both because it's not accurate but also I think for the future we don't want that we want something that's a supplement but I think animals because we've used them throughout history for so many different things we we domesticated them not because they do what we do but because what they do is different and that's useful and I it's just like whether we're talking about companionship whether we're talking about work integration whether we're talking about responsibility for harm there's just so many things we can draw on in that history from these entities that can sense think make autonomous decisions and learn that are applicable to how we should be thinking about robots in Ai and and the point of the book is not that they're the same thing that animals and robots are the same obviously there are tons of differences there like you can't you can't have a conversation with a squirrel right but the the point you do it all the time oh really by the way squirrels are the cutest I project so much on squirrels I wonder what their inner life is um I suspect they're much bigger [ __ ] than we imagine really like if it was a giant squirrel it would [ __ ] you over so fast if you had the chance it would take everything you own it would eat all your stuff because it's small and the Furry Tail the furry tale is a is uh is a weapon against human consciousness and cognition it wins us over that's what cats do too cats out I'll competed squirrels and dogs like yeah dogs no dogs have love cats are have no soul they I'm just kidding people get so angry I talk [ __ ] about cats that I love cats anyway uh so yeah uh yeah you're you're describing all the different kinds of animals that get domesticated",
        "start": "01:05:02",
        "duration": 217.91900000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "and it's a really interesting idea that it's not just sort of pets there's all kinds of domestication going on they all have all kinds of uses yes like the uh Ox that you propose might be at least historically one of the most useful domesticated animals it was a game changer because it revolutionized like what people could do economically Etc so I I mean just like robots They're Gonna Change they're going to change things economically they're going to change Landscapes like cities might even get rebuilt around autonomous vehicles or drones or delivery robots like I think just the same ways that animals have really shifted society and Society has adapted also to like socially accepting animals as pets um I think we're going to see very similar things with robots so I think it's a useful analogy it's not a perfect one but I think it's it helps us get away from this idea that robots can shoot or will replace people if you remember what are some interesting uses of animals ferrets for example oh yeah the ferrets they they still do this they use ferrets to go into narrow spaces that people can't go into like a pipe or like they'll use in the wrong electrical wire I think they did that for princess dies for wedding there's so many weird ways we've used animals and still use animals for things that robots can't do like the dolphins that they used in the in the military I think the I think Russia still has Dolphins and the US Dollars dolphins in their navies um uh mind detection looking for lost underwater equipment some rumors about like using them for weaponry which which I think Russia's like sure believe that and America's like no no we don't do that who knows but they started doing that in like the 60s 70s they started training these Dolphins because",
        "start": "01:06:51",
        "duration": 229.68100000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "they were like oh dolphins have this amazing echolocation system that we can't replicate with machines and they're trainable so we're going to use them for all the stuff that we can't do with machines or by ourselves and they've tried to phase out the Dolphins I know the US has like invested a lot of money in trying to make robots do the Mind detection but like you were saying there are some things that the robots are good at and there's some things that biological creatures are better at so they still have the Dolphins so there's also pigeons of course oh yeah pigeons oh my gosh there's so many examples the pitch I mean the pigeons were the original hobby photography drone they also carried mail for thousands of years letting people communicate with each other in new ways so the thing that I like about the animal analogies they have all these physical abilities but also sensing abilities that we just we don't have and like that's that's just so useful and that's that's robots right robots have physical abilities they can help us lift things or do things that we're not physically capable of they can also sense things it's just I just feel like I still feel like it's a really good analogy and really strong and it works because it's people are familiar with it what about companionship and when we start to think about like cats and dogs like pets that seem to serve no purpose whatsoever except the social connection yeah I mean this you were a thing at least in the United States like dogs used to have like they used to have a purpose they used to be guard dogs or they had some sort of function and then at some point they became just part of the family um and I it's it's so interesting how there's some animals that we've treated as",
        "start": "01:08:46",
        "duration": 212.64,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "workers some that we've treated as objects some that we eat and some that are parts of our families and that that's different across cultures and I'm convinced that we're going to see the same thing with robots um where people are going to develop strong emotional connections to certain robots that they relate to either culturally or or personally emotionally and then there's going to be other robots that we don't treat the same way I wonder does that have to do more with the culture and the people or the robot design is there interplay between the two like why did dogs and cats out compete ox and I don't know what else like farm animals to to really get inside the home and get inside our hearts yeah I mean people point to the fact that dogs are very genetically flexible and um they can evolve much more quickly than other animals and so they evolutionary biologists think that dogs evolved to be more appealing to us and then once we learned how to breed them we started breeding them to be more appealing to us too which is not something that we necessarily would be able to do with cows although we've bred them to make more milk for us so but part of it is also culture I mean there are cultures where people eat dogs still today and then there's other cultures where we're like oh no that's terrible we would never do that and so I think there's a lot of different elements that play in I wonder if there's good because I understand dogs because they use their eyes they're able to communicate affection all those kinds of things it's really interesting what dogs do there's a whole conferences in dog Consciousness and cognition and all that kind of stuff now cats is a mystery to me because they seem to not give a [ __ ] about the human but they're warm and",
        "start": "01:10:32",
        "duration": 219.42000000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "fluffy but they but they're also passive aggressive so they're at the same time they're like they're dismissive of of you in some sense I think some people like that some people like that about people yeah they want they want the push and pull over of a relationship they don't want loyalty or unconditional love that does that means they haven't earned it yeah yeah and maybe that says a lot more about the people than it does about the animal oh yeah we all need therapy yeah so I'm judging harshly to people that have cats or or the people that have dogs maybe the people that have dogs need are are desperate for attention and unconditional love and they're unable to to um to sort of struggle uh to earn meaningful connections um I don't know maybe people are talking about you and your robot pets in the same way yeah that's uh [Laughter] it is kind of sad there's just robots everywhere but he's I mean I'm joking about it being said because I think it's kind of beautiful I think robots are uh beautiful in the same way that pets are even children in that like they capture some kind of magic of uh social robots they have the capacity to have the same kind of magic of connection um I don't know what that is like um when they're brought to life and they move around the way they make me feel I'm pretty convinced is as as you know they will make billions of people feel like I I don't think I'm like some weird robotics guy I'm not I mean you are but not in this way not in this way I mean I",
        "start": "01:12:22",
        "duration": 222.79799999999997,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "just I can put on my like normal human hat and just see this oh this is like there's a lot of possibility there of something cool just like with dogs what is it why are we so into dogs or cats like it's like that it's way different than us it is it's like drooling all over the place with its tongue out and it's like what it's like a weird creature that used to be a wolf why are we into this thing well dogs can either Express or mimic a lot of emotions that we recognize um and I think that's a big thing like a lot of the magic of animals and robots is our own self-projection and the easier it is for us to see ourselves in something and project human emotions or qualities or traits onto it the more we'll relate to it and then you also have the movement of course I think that's also really that's why I'm so interested in physical robots because that's I think the visceral magic of them I think we're I mean there's there's research showing that we're probably biologically hardwired to respond to autonomous movement in our physical space because we've had to watch out for Predators or whatever the reason is um and so animals and robots are very appealing to us as these autonomously moving things that we view as agents instead of objects I mean I I love the moment which is I've been particularly working on which is when a robot like the cowboy hat uh is doing its own thing and then uh it recognizes you I mean the way a dog does and it it looks like this and the the moment of recognition like you're walking say you work in an airport on the street and there's just you know hundreds of strangers but then you see somebody you know and that like where you wake up to like",
        "start": "01:14:16",
        "duration": 233.16200000000003,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "uh that excitement of seeing somebody you know and saying hello and all that kind of stuff that's a magical moment like uh I think especially with the dog it makes you feel noticed and heard and and loved like as somebody looks at you and recognizes you that that it matters that you exist yeah you feel seen yeah and that's a cool feeling and I I honestly think robots can get that feeling oh yeah totally currently Alexa I mean one of the downsides of these systems is they don't there's servants they like uh part of the you know they're trying to maintain privacy I suppose uh but I don't feel seen with Alexa right I think that's going to change I think you're right and I think that that's that's the game changing changing nature of things like these large language learning models and the fact that these companies are investing in embodied versions that move around of Alexa like Astro can I just say yeah I haven't is that out is this I mean it's out you can't just like buy one commercially yet but you can apply for one yeah my gut says that these companies don't have the guts to do the personalization this goes to the because it's edgy is dangerous it's going to make a lot of people very angry like in a way that you know just imagine okay all right if you do the full landscape of human civilization just visualize the number of people that are going through breakups right now just the amount of really passionate Steven if we just look at teenagers the amount of deep heartbreak that's happening and like if if you're going to have Alexa have more of a personal connection with the human you're going to have humans that like have",
        "start": "01:16:13",
        "duration": 245.09999999999994,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "existential crises there's a lot of people that suffer from loneliness and depression and like you're now taking on the full responsibility of being a companion to the the the roller coaster of the human condition as a company like imagine PR and marketing people they're gonna freak out they don't have the guts it's going to have to come from somebody from a new Apple from those kinds of folks like it's a small startup and it might yeah like they're coming there's already a virtual therapist there's that replica app I haven't tried it but replicas like a spiritual companion like it's coming and if big companies don't do it someone else will yeah I think the the future the next trillion dollar company will be those personalization because if you think um if you think about all the the AI we have around us all the the smartphone and so on there's very minimal personalization you don't think that's just because they weren't able yeah really I don't think they have the guts I mean it might be true but I have to wonder I mean Google is clearly gonna do something with the language I mean they don't have to that are you challenging them uh partially but not really because I know they're not going to do it I mean they don't have to it's bad for business in the short term I'm gonna be honest like maybe it's not such a bad thing if they don't just like roll this out quickly because I do think there are huge issues and and there's and not just issues with like the responsibility of like unforeseen effects on people but what's the business model and if you are using the business model that you've used in other domains then you're going to have to collect data from people which you will anyway to personalize the thing and you're going to be somehow monetizing the data or you're going to be doing some like ad model it just it",
        "start": "01:18:15",
        "duration": 235.44,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "seems like now we're suddenly getting into the realm of like severe consumer protection issues and I'm I'm really worried about that I I see massive potential for this technology to be used in a way that's not for the public good and not I mean that's in in an individual user's interest maybe but not in society's interest yes yeah I think I think that kind of personalization should be like redefine how we treat data I think you should own all the data your phone knows about you like and be able to delete it with a single click and walk away and that data cannot be monetized or used or shared anywhere without your permission I think that's the only way people will trust you to give to if for you to use that data but then how are companies gonna I mean a lot of these applications rely on massive throws of data to train the AI system right so you have to um opt-in constantly and opt-in not in some legal I agree but obvious like show exactly like um in the way uh I opt in to tell you a secret like we understand like that like I have to have to choose like how well do I know you and then I say like don't tell this to anyone and then I have to judge how leaky that uh like how good you are I keep your secrets in that same way like it's very transparent in uh which data you're allowed to use for which purposes that's what people are saying is the solution and I think that works to some extent having transparency having people consent I think it breaks down at the point at which have you seen this happen on social media too like people are willingly giving up their data because they're",
        "start": "01:20:13",
        "duration": 233.80100000000002,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "getting a functionality from that and then the harm that that causes is on a like maybe just someone else and not to them personally so I don't think people are given their data they're not being asked like but if if you were consensual if you were like tell me a secret about yourself and I'll give you a hundred dollars I'd tell you a secret no not a hundred dollars uh first of all you wouldn't uh you wouldn't trust like why are you giving me a hundred dollars it's a bad example but but like I I need um I would ask for your specific like fashion uh interest into in order to give recommendations to you for shopping and I'd be very clear for that you could disable that you can uh delete that but but then you can be have a deep meaningful Rich connection with the system about what you think you look fat in what you look great in what like the full history of all the things you've worn whether you uh regret to Justin Bieber enjoy the Justin Bieber shirt all of that information that's mostly private to even you not even your loved ones that a system should have that because then a system if you trust it to keep control of that data that you own you can walk away with that system could tell you a damn good thing to wear it could and the harm that I'm concerned about is not that the system is going to then suggest a dress for me that is based on my preferences so I I went to this conference once where I was talking to the people who do the analytics in like the big ad companies and like literally a woman there was like I can ask you three totally unrelated questions and tell you what menstrual product you use and so what they do is they aggregate the data and they map out different personalities and different people and",
        "start": "01:22:11",
        "duration": 231.65900000000002,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "demographics and then they have a lot of power and control to Market to people so like I might not be sharing my data with any of the systems because I'm like I'm on Twitter I know that this is bad other people might be sharing data that can be used against me like it's I think it's it's way more complex than just I share a piece of personal information and it gets used against me I think that at a more systemic level and then it's always you know vulnerable populations that are targeted by this um you know low-income people being targeted for scammy loans or I don't know like I could get targeted like someone not me because I have someone who doesn't have kids yet and is my age could get targeted for like freezing their eggs and there's all these ways that you can manipulate people where it's not really clear that that came from that person's data it came from all of us all of us opting into this but there there's a bunch of sneaky decisions along the way that could be avoided if there's transparency so that so one of the ways that goes wrong if you share that data with too many ad Networks don't run your own ad Network don't share with anybody okay and that's data could regulate you it belongs to just you and all the ways you allow the company to use it the default is in no way at all and you're consciously constantly saying exactly how to use it and uh and also it has to do with the recommender system itself from the company which is um freezing your eggs if that doesn't make you happy if that idea doesn't make you happy then the system shouldn't recommend it and should very be very good at Learning so not the kind of things that the category of people it thinks you belong to would do but more you specifically",
        "start": "01:24:07",
        "duration": 254.20199999999994,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "what makes you happy what is helping you grow but you're assuming that people's preferences and like what makes them happy is static whereas when we're talking before about how a company like Apple can tell people what they want and they will start to want it that's the thing that I'm more concerned about yeah that is a huge problem it's not just listening to people but manipulating them into wanting something and that's like we have a long history of using technology for that purpose like the persuasive design in casinos to get people to gamble more or like it's just I'm the other thing that I'm worried about is as we have more social technology suddenly you have this on a new level like if you look at the influencer marketing that happens online now what's the influencer so like on Instagram there will be some like person who has a bunch of followers yeah and then a brand will like hire them to promote some product and it's above board they disclose like I'm this is an ad that I'm promoting but they have so many young followers who like deeply admire and trust them this I mean this must work for you too don't you have like ads on the podcast like people trust magic spoon cereal low carb yes if you say that like I guarantee you some people will buy that just because even though they know that you're being paid they trust you yeah it's different with podcasts because uh well my particular situation but it's true for a lot of pockets especially big ones is you know I have 10 times more sponsors that want to be sponsors than than I have so you get to select the ones that you actually want to support and so like you end up using it and then you're able to actually like there's no incentive to like um",
        "start": "01:26:15",
        "duration": 229.55999999999995,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "show for anybody sure and that's why it's fine when it's still human influencers right now if you're a bot you're not gonna just discriminate you're not gonna be like oh well this product is good for people you think they'll be like Bots essentially with millions of followers there already are there are virtual influencers in South Korea yeah who show products and and like that's just the tip of the iceberg because that's still very primitive now with the new image generation and the language learning models and like so we're starting to do some research around kids um and like young adults because a lot of the research on like what's okay to advertise to kids and what is too manipulative has to do with television ads back in the day where like a kid who's 12 understands oh that's an advertisement I can distinguish that from entertainment I know it's trying to sell me something now it's getting really really murky with influencers and then if you have like a bot that that a kid has developed a relationship with is it okay to market products through that or not like you're getting into all these consumer protection issues because you're developing a trusted relationship with a social entity but it's and and so and so now it's like personalized it's scalable it's automated and it has it it can so some of the research showing that kids are already very confused about like the incentives of the company versus what the robot is doing meaning they're so okay they're not deeply understanding the incentives of the of the of the system well yeah so like kids who are old enough to understand this is a television advertisement is trying to advertise to me I might still decide I want this product but they understand what's going on so there's some",
        "start": "01:28:10",
        "duration": 229.23999999999998,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "transparency there that age child so um Daniela de Paola Anastasia ostrovsky and I advised on this project they did this um they they asked kids who had interacted with social robots whether they would like a policy that allows robots to Market to people through casual conversation or whether they would prefer that it has to be transparent that it's like an ad coming from a company and the majority said they preferred the casual conversation and when asked why there was a lot of confusion about they were like well the robot knows me better than the company does so the robot's only going to Market things that I like and so they don't really they're not connecting the fact that the robot is an agent of the company they're viewing it as something separate and I think that even happens subconsciously with grown-ups when it comes to robots and artificial agents and it will like this blank guy at Google sorry I'm going on and on but like his main concern was that Google owned this sentient agent and that it was being mistreated his concern was not that the agent was going to mistreat people so I think we're going to see a lot of this yeah but shitty companies will do that I think ultimately that confusion should be alleviated by the robot should actually know you better and should not have any control from the company but what's the business model for that it's if you use the robot to buy first of all the robot should probably cost money should what cost money like the way Windows operating system does I see it more like an operating system than um like this thing is your window no pun intended into the into the world so it's helping you it's like a personal assistant",
        "start": "01:30:07",
        "duration": 224.81899999999996,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "right and so that should cost money you should you know whatever it is 10 bucks 20 bucks like that's the thing that makes your life significantly better this idea that everything should be free is is like it should actually help educate you you should talk [ __ ] about all the other companies that do stuff for free but uh but also yeah in terms of if you purchase stuff based on its recommendation it gets money that so it's it's kind of AD driven but it's not ads it's like um um it's not controlled like no no external entities can control it to try to manipulate to want a thing that would be amazing it's actually trying to discover what you want so it's not allowed to have any influence no promoted ad no anything so that's finding I don't know the uh the the thing that would actually make you happy that's the only thing it cares about I I think I think companies like this can win out yes I think eventually once people understand the value of the robot even just like I think that robots would be valuable to people even if they're not marketing something or helping with like preferences or anything like just a simple the same thing as a pet like a dog that has no function other than being a member of your family I think robots could really be that and people would pay for that I don't think the market realizes that yet and so my concern is that companies are not going to go in that direction at least not yet of making like this contained thing that you bought it seems almost old-fashioned right to have a disconnected uh object that you buy that you're not like paying a subscription for it's not like controlled by one of the big corporations but that's the",
        "start": "01:31:58",
        "duration": 233.38100000000009,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "old-fashioned things that people uh uh yearn for because I think is very popular now and people understand the negative effects of social media the negative effects of the data being used in all these kinds of ways I think I think we're just waking up to the realization we tried but we're like baby deer finding our legs in this new world of social media of AD driven companies and realizing okay this has to be done somehow different I mean that like like one of the most popular Notions at least the United States and social media is evil and it's doing bad it's it's doing bad by us it's not like it's totally tricked us into believing that is good for us I think everybody knows it's bad for us and so like there's a hunger for our other ideas all right it's time for us to assist that company I think so let's do it let's do it I think let's go hopefully no one listens to this and steals the idea there's no see that's the other thing I think I'm a big person on um executions what matters I mean oh yeah it's like ideas are kind of true the social robotics is a good example that there's been so many amazing companies that went out of business I mean to me it's obvious like it's obvious that there will be a robotics company that puts a social robot in the home of billions of homes yeah and it'll be a companion okay there you go you can steal that idea do it okay for you what about Elon musk's humanoid is he gonna execute on that there might be a lot to say so for people who are not aware there's an Optimus Tesla's Optimus robot that's um I guess the stated reason for that robot is a humanoid robot in the factory that's able to automate some of the tasks that humans are currently doing and the reason you want to do it's the",
        "start": "01:33:56",
        "duration": 236.82,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "second reason you mentioned the reason you want to do a humanoid robot because the factory is built for the certain tasks that are um designed for humans so it's hard to automate with the any other form factor than a humanoid and then the other reason is because so much effort has been put into this giant data engine machine of of perception that's inside Tesla autopilot that's seemingly at least the machine if not the data is transferable to the factory setting to any setting yeah he said he would do anything that's boring to to us yeah yeah the interesting thing about that is there's no interest and no discussion about the social aspect Mike I I talked to him on Mike and off Mike about it quite a bit and he there's not a discussion about like to me it's obvious if a thing like that works at all at all in fact it has to work really well in a factory if it works kind of shitty it's much more useful in the home that's true because we're much this we're I I think being shitty as stuff is kind of uh what makes relationships great like you want to be flawed and be able to communicate your flaws and be unpredictable in certain ways like if you fell over every once in a while for no reason whatsoever I think that's essential for for like very Charming well it's Charming but also concerning and also like uh like like are you okay I mean it's both hilarious it's whenever somebody you love like falls down the stairs it was both hilarious and concerning it's some some dance between the two and I think that's essential for like um you almost want to engineer that in",
        "start": "01:35:56",
        "duration": 246.08100000000007,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "uh except you don't have to because of Robotics in the physical Space is really difficult so um I think I've learned to not discount the the efforts that Elon does there's a few things that are really interesting there one because he's taken extremely seriously what I like is the humanoid form the cost of building a robot I talked to Jim Keller offline about this a lot and currently human robots cost a lot of money and the way they're thinking about it now they're not talking about all the social robotic stuff that you and I care about uh they are thinking how can we manufacture this thing cheaply and do it like well and the kind of discussions they're having is really great engineering it's like it's a bit it's like first principles question of like why is this cost so much like what's the cheap way how why can't we build and there's not a good answer uh why can't we build this humanoid form for under a thousand dollars and like I've I've sat and had these conversations there's no reason it's uh I think the reason they've been so expensive is because um they were focused on trying to they weren't focused on doing the mass manufacture they were people are focused on getting a thing that's um I don't know I don't know exactly what the reasoning is but it's the same like waymo it's like let's let's build a million dollar car in the beginning or like multi-million dollar car let's try to solve that problem the the way Elon the way Jim Keller the way some of those folks are thinking is that's like at the same time try to actually build a system that's cheap not crappy but cheap unless from first principles what is the minimum amount of uh degrees of freedom we need what are",
        "start": "01:37:58",
        "duration": 227.77999999999997,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "the joints where's the control set like how many how do we act like where are the activators uh what's the way to power this in the lowest cost way possible but also in a way that's like actually works how do we make the whole thing not part of the components where there's a supply chain you have to have all these different parts that have to feed us so do it all from scratch and do the the learning I mean it's like immediately certain things like become obvious do uh the exact same pipeline as you do for autonomous driving just the exactly I mean the infrastructure that is incredible for the computer vision for the manipulation task the control problem changes the perception uh problem changes but the pipeline doesn't change and do it and so I don't I don't um obviously the optimism about how long it's going to take I don't share um but it's a really interesting problem and I don't want to say anything because my first gut is to say that why the humanoid form that doesn't make sense yeah that's my second gut too but but then there's a lot of people that are really excited about the humanoid form there that's true I don't want to get in the way like they might solve this thing and they might it's like similar with Boston Dynamics like why like if I were to you can be a hater and be and you go go up to Mark Robert and just like how are you gonna make money with these like super expensive legged robots what's what's your business plan this doesn't make any sense why are you doing these legged robots but at the same time they're pushing forward the science the art of Robotics and the way that nobody else does yeah and uh with Elon they're not just going to do that they're going to drive down the cost to where we can have humanoid baths in the home potentially so the part I agree with is a lot of people find it fascinating and",
        "start": "01:39:54",
        "duration": 239.69900000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "it probably also attracts Talent who want to work on humanoid robots I think it's a fascinating scientific problem and Engineering problem and it can teach us more about human body and Locomotion and all of that I think there's a lot to learn from it where I get tripped up is why we need them for anything other than art and entertainment in the real world like I get that there's some areas where you can't just rebuild like a spaceship you can't just like they've worked for so many years on these spaceships you can't just re-engineer it you have some things that are just built for human bodies a submarine a spatial but a factory maybe I'm naive but it seems like we've already rebuilt factories to accommodate other types of robots why would we want to just like make a humanoid robot to go in there I I just get really tripped up on I think that people want humanoids I think people are fascinated by them I think it's a little over hyped well most of our world is still built for humanoids I know but it shouldn't be it should be built so that it's wheelchair accessible right so the question is do you build a world that's the general form of wheelchair accessible uh [Music] all robot form factor accessible or do you build Tomb Raider robots I mean it doesn't have to be all and it also doesn't have to I feel like we're thinking so little about this system in general and how to create infrastructure that works for everyone all kinds of people all kinds of robots like that's that I mean it's more of an investment but that would pay off way more in the future than just trying to cram expensive or maybe slightly less expensive humanoid technology into a human space unfortunately one company",
        "start": "01:41:55",
        "duration": 231.59899999999993,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "can't do that we have to work together it's like autonomous driving can be easily solved if you do v2i if you change the infrastructure of cities and so on but that requires a lot of people a lot of them are politicians and a lot of them are somewhat if not a lot corrupt and all those kinds of things I and the talent thing you mentioned is really really really important I've gotten a chance to meet a lot of folks at SpaceX and Tesla other companies too but they're specifically the openness makes it easier to like meet everybody I think a lot of amazing things in this world happen when you get amazing people together oh yeah and if you can sell an idea like us becoming a multi-planetary species you can say why the hell are we going to Mars like why colonize Mars if you think from from basic first principles it doesn't make any sense it doesn't make any sense to to go to the Moon it doesn't go it the only thing that makes sense to go to spaces for satellites but there's something about the vision of the future the optimism Laden that permeates this vision of us becoming multi-planetary is thinking not just for the next 10 years it's thinking like human civilization reaching out into the Stars it it makes people dream it's really exciting and that they're gonna come up with some cool [ __ ] that might not have anything to do with uh like here's what I because Elon doesn't seem to care about social robotics which is constantly surprising to me and to talk to him it doesn't humans are humans are the things you avoid and don't hurt right like that's like the number one job of a robot is not to hurt",
        "start": "01:43:51",
        "duration": 229.72299999999993,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "a human to avoid them you know that the the collaborative aspect the human robot interaction I think is not at least not in his uh um and that's something he thinks about deeply but my sense is if somebody like that takes on the problem of human robotics we're going to get a social robot out of it like people like not necessarily Elon but people like like Elon if they take on seriously these um like I could just imagine with the with the humanoid robot you can't help but create a social robot so if you do different form factors if you do industrial uh robotics um you don't you're likely to actually not end up in like walking head into a social a social robot human robot interaction problem if you create for whatever the hell reason you want to a humanoid robot you're gonna have to reinvent or not reinvent but do um introduce a lot of fascinating new ideas into the problem of human robot interaction which I'm excited about so like if I if I was a business person I would say this is not this is this is way too risky this doesn't make any sense but when people are really convinced and there's a lot of amazing people working on it it's like all right let's see what happens here this is really interesting just like with Atlas and Boston Dynamics I mean they I I um I apologize if I'm ignorant on this but I think they really more than anyone else maybe with iboat like Sony pushed forward humanoid robotics like a leap with the oh yeah absolutely and like without them like where the hell did they do it why well I think for them it is a research platform it's not I don't think they ever the speculation I don't think they ever intended Atlas to be like a commercially",
        "start": "01:45:46",
        "duration": 236.921,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "successful robot I think they were just like can we do this let's try yeah I wonder if they maybe the answer they landed on is because they eventually went to um spot the earlier versions of the spot so uh quadruped like four four-legged robot but maybe they reached for let's try to make um like I think they tried it and they still are trying it for Atlas to be picking up boxes to moving boxes to being it it makes sense okay if they were exactly the same cost it makes sense to have a human robot in the warehouse currently currently I think it's short-sighted but yes currently yes it would sell but it's not it's it's short-sighted it's short-sighted but it it's it's not pragmatic to think any other way to think that you're going to be able to change warehouses you're gonna have to you're going You're Amazon you can totally change your warehouses but yes yes but even if you're Amazon that's very costly to change warehouses it is it's a big investment but isn't shouldn't you do that investment in a way so here's the thing if you build the Humana robot that works in the warehouse that human robot and I see I don't know why Tesla's not talking about it this way as far as I know but like that human robot is going to have all kinds of other applications outside their setting like to me it's obvious I think it's a really hard problem to solve but whoever solves the human robot problem are gonna have to solve the social robotics problem oh for sure I mean they're already with the spot needing to spell social robotics problems for uh like for spot to be effective at scale I'm not sure which spot is currently effective skills getting better and better but",
        "start": "01:47:47",
        "duration": 237.65900000000002,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "they're actually the thing they they did it's an interesting decision perhaps thus will end up doing the same thing which is spot is supposed to be a platform for intelligence so spot doesn't have any high level intelligence like a high level perception skills it's supposed to be controlled remotely and it's a platform that you can attach attached off to something yeah and somebody else is supposed to do the attaching it's a platform that you can take in uneven ground and it's able to maintain balance go into dangerous situations it's a platform on top of that you can add a camera that does surveillance that you can remotely monitor you can record uh you can record the camera you can remote control it but it's not good manipulation basic object manipulation but not autonomous object communication it's remotely controlled but the Intelligence on top of it which was what would be required for automation is somebody else is supposed to do yeah perhaps thus would do the same the same thing ultimately but it doesn't make sense because the goal of Optimus is automation without that um but then you never know he's like why go to Mars why why um I mean that's true and I I reluctantly like am very excited about space travel um can you introspect like why why am I excited about it I think what got me excited was I saw a panel with some people who um study other planets and it became really clear how little we know about ourselves and about how nature works and just how much there is to learn from exploring other parts of the universe so like on a rational level that's how I convince myself that that's why I'm excited in reality it's just [ __ ]",
        "start": "01:49:45",
        "duration": 245.30199999999996,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "exciting I mean just like the idea that we can do this difficult thing and that humans come together to build things that can explore space I mean there's just something inherently thrilling about that and I'm reluctant about it because I feel like there are so many other challenges and problems that I think are more important to solve but I also think we should be doing all of it at once and so to that extent I'm like all for research on humanoid robots development of humanoid robots I think that there's a lot to explore and learn and it doesn't necessarily take away from other areas of science at least it shouldn't I think unfortunately a lot of the attention goes towards that and it does take resources and attention away from other areas of Robotics that we should be focused on but I don't think we shouldn't do it so you think it might be a little bit of a distraction oh forget the the Elon particular application but if you care about social robotics the humanoid form is a distraction it's a distraction and it's one that I find particularly boring it's just it's interesting from a research perspective but from like what types of robots can we create to put in our world like why would we just create a humanoid robot so even even just robotic manipulation so arms is not useful either oh arms can be useful but like why not have three arms like why does it have to look like a person well I actually personally just think that washing the dishes is is harder than a robot that can be a companion yeah being useful in the home is actually really tough but does your companion have to have like two arms that look like you no I I'm making the",
        "start": "01:51:49",
        "duration": 229.49899999999994,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "case for zero arms oh okay zero yeah okay that didn't come out the way I meant it because it almost sounds like I don't want a robot to defend itself like that's immediately you can project you know I mean like it's your uh no I think um I just think that the social component doesn't require arms or legs or so on right as we've talked about and I think that's probably where a lot of the meaningful impact that's going to be happening yeah I think just we could get so creative with the design like why not have a robot on roller skates or like whatever like why does it have to look like us yeah uh still it is it is a compelling and interesting form from a research perspective like you said yeah you co-authored the papers you were talking about that um for Wii robot 2022 Lula robot consumer protection in the face of automated social marketing I think you were talking about some of the ideas in that yes oh you got it from Twitter I was like that's not published yet yeah would you this is how I do my research you just go through people's Twitter feeds yeah go thank you um it's not stalking if it's public uh so there's uh you looked at me like you're offended like how did you know and I was just like worried that like some early I mean yeah there's a PDF does it there is there's a PDF like now yeah maybe like as of a few days ago yeah okay well yeah yeah okay you look violated like how did you get that PDF it's just a draft it's online nobody read it yet until we've written the final paper well it's really good so I enjoyed it oh thank you oh by the time this comes out I'm sure it'll be out or no when's we roll up so basically we robot that that's the",
        "start": "01:53:43",
        "duration": 230.88099999999997,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "workshop where you have an hour where people give you constructive feedback on the paper and then you write the good right I take it back there's no PDF I don't know it doesn't exist I imagine but there is a table in there in a virtual imagine PDF that I like that I wanted to mention which is um like this kind of uh strategy used across various marketing platforms and it's uh basically looking at traditional media person-to-person interaction targeted ads influencers and social robots this is the kind of idea that you've been speaking to it's just a nice breakdown of that that social robots have personalized recommendations social persuasion automated scalable data collection and embodiment so person-to-person interaction is really nice but it doesn't have the automated and the data collection aspect but the social robots have those two elements yeah we're talking about the potential for social robots to just combine all of these different marketing methods to be this really potent cocktail and that table which was Daniella's idea and a really fantastic one we put it in at the last second so yeah I really like that I'm glad you like it in the PDF that doesn't exist yes that nobody can find if they look yeah so when you say social robots what does that mean does that include virtual ones or no I think a lot of this applies to Virtual ones two although the embodiment thing which I personally find very fascinating is definitely a factor that research shows can enhance people's engagement with a device but can embodiment be a virtual thing also meaning like it has a body in the virtual world like maybe makes you feel like because what makes a body a body is a thing that um can disappear like um has a permanence I mean there's certain",
        "start": "01:55:39",
        "duration": 224.73800000000006,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "characteristics that you kind of Associated physical object so I think what I'm referring to and I think this gets messy because now we have all these new Virtual Worlds and um AR and stuff and I think it gets messy but there's research showing that something on a screen on a traditional screen and something that is moving in your physical space that that has a very different effect on how your brain perceives it even so I mean I I have a sense that we can do that in a virtual world probably like when I've used VR I jump around like an idiot because I think something's gonna hit me and even if a video game on a 2G screen is compelling enough like the thing that's immersive about it is I kind of put myself into that world you kind of those the the the the objects you're interacting with Call of Duty things you're shooting they're they're kind of I mean your imagination fills the gaps and it becomes real like it pulls your mind in when it's well done so it really depends what's shown on on the 2D screen yeah yeah I think there's a ton of different factors and there's different types of embodiment like you can have embodiment in a virtual world you can have an agent that simply text based which is has no embodiment so I think there's a whole spectrum of factors that can influence how much you engage with something yeah I wonder I always wondered if you can have like a an entity living in a computer is okay this is going to be dark I I haven't always wondered about this so this makes it make it sound like I keep thinking about this kind of stuff no but like um this is almost like Black Mirror but the entity that convinced or is able to convince you that it's",
        "start": "01:57:33",
        "duration": 221.27900000000002,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "being tortured inside the computer I need your help to get out something like this that because to me to me suffering is one of the things that make you empathize with like we're not good at as you've you've discussed in other in in the physical form like holding a robot upside down you have a really good examples about that and discussing that I think suffering is a really good Catalyst for empathy mm-hmm and I I just feel like we can uh project embodiment on a virtual thing if it's capable of certain things like suffering yeah so I was wonderful I think that's true and I think that's what happened with the Lambda thing not that I don't none of the transcript was about suffering but it was about having the capacity for suffering and human emotion that convinced the engineer that this thing was sentient and it's basically the plot of ex machina true have you ever made a robot like scream in pain have I no but have you seen that did someone oh yeah no they actually they actually made a Roomba scream whenever it hit a wall yeah I've broken that myself as well yeah because I was inspired by that yeah I still have it oh oh sorry uh hit a wall that didn't I never bumped into something it would screaming yeah no I uh so I had the way I programmed in the room was is when I kick it whenever I so contact between me and the robots when it screamed really okay and you were inspired by that yeah I guess I misremembered the video I saw the video a long long time ago and uh or maybe heard somebody mention and that just it's the easiest thing to program so I did that I haven't run those roombas for over a year now but yeah it was um my experience with it was that it's",
        "start": "01:59:24",
        "duration": 231.12,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "it's like um they quickly become like you remember them uh you you um you you miss them like they're real living beings so the capacity of yourself or is is a really powerful thing yeah even then that I mean it was kind of hilarious it was just a random recording of screaming from the internet but it's still it still is weird there's a thing you have to get right based on the interaction like the latency like it has there is there is a realistic aspect of how you should scream relative to when you get hurt like it should correspond correctly like if you kick it really hard it should scream louder no it's just scream at the appropriate time not like oh I see it's like one second later right like there's a exact like there's a timing when you get like I don't know uh when you run into when you run your foot into like the side of a table or something there's a timing there the Dynamics you have to get right for the for the actual screaming because the the Roomba in particular uh doesn't so I was uh the sensors don't it doesn't know about pain see what I'm sorry to say Roomba doesn't understand pain uh so you have to correctly map the the sensors the timing to the production of the sound but when you get that somewhat right it starts is it's weird it's really weird feeling and you actually feel like a bad person oh yeah so but it's is makes you think because that with all the ways that we talked about that could be used to manipulate you oh for sure in a good and bad way so the good ways like you could form a connection with a thing uh in a bad way that you can form a connection in order to sell you products that you don't want yeah or",
        "start": "02:01:18",
        "duration": 243.39800000000002,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "manipulate you politically or in the many nefarious things you tweeted we're about to be living in the movie Her except instead I'm seeing I've researched your tweets like they're like Shakespeare we're about to be living in the movie Her except instead of about love is going to be about what I say the chatbot being subtly racist and the question whether it's ethical for companies to charge for software upgrades yeah so uh can we break that down uh what do you mean by that yeah obviously some of it is humor yes well kind of I am like oh it's so weird to be in the space where I'm so worried about this technology and also so excited about it at the same time but the the really like I haven't I gotten a little bit jaded and then with gpd3 and then the Lambda transcript I was like re-energized but have also been thinking a lot about you know what are the what are the ethical issues that are going to come up and I think some of the things that companies are really going to have to figure out is obviously algorithmic bias is a huge and known problem at this point like even you know the the new image generation tools like Dolly uh where they've clearly put in a lot of effort to make sure that if you search for people it gives you a diverse set of people Etc like even that one people have already found numerous like ways that it just kind of regurgitates biases of things that it finds on the internet like how if you search for Success it gives you a bunch of images of men if you search for sadness it gives you a bunch of images of women so I think that this is this is like the really tricky one with these voice voice agents that companies are going to have to figure out and that's why it's subtly",
        "start": "02:03:22",
        "duration": 226.12099999999995,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "racist and not overtly because I think they're going to be able to solve the overt thing and then with the subtle stuff it's going to be really difficult and then I think the other thing is going to be yeah like people are gonna become so emotionally attached to artificial agents with this complexity of language with a potential embodiment factor that I mean there's already there's a paper at we robot this year written by roboticists about how to deal with the fact that robots die and looking at it as an ethical issue because it impacts people and I think there's going to be way more issues than just that like like I think that the Tweet was software upgrades right like how much is it okay to charge for something like that if someone is deeply emotionally invested in this relationship oh the ethics of that that's interesting but there's also the practical funding mechanisms like you mentioned with diver the the dog in theory there's a subscription yeah the new IBO so the old IBO from the 90s people got really attached to you and in Japan they're still having like funerals and Buddhist temples for the ibos that can't be repaired because people really viewed them as part of their families so we're talking about robot dogs robot dogs the IBO yeah the the original like famous robot dog that Sony made came out in the 90s got discontinued having funerals for them in Japan now they have a new one the new one is great I have one at home it's like it's three thousand dollars I think it's three thousand bucks and then after a few years you have to start paying I think it's like 300 a year for for a subscription service for cloud services and the cloud services uh that uh I mean it's a lot uh the dog is more complex than the",
        "start": "02:05:19",
        "duration": 219.46099999999996,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "original and it has a lot of cool features and it can remember stuff and experiences and it can learn and a lot of that is outsourced the cloud and so you have to pay to keep that running which makes sense people you know should pay and people who aren't using it shouldn't have to pay but it does raise the interesting question could you set that price to reflect a consumer's willingness to pay for the emotional connection so if if like you know that people are really really attached to these things just like they would be to a real dog could you just start charging more because there's like more demand yeah I mean you have to be but there but that's true for anything that people love right it is and it's also true for real dogs like there's all these new medical services nowadays where people will shout out thousands and thousands of dollars to keep their Pets Alive and is that taking advantage of people or is that just giving them what they want that's that's the question uh back to marriage what about all the money that it costs to get married and then all the money that it costs to get a divorce that feels like a very like uh that's like a scam I think the society is full of scams that are like oh it's such a scam and then we've created like the whole wedding industrial complex has created all these quote unquote Traditions that people buy into that aren't even Traditions like they're just fabricated by marketing like it's awful uh let me ask you about racist robots is it up to a company that creates that so we talk about removing bias and so on yeah and that's a really popular field in AI currently yes and a lot of people",
        "start": "02:07:11",
        "duration": 222.47800000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "agree that it's an important field but the question is for like social robotics is sure to be up to the company to remove the bias of society well who else can oh to remove the bias of society like I guess because there's a lot of people that are subtly racist in modern society like why shouldn't our robots also be subtly racist I mean that's like why do we put so much responsibility on the robots because I'm imagining like a like a Hitler Roomba I mean that that would be funny uh but but I guess I'm asking a serious question yes exactly I'm allowed to make that joke yes and I've been non-stop reading about World War II and Hitler I think um I'm glad we exist in a world where we can just make those jokes um that helps deal with it uh anyway yeah it is a serious question of sort of like um like it's such a difficult problem to solve now of course like bias and so on like there's a little hanging fruit which I think was a lot of people are focused on but then it becomes like subtle stuff over time and it's very difficult to know now if you come if you can also completely remove the personality you can completely remove the personalization you can remove the language aspect which is what I had been arguing because I was like the language is the disappointing aspect of social robots anyway but now we're reintroducing that because it's it's now no longer disappointing so I do think well let's just start with the promise which I think is very true which is that racism is not a neutral thing but it is the thing that we don't want in our society like I it does not conform to my values so if we agree that racism is bad",
        "start": "02:09:01",
        "duration": 224.55999999999995,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "I do think that it has to be the company because the pro I mean it might not be possible and companies might have to put out products that where they're taking risks and they might get slammed by consumers and they might have to adjust I don't know like how this is going to work in the market I have opinions about how it should work but it is on the company and the danger with robots is that they can entrench this stuff it's not like your Racist uncle who you can have a conversation with and put things into context maybe with that yeah or who who might change over time with more experience a robot really just like regurgitates things entrenches them could influence other people and I mean I think that's terrible well I think there's a difficult challenge here is because even the premise you started with that essentially racism is bad um I think we live in a society today where the definition of racism is different between different people some people say that it's not enough not to be racist some people say you have to be anti-racist so you have to you have to have a robot that constantly calls out like calls you out on your uh implicit racism I would love that I would love that robot but like maybe it maybe it's these well I don't know if you love it because maybe you'll you'll see racism and things that aren't racist and then you're arguing with a robot your robot starts going to races I'm not I'm not exactly sure that I mean it's a it's a tricky thing I guess I'm saying that um the line is not obvious especially in this heated discussion where we have a lot of identity politics of what what is harmful to different groups and so on yeah it feels diff it feels like a the broader question here is should a",
        "start": "02:10:57",
        "duration": 249.72000000000003,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "social robotics company be solving or being part of solving the issues of society well okay I think it's the same question as should I as an individual be responsible for knowing everything in advance and saying all the right things and the answer to that is yes I am responsible but I'm not going to get it perfect and then the question is how do we deal with that and so as a person how I aspire to deal with that is when I do inevitably make a mistake because I have blind spots and people get angry I don't take that personally and I listen to what's behind the anger and it can even happen that like maybe I'll tweet something that's well intentioned and one you know one group of people starts yelling at me and then I change it the way that they said and then another group of people starts yelling at me which has happened this this happened to me actually um around in my talks I talk about robots that are used in autism therapy and so whether to say a child with autism or an autistic child is super controversial and a lot of autistic people prefer to be referred to as autistic people and a lot of parents of autistic children prefer child with autism and then there's they disagree so so I've gotten yelled at from both sides and I think I'm still resp I'm responsible even if I can't get it right I don't know if that makes sense like it's a responsibility thing and I'm I can be as well intentioned as I want and I'm still going to make mistakes and that is part of the existing power structures that exist and that's something that I accept and you accept being attacked from both sides and grow from it and learn from it yeah but the the danger is that after being attacked assume you don't get canceled AKA completely removed from your ability",
        "start": "02:13:02",
        "duration": 238.06,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "to to tweet uh you might become jaded and not want to talk about autism anymore I don't and I didn't I mean it's happened to me and that's what I did was I listened to those sides and I chose I tried to get information and then I I decided that I was going to use autistic children and now moving forward with that like I don't know for now right for now yeah until until I get updated information and I'm never gonna get anything perfect but I'm making choices and I'm moving forward because being a coward and like just retreating from that I think but here's the problem you're a very smart person and an individual researcher thinker an intellectual so that's the right thing for you to do the hard thing is one as a company imagine you had a PR team I said Kate like this you should we hate yeah I mean just well if you're If you hired PR people like obviously they would see that and they'd be like well maybe don't bring up autism maybe don't bring up these topics you're you're getting attacked it's bad for your brand they'll say the brand word they'll be uh you know if you look at different demographics that are inspired by your work I think it's insensitive to them let's not mention this anymore like there's this kind of pressure that all of a sudden you or or you do sub-optimal decisions you take a kind of poll um again it's looking at the past versus the future all those kinds of things and it it becomes difficult in the same way that is difficult for social media companies to to figure out like whose sensor who'd recommend this is ultimately a question about leadership honestly like the way that I see leadership because right now the thing that bothers me about institutions and a lot of people who run",
        "start": "02:15:03",
        "duration": 241.00200000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "current institutions is that their main focus is protecting the institution or protecting themselves personally that is bad leadership because it means you cannot have integrity you cannot lead with integrity and it makes sense because like obviously if you're the type of leader who immediately blows up the institution you're leading then that doesn't exist anymore and maybe that's why we don't have any good leaders anymore because they had integrity and they didn't put you know the survival of the institution first but I feel like you have to I just to be a good leader you have to be responsible and understand that with great power comes great responsibility you have to be humble and you have to listen and you have to learn you can't get defensive and you cannot put your own protection before other things yeah take risks where you might lose your job uh you might lose your well-being because of um because for in in the process of standing for the principles for the things you think are right to do yeah based on the things you've like based on learning from like listening to people and learning from what they what they feel and the same goes from the institution yeah yeah but I ultimately actually believe that those kinds of companies and countries succeed that have leaders like that you should run for president no thanks yeah that's maybe the problem like the people who have good ideas about leadership they're like yeah no this is why I don't know why I'm not running a company it's been I think three years since the Jeffrey Epstein controversy at MIT MIT media lab Joy Edo the head of uh the media lab resigned and I think at that time you were an opinion article about it so just looking back a few years have passed what",
        "start": "02:17:05",
        "duration": 243.76300000000006,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "what have you learned about human nature um from the fact that somebody like Jeffrey Epstein found his way inside MIT it's a really good question what have I learned about human nature I think well there's there's how did this problem come about and then there's what was the reaction to this problem and to it becoming public and in the reaction the things I learned about human nature were that sometimes cowards are worse than [ __ ] wow I'm really oh I mean that's a really powerful statement I think because the [ __ ] at least you know what you're dealing with they have integrity in a way they're just living out their [ __ ] values yeah and the cowards are the ones that you have to watch out for and this comes back to people protecting themselves over doing the right thing um they'll throw others under the bus is there some sense that not enough people took responsibility for sure and I mean wanna sugarcoat at all what Joey Ito did I mean I think it's gross that he took money from Jeffrey Epstein I believe him that he didn't know about the bad bad stuff but I've been in those circles with those like public intellectual dudes that he was hanging out with and any woman in those circles like the 10 zillion red flags just the whole environment was so misogynist like and so personally because Joey like was a great boss and a great friend it I was really disappointed that he ignored that in favor of raising money",
        "start": "02:19:07",
        "duration": 228.90200000000004,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "um and I think that it was right for him to resign in the face of that but one of the things that he did that no many others didn't was he came forward about it and he took responsibility and all of the people who didn't I think it's just interesting the other thing I learned about human nature okay I'm gonna go on on a tangent but I'll come back I promise so I once saw this tweet from someone or was a Twitter thread from someone who worked at a homeless shelter and he said that when he started working there he noticed that people would often come in and use the bathroom and they would just trash the entire bathroom like rip things out of the walls like toilet paper on the ground and he asked someone who had been there longer like why do they do this why do the homeless people come in and trash the bathroom and he was told it's because it's the only thing in their lives that they have control over and I feel like sometimes when it comes to the response the just the the mobbing response that happens in the wake of some harm that was caused if you can't Target the person who actually caused the harm who was Epstein you will go as many circles out as you can until you find the person that you have power over and you have control over and then you will trash that and it makes sense that people do this it's again it's a human nature thing of course you're going to focus all your energy because you feel helpless and enraged and you and it's unfair and you have no other power you're going to focus all of your energy on someone who's so far removed from the problem that that's not even an efficient solution and the problem is often the the first person you find is the one that has",
        "start": "02:21:16",
        "duration": 225.96099999999993,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "Integrity sufficient Integrity to take responsibility yeah and it's why my husband always says he's he is a liberal but he's always like when liberals form a firing squad they stand in a circle because you know that your friends are going to listen to you so you criticize them you're not going to be able to convince someone across the aisle but see in that situation what I had hoped is the people in the farther in that situation any situation of that sort the people that are farther out in the circles uh stand up yes and like it also take some responsibility for the broader picture of human nature versus like specific situation but also take some responsibility and um but also defend the people involved as flawed not you know like no no nothing like like this people [ __ ] up like you said there's a lot of red flags that people just ignored for the sake of money in this particular case but also like be transparent in public about it and spread the responsibility across large number of people such that you learn a lesson from it institutionally yeah it was a systems problem it wasn't a one individual problem and I feel like currently because uh Joey took like resigned because of it or essentially fired pressured out because of it uh MIT can pretend like oh we didn't we didn't know anything we wasn't part bad leadership again because when you are at the top of an institution that much power and you were complicit in what happened which they were like come on there's no way that they didn't know that this was happening so I like to not stand up and take",
        "start": "02:23:21",
        "duration": 247.26000000000002,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "responsibility I think it's bad leadership do you understand why Epstein was able to um outside of MIT he was able to make a lot of friends with a lot of powerful people does that make sense to you why was he able to get in these rooms befriend these people but friend people that I don't know personally but I think a lot of them indirectly I know as being good people smart people why would they let Jeffrey Epstein into the into their office have a discussion with them what do you understand about human nature from that well so I never met Epstein or I mean I've met some of the people who interacted with him but I was never like I never saw him in action I don't know how charismatic he was or what that was but I do think that sometimes the simple answer is the more likely one and from my understanding what he would do is he was kind of a grift a social grifter like you know those people who will you must get this because you're famous you must get people coming to you and being like Oh I know your friends so and so in order to get cred with you um I think he just convinced some people who were trusted in a network that he was a great guy and that you know whatever I think at that point because at that point he had had like a what a commission prior but it was a one-off thing it wasn't clear that there was this other thing that was that and most people probably don't check yeah and most people don't check like you're on an event you meet this guy I don't know maybe people do check when they're that powerful and wealthy or maybe they don't I have no idea no they're just stupid I I mean and they're not like all right well like does anyone check",
        "start": "02:25:25",
        "duration": 248.61899999999997,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "anything about me because I've walked into some some of the richest the most popular powerful people in the world and nobody like asks questions like who the [ __ ] is this guy like yeah like nobody asks those questions it's it's interesting I I would think like there would be more security or something like there there it really isn't I think a lot of it has to do well my hope is in my case has to do with like people can sense that this is a good person but if that's the case then they can surely then a human being can use charisma to infiltrate yeah just being just saying the right way of people vouching for you within that type of network like once you yeah once you have someone powerful vouching for you who someone else trusts then you know you're in so how do you avoid something like that if you're MIT if you're Harvard if you're in any of these institutions well I mean first of all you have to do your homework before you take money from someone um like I think I think that's required but I think you know I think Joey did do his homework I think he did and I think at the time that he took money there was the one conviction and not like the later thing and I think that the story at that time was that he didn't know she was underage and lava and or whatever it was mistaken Joey always believed in Redemption for people and that people can change and that they can genuinely regret and like learn and and move on and he was a big believer in that so I could totally see him being like well I'm not gonna exclude him because of this thing and because other people are vouching for him so and just to be clear we're now talking about the set of people who I think Joey belonged to who did not like go to the island and have sex with underage girls",
        "start": "02:27:29",
        "duration": 224.199,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "because that's a whole other set of people who like were powerful and like were part of that Network and who knew and participated and and so like I distinguish between people who got taken in who didn't know that that was happening and people who knew I wonder what the different circles look like so like people that went to the island and then didn't do anything it didn't see anything didn't know about anything versus the people that did something and then there's people who heard rumors maybe and what do you do with rumors like isn't there isn't there people that uh heard rumors about Bill Cosby for the longest time for like for the longest like whenever that happened like all these people came out of the woodwork like everybody kind of knew um I mean this it's like all right so what are you supposed to do with rumors like what uh I think the other way to put is red flags as you were saying yeah and like I can tell you that those circles like there were red flags without me even hearing any rumors about anything ever like I was already like um there are not a lot of women here which is a bad sign isn't there a lot of places where there's not a lot of women and that doesn't necessarily mean it's a bad sign there are if it's like a pipeline problem where it's like I don't know technology law clinic that only gets like male lawyers because there's all there's not a lot of women you know applicants in the pool but there's some aspect of this situation that like there should be more women here oh yeah you've uh actually I'd love to ask you about this because uh you have strong opinions about Richard stallman is that do you still have those strong",
        "start": "02:29:25",
        "duration": 218.199,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "opinions look all I need to say is that he my friend who's a law professor yeah she shook his hand and he licked her arm from wrist to elbow and it certainly wasn't appropriate at that time what about if you're like an incredibly weird person okay the lot of Divergence and everywhere yes we need to accept that people are different that people don't understand social conventions the same way but one of the things that I've learned about neurodivergence is that women are often expected or taught to mask their neurodivergence and kind of fit in and men are accommodated and excused and I don't think that being neurodivergent gives you a license to be an [ __ ] like you can be a weird person and you can still learn that it's not okay to lick someone's arm yeah there's it's a balance like women should be allowed to be a little weirder and men should be less weird because I think I think there's uh because I you're one of the people I think tweeting that what made me because I wanted to talk to Richard Stoneman on the podcast about because I didn't have a context because I wanted to talk to him because he's you know free software he's very weird in interesting good ways in the world of computer science he's also weird in that you know when he gives a talk he'll be like uh like picking at his feet and eating the skin off his feet right that he's known for these extremely kind of how else do you put it I don't know how to put it but then there was um something that happened to him in conversations on this thread related to Epstein yeah which I was torn about because I felt it's similar to Joy uh",
        "start": "02:31:19",
        "duration": 239.10000000000008,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "you know it's like I felt he was maligned like uh people were looking for somebody to get angry at so he he was inappropriate but the um I didn't like the cowardice more like I I set aside his his situation and we could discuss it but the the cowardice on mit's part and this is me saying it about the way they treated that whole situation oh they're always copied anything they should try to make the problem go away yeah so that it was it was about yeah exactly making the conversation I think he should have left the mailing they shouldn't have he shouldn't have been part of the mailing well that's probably true also but I think I think what what bothered me what always bothers me in these mailing list situations or Twitter situations like if you say something [Music] that's hurtful to people or makes people angry and then people start yelling at you maybe they shouldn't be yelling maybe they are yelling because again you're the only point of power they have maybe maybe it's okay that you're yelling whatever it is like it's your response to that that matters and I think that I just have a lot of respect for people who can say oh people are angry there's a reason they're angry let me find out what that reason is and learn more about it it doesn't mean that I'm wrong it doesn't mean that I'm bad doesn't mean that I'm ill-intentioned but why are they angry I want to understand and then once you understand you can respond again with integrity and say actually I stand by what I said here's why or you can say actually I listened",
        "start": "02:33:23",
        "duration": 219.45900000000003,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "and here are some things I learned that's the kind of response I want to see from people and people like stallman do not respond that way they just like go into battle right like where it's obvious you you didn't listen yeah no not just in listening honestly that's to me as bad as the people who just apologize just because they are trying to make the problem go away of course all right so like if that's not supposed to be bad a good apology has to include understanding what you did wrong and in part standing up for the things you think you did right so yeah if there are those things yeah finding and then but you have to give you have to acknowledge you have to like give that hard hit to the ego that says I did something wrong yeah that definitely Richard stalma is not somebody who's capable of that kind of thing or hasn't given evidence of that kind of thing um but that was also even just your tweet I had to do a lot of thinking like different people from different walks of life see red flags and different things yes and so things I find um as a as a man non-threatening and hilarious are not necessarily um doesn't mean that they're aren't like deeply hurtful to others and I don't mean that in the social justice Warrior way but in a in a in a real world like people really have different experiences so I have to like really put things into context um I have to kind of listen to what people are saying put aside the emotion of what their emotion will do what you're saying it and try to keep the the facts of their experience and learn from it and because it's not just about the individual experience either it's not",
        "start": "02:35:14",
        "duration": 226.781,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "like oh you know my friend didn't have a sense of humor about being licked it's that she's been she's been metaphorically licked you know 57 times that week because she's an attractive law professor and she doesn't get taken and so like men walk through the world and it's impossible for them to even understand what it's like to have a different experience of the world and that's why it's so important to listen to people and believe people and believe that they're angry for a reason maybe you don't like their tone maybe you don't like that they're angry at you maybe you get defensive about that maybe you think that they should you know explain it to you but believe that they're angry for a reason and try to understand it yeah there's a deep truth there uh and an opportunity for you to become a better person can I ask you a question why haven't you been doing that for two hours three hours now uh let me ask you about uh Elaine Maxwell she's been saying that she's an innocent victim uh is she an innocent victim or is she uh evil and equally responsible like Jeffrey Epstein now I'm asking far away from any MIT things and more just your sense of the whole situation I haven't been following it so I don't know the facts of the situation and like what is now like known to be her role in that if I were her clearly I'm not but if I were her I wouldn't be going around saying I'm an innocent victim I would say maybe she's I don't know what she's saying again like I don't know she was controlled by Jeffrey is she saying this as part of a legal case or is she saying this as like a PR thing uh well PR but it's not just her it's our whole family believes this there's uh there's a whole effort that says like that",
        "start": "02:37:09",
        "duration": 226.43899999999996,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "how should I put it I believe they believe it so in that sense it's not PR I I believe the family the basically the family is saying that she's a good she's a really good human being well I think everyone is a good human being I know it's a controversial opinion but I think everyone is a good human being there's no evil people there's people who do bad things and who behave in ways that harm others and I think we should always hold people accountable for that but holding someone accountable doesn't mean saying that they're evil yeah actually those those people usually think they're doing good yeah I mean aside from I don't know maybe sociopaths like are specifically trying to like harm people but I think most people are trying to do their best and if they're not doing their best is because there's some impediment or something in their past so I I just I genuinely don't believe in good and evil people but I do believe in like harmful and not harmful actions and so I don't know like I don't care I don't care yeah she's a good person but if she contributed to harm then she needs to be accountable for that like that's my position I don't know what the facts of the matter are it seems like she was pretty close to the situation so it doesn't seem very believable that she was a victim but I don't know I wish I have met Epstein because something tells me he would just be a regular person a charismatic person like anybody else and that's a very dark reality that we don't know which Among Us what what each of us are hiding in the closet that's a really tough thing to like deal with because then you can put your trust into some people and they can completely betray that",
        "start": "02:39:08",
        "duration": 223.04100000000003,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "trust and in the process destroy you yeah which is a lot of people that interacted with Epstein then now have to I mean if they're not destroyed by it then they're they that their whole like the ground on which they stand ethically is is has crumbled at least in part and you I'm sure I'm sure you and I have interacted with people without knowing it who are bad people people who have done bad things because I was talking about bad guys I'm trying to move them towards they're just people who make bad choices yeah that's really powerful actually that's really important to remember because that that means you have compassion towards all human beings um do you have hope for the future of MIT a future of media lab in this context uh so David Newman is now at the helm I'm gonna talk I talked to a priest I'll talk to her again she's great love her yeah she's great I don't know if she knew the whole situation when she started because the situation went beyond just the Epstein Scandal a bunch of other stuff happened at the same time some of it's not public um but my what I was personally going through at that time so the Epstein thing happened I think was it August or September 2019 it was somewhere around late summer in June 2019 so I'm I'm a research scientist at MIT you are too right so and I always have had various supervisors uh you know over the years and they've just basically let me do what I want which has been great but I had a supervisor at the time and he called me into his office for regular check-in",
        "start": "02:41:03",
        "duration": 228.46100000000007,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "in June of 2019 I reported to MIT that my supervisor had grabbed me pulled me into a hug wrapped his arms around my waist and started massaging my hip and trying to kiss me kiss my face kiss me near the mouth um and said literally the words don't worry I'll take care of your career um and that that experience was really interesting because I just I was very indignant I was like he can't do that to me doesn't he know who I am and I was like this is the me too era and I naively thought that when I reported that it would get taken care of and then I had to go through the whole reporting process at MIT and I learned a lot about how institutions really handle those things internally um particularly situations where I couldn't provide evidence that it happened I had no reason to lie about it but I had no evidence and so I was going through that and that was another experience for me where there's so many people in the institution who really believe in protecting the institution at all costs and there's only a few people who care about doing the right thing and one of them resigned and now there's even less of them left so so what did you learn from that I mean where is the source if you have hope for this institution that I think you love at least in part I I love the idea of MiG I love the idea I love the research body I love a lot of the faculty I love the students the students I love the energy like I love it all I think the administration suffers from the same problems as any institutional any leadership of an",
        "start": "02:43:00",
        "duration": 226.51800000000003,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "institution that is large which is that they've become risk-averse like you mentioned they care about PR the only ways to get their attention or change their minds about anything or to threaten the reputation of The Institute or to have a lot of money that's the only way to have power at the Institute um yeah I don't think they I don't think they have a lot of Integrity or believe in ideas or even have a lot of connection to the research body and like the people who are really because it's so weird you have this amazing research body of people pushing the boundaries of things who aren't afraid to like there's the hacker culture and then you have the administration and they're really like protect the institution at all costs yeah there's your disconnect right completely I wonder if that was those there if it just kind of slowly grows over time a disconnect between the administration The Faculty I think it grew over time is what I've heard I mean I've been there for 11 years now I don't know if it's gotten worse during my time but I've heard from people who've been there longer that it didn't know like MIT didn't used to have a general counsel's office they didn't used to have all this corporate stuff and then they had to create it as they got bigger and in the era where such things are I guess deemed necessary see I believe in the power of individuals to like overthrow the thing so it's just a really good president of MIT or certain people in the administration can reform the whole thing because the the culture is still there of like I think everybody remembers that MIT is about the students and the faculty do they though because",
        "start": "02:44:56",
        "duration": 220.79799999999994,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "I've had a lot of conversations that have been shocking with like senior Administration they think the students are children they call them kids it's like these are the smartest people they're way smarter than you yeah and you're so dismissive but those individuals I'm saying like the the capacity like the aura of the place still values this the students and the faculty like I I'm not I'm being awfully poetic about it but what I mean is the administration is the um the froth at the top of the like the waves the surface like they can be removed and New Life can be brought in that would keep to the spirit of the place who decides on who to bring in who's oh I see uh I see but I I do think ultimately especially in the era of social media and so on um faculty and students have more and more power there's more more of a voice I suppose I hope so I really do I don't see MIT going away anytime soon and like I also don't think it's a terrible place at all yeah it's an amazing place and it's a but there's different trajectories you can take yeah and like and that has to do with a lot of things including um does it is it stays even if we talk about robotics it could be the capital of the world in robotics but currently if you want to be doing the best AI work in the world you're going to go to Google or Facebook um or Tesla or apple or so on you're not going to be you're not going to be in MIT and so that that has to do I think that's basically has to do with um not allowing the the Brilliance of the researchers to flourish yeah people say it's about money but I",
        "start": "02:46:53",
        "duration": 244.86,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "don't think it's about that at all like sometimes you have more freedom and can work on more interesting things in companies that's what really where they lose people yeah and some the the freedom in all in in all ways which is why it's heartbreaking to get like people like Richard stallman there's such an interesting line because like Christians Thomas a gigantic weirdo that cross lines you shouldn't across right but we don't want to draw too many lines this is the tricky thing there are different types of lines in my opinion but just your opinion because you have strong lines you hold through but then if Administration listens to every line there's there's also power in drawing a line like and there's it becomes like a little drug you have to find the right balance licking somebody's arm is never appropriate I think the biggest aspect there is not uh owning it learning from a growing from it from a perspective a stallman or people like that uh back when it happened like understanding seeing the being empathetic seeing the the fact that this was like totally inappropriate uh like not when that particular act but everything that led up to it too no I think there are different kinds of lines I think they're a lot so Stone and crossed lines that essentially excluded a bunch of people and created an environment where we their Brilliant Minds that we never got the benefit of because he made things feel gross or even unsafe for people there are lines that you can cross where you're challenging an institution to like I don't think he was intentionally trying to cross a line or maybe maybe he didn't care there are lines that you can cross intentionally to move something",
        "start": "02:48:55",
        "duration": 235.52199999999996,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "forward or to do the right thing like when MIT was like you can't put an all-gender restroom in the media lab because like something permits whatever and Joey did it anyway that's a line you can cross to make things actually better for people and the line you're Crossing is some arbitrary stupid rule that people who don't want to take the risk or like yeah for sure you know what I mean no ultimately I think the thing you said is like cross lines in a way that doesn't uh uh alienate others so like for example me weren't I started for a while wearing a suit often at MIT which sounds counter-intuitive but that's actually um I people always looked at me weird for that MIT created this culture specifically the people I was working with like nobody wore a suit maybe the business don't trust the suits I was like [ __ ] you I'm wearing the suit but that's not really hurting anybody right exactly um it's challenging people's perceptions it's doing something that you want to do yeah but it's not hurting people and and that that particular thing was um yeah it's hurting people it's a good line that's a good line to like hurting ultimately the people that you want to flourish yeah yeah you tweeted a picture of a pumpkin spice Greek yogurt and asked uh grounds for divorce yes no so let me ask you what's what's the key to a successful relationship oh my God a good couple therapist what uh what went wrong with the pumpkin spice Greek yogurt what's exactly what's wrong is it the pumpkin is it the Greek I don't understand that tweet for a while I grew up in Europe so I don't understand the pumpkin spice in everything craze that they do every",
        "start": "02:50:57",
        "duration": 228.238,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "Autumn here like I understand that it might be good in some foods but they just put it in everything and it doesn't belong in Greek yogurt I mean I was just being humorous I ate one of those yogurts and I actually tasted pretty good so I think part of the success of a good marriage is like giving each other a hard time humorously for things like that is there a broader lesson because you guys seem to have a really great marriage from the external I mean every marriage looks good from the external every I think yeah that's that's not true but yeah okay relationships have hard relationships with anyone are hard actually because people evolve and change and you have to make sure there's space for both people to evolve and change together and I think one of the things that I really liked about are marriage vows was I remember before we got married Greg at some point like got kind of nervous and he was like it's just it's such a big commitment to commit like to something for life and I was like we're not committing to this for life and he was like we're not and I'm like no like we're committing to being part of a team and doing what's best for the team what's best for the team is to break up we'll break up like I don't believe in this like we have to do this for our whole lives and that really resonated with him too so yeah did you put in the well yeah those are vows like that we're just we're gonna be a team you're a team and do what's right for the team yeah yeah that's very like Michael Jordan view uh uh do you guys get like married in the in the desert like November Rain Style with Slash playing or",
        "start": "02:52:54",
        "duration": 225.93999999999997,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "you don't have to answer that I'm not good at these questions okay you've brought up marriage like eight times are you trying to hint something on the podcast you have an announcement to make no what I don't know it just seems like a good metaphor for why why why what it felt like a good metaphor for in a bunch of cases for the uh marriage industrial complex I remember that um and oh people complaining it just seemed like marriage is one of the things that always surprises me because I want to get married you do yeah I do and then I I listen to like friends of mine that complain not all I like I like guys I really like guys that don't complain about their marriage it's such a cheap like if it's such a cheap release valve like it doesn't that's bitching about anything honestly that's just like it's too easy but especially like [ __ ] about the sports team or the weather if you want but like about somebody that you're dedicating your life to like if you [ __ ] about them you're going to see them as a lesser being also like you don't think so but you're going to like decrease the value you have I I personally believe over time you're not going to appreciate the magic of that person I think anyway but it's like that I just noticed this a lot that people are married and they will whine about you know like the wife uh whatever you know this this cut is part of the sort of the culture to kind of uh comment in that way I think women do the same thing about the husband uh he doesn't he never does this or he's a goof he's incompetent at this or that whatever they there's a kind of yeah there's those tropes like oh you know husbands never do X and like wives or I know I think those do a disservice to everyone is just disrespectful to everyone involved yeah but it happens so",
        "start": "02:54:51",
        "duration": 235.84099999999984,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "yeah I was and brought that up as an example of something that people actually love but they complain about because for some reason that's more fun to do is complain about stuff yeah and so that's what with clippy or whatever right so like you complain about but you actually love it there you go it's just a good metaphor that you know um what was I going to ask you uh oh you uh your hamster died when I was like eight you miss her beige um what's the closest relationship you've had with a pet not the one what we didn't have a lot of robot have you loved the most in your life I think my my first pet was a goldfish named Bob and he died immediately and that was really sad [Laughter] I think I think it was really attached to Bob and Nancy my goldfish we got new Bobs and then Bob kept dying and we got new bulbs Nancy just kept living so it was very replaceable yeah I was young it was easy do you think there will be a time when the robot like in the movie Her be something we fall in love with romantically oh yeah oh for sure yeah at scale like we're a lot of people romantically I don't know if it's gonna happen at scale I think we talked about this a little bit last time on the podcast too where I think we're just capable of so many different kinds of relationships and actually part of why I think marriage is so tough as a relationship is because we put so many expectations on it like your partner has to be your best friend and you have to be sexually attracted to them and they have to be a good co-parent and a good roommate and like",
        "start": "02:56:51",
        "duration": 227.496,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "all the relationships at once that have to work but we're like normally with other people we have like one type of relationship but we even have we have a different relationship to our dog than we do to our neighbor than we do to the you know person out someone a co-worker I think that some people are gonna find romantic relationships with robots interesting it might even be a widespread thing but I don't think it's gonna replace like human romantic relationships I think it's just gonna be a separate type of thing it's gonna be more narrow more narrow or even like just something new that we haven't really experienced before maybe like having a crush on an artificial agent is a different type of Fascination I don't know people would see that as cheating I think people well I mean the things that people feel threatened by in relationships are very manifold so yeah that's just an interesting one because uh maybe gel maybe it'll be good A little jealousy for the relationship maybe they'll be like part of the couple's therapy you know kind of thing or whatever think jealousy I mean I think it's hard to avoid jealousy but I think the objective is probably to avoid I mean some people don't even get jealous when their partner sleeps with someone else like there's polyamory and um yeah I think there's just such a diversity of different ways that we can structure relationships or view them that this is just going to be another one that we add you dedicate your book to your dad what did you learn about life from your dad oh man my dad is",
        "start": "02:58:52",
        "duration": 216.96,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "he's a great listener and he is the best person I know at um the type of cognitive empathy that like perspective taking so not like emotional like crying empathy but trying to see someone else's point of view and trying to put yourself in their shoes and he really instilled that in me from an early age and then he made me read a ton of Science Fiction which probably led me down this path uh taught you how to be curious about the world and how to be open-minded yeah last question what role does Love play in The Human Condition so this one been talking about love and robots How uh and you're fascinated by social robotics it feels like all of that operates in the landscape of something that we can call love love yeah I think there are a lot of different kinds of love I feel like it's we need I'm like don't the eskimos have all these different words for snow we need we need more words for to describe different types and kinds of love that we experience but I think love is so important and I also think it's not zero-sum that's the that's the really interesting thing about love is that you know I had one kid and I love loved my first kid more than anything else in the world and I was like how can I have a second kid and then love that kid also I'm never gonna love it as much as the first but I love them both equally it's just like my heart expanded and so I think that people who are threatened by love towards artificial agents they don't need to be threatened for that reason artificial agents will just if Done Right will just expand your capacity for love I think so I agree beautifully put okay this is awesome I still didn't talk about half",
        "start": "03:00:39",
        "duration": 245.81899999999996,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    },
    {
        "text": "the things I want to talk about but we're already like way over three hours so thank you so much I really appreciate you talking today you're awesome you're an amazing human being a great roboticist great writer now it's an honor that you would talk with me thanks for doing it right back at you thank you thanks for listening to this conversation with Kate Dowling to support this podcast please check out our sponsors in the description and now let me leave you with some words for Maya Angelou courage is the most important of all the virtues because without courage you can't practice any other virtue consistently thank you for listening and hope to see you next time",
        "start": "03:02:44",
        "duration": 80.081,
        "title": "Kate Darling: Social Robots, Ethics, Privacy and the Future of MIT | Lex Fridman Podcast #329"
    }
]