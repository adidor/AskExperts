[
    {
        "text": "like buses AI news can sometimes be slow and sometimes arrive all at once in the last few days we have had dramatic new leaked insights into the sheer breadth of Google's Gemini just today we've had the release of meta's code Lama and earlier their impressive multilingual seamless m4t model and last but definitely not least this 88 page AI Consciousness report and yes I read it all it's juicy so I'm saving that for the end but let's start with two major pay World articles one from the information and one from the New York Times about Google's Gemini model from both of them I counted a total of nine New Revelations so let's get straight to it to give you a sense of timeline by the way Google's newly merged AI SWAT team they call it is preparing for a big fall or Autumn launch the takeaway for me from both articles is that Gemini is going to be the everything model did you know it's going to be the Rival to Mid journey and stable diffusion mid Journey only has 11 full-time staff so it is more than plausible that Google's Gemini could outperform mid Journey version 5 next we may be able to create graphics with just text descriptions and Control software using only text or voice commands these next two are speculations so I'm not even counting them in the list of leaks I've already covered in a previous video that Gemini has been trained on YouTube video transcripts and the speculation is that by integrating video and audio into Gemini it could perhaps help a mechanic diagnose a problem with a car repair based on a video or be a rival to Runway ml by generating Advanced text a video based on descriptions of what a user wants to see you can start to see why I'm beginning to think of it as the everything model another leak is that one of the co-founders of Google Sergey Brin is working on on the front lines of Google Gemini and lastly from this article I found it really interesting",
        "start": "00:00:00",
        "duration": 249.96099999999998,
        "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper"
    },
    {
        "text": "that Google's lawyers have been closely evaluating the training and they made researchers remove training data that had come from textbooks even though those textbooks helped the model answer questions about subjects like astronomy or biology and I do wonder if they privately benchmarked Gemini before removing that crucial textbook data but if that's not enough prepare to also receive life advice my theory here is that Google wants to compete directly for market share with inflections Pi what if you want scientific creative or professional writing Yep they're working on that too in fact we already know that Google has software named Genesis that they're pitching to the New York Times which can generate news articles rewrite them suggest headlines Etc but some people will be more interested in this feature that Google deepmind is working on the ability to draft critiques of an argument and generate quizzes word and number puzzles it's almost easier at this point to ask what might Google Gemini not be able to do and yes this is not Gemini but Google Deep Mind is also using AI to design the next generation of semiconductors but if the fall seems far away how about today when we got code llama from meta I spent much of the last 2 hours reading most of the 47 page paper and you can see code llama in action on screen some highlights include that the code llama models provide stable generations with up to 100,000 tokens of context obviously that could be used for generating longer programs or providing the model with more context from your codebase to make the generations more relevant it comes in three versions code llama code llama instruct which can better understand natural language instructions and code llama python better of course at python it's available for commercial use and as you can see some of the versions rival GPT 3.5 on human eval that top score of 53.7% on pass at one puts it in the same",
        "start": "00:02:05",
        "duration": 240.079,
        "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper"
    },
    {
        "text": "ballpark as 51 I've actually done a full video on 51 so do check that out but that got 50.6% but it is about 25 times smaller at 1.3 billion parameters interestingly the code llama paper which also came out about 2 hours ago mentions F1 directly saying that it follows in a similar Spirit but the difference is that fi1 is closed Source anyway a couple more interesting things before we move on from code llama and the first one is the self- instruct method that they use let me know if you also find this fascinating because step one was to generate 62,000 interview style programming questions by prompting llama 2 the 70 billion parameter model then they removed duplicates in step two but here's where it gets interesting for each of those questions they first generated a unit test by prompting code llama 7 billion parameters then they generated 10 python solutions by prompting code llama finally they ran unit tests on those 10 Solutions and they added the first solution that passes those tests along with the corresponding question and test to the self- instruct data set if that sounded a bit complicated let me try to distill it a bit they asked the Big Brother llama 2 model to generate questions then got the little brother code llama to generate tests for those questions then got the model to generate solutions to its own tests found the good solution that don't forget it produced and then use those to further train the model to be honest synthetic data and self-instructed back one final interesting quote from the paper on safety and that was an argument Advanced by one of their red teamers they made the point that various scripts and code is readily available on mainstream public websites hacking forums or the dark web and the advanced malware development is beyond the current capabilities of available l LMS and even",
        "start": "00:04:05",
        "duration": 227.39999999999992,
        "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper"
    },
    {
        "text": "an advanced llm paired with an expert malware developer is not particularly useful at the moment as the barrier is not typically writing the malware code itself let me know what you think in the comments but we must move on to seamless m4t released a couple of days ago from meta which frankly seems amazing for multilingual translation that's Speech to Text Speech to speech text to text and more it has speech recognition for nearly 100 languages and can output in 36 languages but there's one feature I find particularly cool now let's talk about code switching code switching happens when a multilingual speaker switches between languages while they are speaking our model seamless M4 automatically recognizes and translates more than one language when mixed in the same sentence as a multilingual speaker this is a very exciting capability for me I often switch from Hindi to delu when I speak with my dad notice in the following example when I change languages Hindi I can speak Hindi tuug and English sometimes I use all three languages in one conversation speaking of cool though we had this epic story out yesterday AI gave a paralyzed woman her voice back in a moment you're going to see her being plugged in to the model there we go and the short version is that this woman suffered a stroke that left her unable to speak but now for the first time her speech and facial expressions can be synthesized from her brain signals decoding these signals into text at nearly 80 words per minute up from 14 words per minute but let's now end on this an 88 page report on Consciousness in artificial intelligence which counts as one of its co-authors Yoshua Benjo the touring Award winner it was dense and quite technical but well worth the read look at this sentence in just the abstract our analysis suggests that no current AI systems are conscious but",
        "start": "00:06:00",
        "duration": 255.08099999999993,
        "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper"
    },
    {
        "text": "also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators these are the IND indicators and each one gets a few pages in the report and the reason that they're split up is because each one rests on a certain Theory Of Consciousness obviously the key problem is that we don't have a consensus theory on what Consciousness is or how it comes about so in a way to hedge their bets they group in different theories and look at the kind of indicators that would satisfy each one you might say that list seems so theoretical why not just test the model or even ask the model for more on that approach see my theory of Mind video but the problem is as they say on page four the main alternative to a theory heavy approach is to use behavioral tests for Consciousness but as I talked about in the other video that method is unreliable because AI systems can be trained of course they are to mimic human behaviors are working actually in very different ways essentially llms have broken the traditional tests for Consciousness including of course the touring test test the paper also rests on the Assumption of computational functionalism essentially that computations are essential for Consciousness as in it's not What You're Made Of it's what you do if this is wrong and the substrate in fact is key say biological cells then it stands the reason that AI would never be conscious but one of their early conclusions is that if computational functionalism is true and it is widely believed conscious AI systems could realistically be built in the near term having digested the ENT entire paper they're strongly suggesting that we're not there yet but if this theory is true we could be there especially if researchers deliberately designed systems to meet these criteria in fact here is a key quote from one of the authors in science that came along",
        "start": "00:08:20",
        "duration": 227.479,
        "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper"
    },
    {
        "text": "with the piece it would be trivial to design all of these features into an AI the reason no one has done so is it is not clear that they would be useful for tasks now to be honest it is way beyond my pay grade to try to explain every aspect of the paper but I'm going to try my best to convey the key bits first what is the definition of Consciousness that they are working with well skipping the jargon they essentially say if you are reading this report on a screen you are having a conscious visual experience of the screen that is separated from sentience which is also sometimes used to mean being capable of pleasure or pain and they say that it's possible for a system to be sentient without being conscious by sensing its body or environment and it's possible for a system to be conscious without sensing its body or environment it also might be possible to be slightly conscious or conscious to a greater degree than humans Ilia satova famously said it may be that today's large neural networks are slightly conscious and Carl Schulman and Nick Bostrom wrote an entire chapter of a book on the possibility that models become more conscious than human beings they say such beings could contribute immense value to the world and failing to respect their interests could produce a moral catastrophe one of the theories of Consciousness discussed is recurrent processing Theory and here is the key part of that theory One initial feedforward sweep of activity through the hierarchy of visual areas is sufficient for some visual operations like extracting features from a scene but not sufficient for conscious experience however when the stimulus is sufficiently strong or Salient we get this looped recurrent processing in which signals are sent back from higher areas to lower ones it's only then that you get a conscious representation of an organized scene the paper then draws indicators based on each theory for",
        "start": "00:10:14",
        "duration": 230.39999999999998,
        "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper"
    },
    {
        "text": "example if current processing theory is accurate then here are two indicators that something would be conscious they then draw analogies for each Theory to AI systems for example on recurrence specifically algorithmic recurrence they say that's a weak condition that many AI systems already meet but don't forget when they say that it's an analogy not only does it require the theory to be correct it requires the analogy to hold true I is the recurrence that we see in AI a good analogy for the recurrence of this Theory or what about the next one Global workspace theory if that theory is correct here are four indicators of something being conscious according to that theory to be honest if you are at all interested in Consciousness the pages on each one of these taught me a lot about test for Consciousness and just theories of Consciousness again let's just say that theory is correct do AI systems demonstrate these indicators do they have modules that can work in parallel and a global workspace at the center is that workspace bandwidth limited requiring the compression and selection of information from the modules well here again we can only rely on analogies in this case to the Transformer architecture they say in a sense they do have modules they do have a limited capacity workspace introducing a bottleneck but then the authors introduce plenty of points about how the analogy is not perfect even here of course you can pause and read the details if you like or indeed read the entire paper so that's the tone of the paper if silicon can be a replacement to carbon and if these analogies hold then there is a strong case that most or all of the conditions for Consciousness suggested by current computational theories can be met using existing Tech techniques in AI this is not to say that current AI systems are likely to be conscious there is also the issue of whether they combine existing techniques",
        "start": "00:12:09",
        "duration": 231.92,
        "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper"
    },
    {
        "text": "in the right ways but it does suggest that conscious AI is not merely a remote possibility in the distant future and here is the key bit if it is at all possible to build conscious AI systems without radically new hardware it may be possible now of course even if all of those conditions and analogies hold it may not be the same type of Consciousness as our Consciousness it seems possible that say to imagine a conscious being that had only a succession of brief static discret experiences perhaps just during pre-training or they might have experiences without feeling that they are a persisting subject but my own summary is this we clearly don't fully understand Consciousness or what is required for Consciousness we don't know if Consciousness in AI systems is theoretically impossible or imminent the authors actually quote this open letter from the association for math ma matical Consciousness science and in it at the end the letter says we emphasize that the rapid development of AI is exposing the urgent need to accelerate research in the field of Consciousness science even if we develop a system that ticks all of these indicators and trust me someone is probably working on that right now we still won't know for sure and many people will deny forever that that system is conscious I'm not claiming I have the answer by the way I have absolutely no idea if these systems are imminently conscious already conscious or will never be conscious all I can say is that it's a bit less sci-fi than many people believe and the authors also point out two risks under attributing Consciousness to AI playing down the possibility but they also point out the risk of over attributing Consciousness to AI on under attributing Consciousness they say this given the uncertainties about Consciousness mentioned above we may create conscious AI systems long before we recognize that",
        "start": "00:14:05",
        "duration": 216.91900000000004,
        "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper"
    },
    {
        "text": "we have done so and I see this sentence as a fateful prediction this tendency is further Amplified when AI systems exhibit humanlike characteristics such as natural language processing which they already do but also facial expressions or adaptive learning capabilities so imagine what people are going to think when photorealistic AI avatars are everywhere and finally there is the risk of experimentation itself on balance we believe that research to better understand the mechanisms which might underly Consciousness in AI is beneficial however of course research on this topic runs the risk of building or enabling others to build a conscious AI system which should not be done lightly and that mitigating this kind of risk should be carefully weighed against the value of better understanding Consciousness in Ai and to tie this back to the start of the video Google's AI safety experts have added that some users who grew too dependent on this technology could think it was sentient and I do wonder if that's an eventuality Google's newly merged AI SWAT team is preparing for as always thank you so much for watching to the end and have a wonderful day oh and just quickly before I end I now have a Discord AI explain Community more info in the description",
        "start": "00:15:54",
        "duration": 146.88200000000003,
        "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper"
    }
]