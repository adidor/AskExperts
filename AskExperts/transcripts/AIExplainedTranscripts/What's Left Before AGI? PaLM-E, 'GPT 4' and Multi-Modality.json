[
    {
        "text": "palm e was released less than a week ago and for some people it may already be old news sure it can understand and manipulate language images and even the physical world the e at the end of palm e By the way stands for embodied but soon apparently we're gonna get the rebranded gbt4 which many people think surely will do better and be publicly accessible but the multi-modal advancements released just this week left me with a question what tasks are left before we call a model artificial general intelligence or AGI something Beyond human intelligence I didn't want hype or get rich schemes I just wanted clear research about what exactly comes before AGI let's start with this four day old statement from anthropic a four billion dollar startup founded by people who left open AI over safety concerns they outlined that in 2019 it seemed possible that multi-modality like Army logical reasoning speed of learning transfer learning across tasks and long-term memory might be walls that would slow or halt the progress of AI in the years since several of these walls such as multi-modality and logical reasoning have fallen what this means is that the different modes of palm e and Microsoft's new visual Chaturbate text image video aren't just cool tricks they are major Milestones palm e can look at images and predict what will happen next check out this robot who's about to fall down that's just an image but ask palmy what will the robot do next and it says fall it knows what's going to happen just from an image it can also read faces and answer natural language questions about them check out Kobe Bryant over here it recognizes him from an image and you can ask questions about his career this example at the bottom I think is especially impressive palm e is actually doing the math from this hastily sketched chalkboard it's solving those classic math problems that we all got at school just from an image now",
        "start": "00:00:00",
        "duration": 246.83999999999995,
        "title": "What's Left Before AGI? PaLM-E, 'GPT 4' and Multi-Modality"
    },
    {
        "text": "think about this palm e is an advancement on gato which at the time the lead scientist at deepmind Nando de Freitas called game over in the search for AGI someone had written an article fearing that we would never achieve AGI and he said game over all we need now are bigger models more compute efficiency smarter memory more modalities Etc and that was gato not palmy of course you may have noticed that neither he nor I am completely defining AGI that's because there are multiple definitions none of which satisfy everyone but a broad one for our purposes is that AGI is a model that is at or above the human level on a majority of economic tasks currently done by humans you can read here some of the tests about what might constitute AGI that's enough about definitions and multi-modality time to get to my central question what is left before AGI well what about learning and reasoning this piece from Wired Magazine in late 2019 argued that robust machine reading was a distant Prospect it gives a challenge of a children's book that has a cute and quite puzzling series of interactions it then states that a good reading system would be able to answer questions like these and then give some natural questions about the passage I will say these questions do require a degree of logic and Common Sense reasoning about the world so you can guess what I did I put them straight into Bing where only three and a half years on from this article and look what happened I pasted in the exact questions from the article and as you might have guessed Bing got them all right pretty much instantly so clearly my quest to find the tasks that are left before AGI would have to continue just quickly before we move on from Bing and Microsoft products what about specifically gpt4 how will it be different from Bing or is it already inside being as many people think the much quoted German CTO of Microsoft",
        "start": "00:02:03",
        "duration": 237.23899999999998,
        "title": "What's Left Before AGI? PaLM-E, 'GPT 4' and Multi-Modality"
    },
    {
        "text": "actually didn't confirm that gpt4 will be multimodal only saying that at the Microsoft events this week there we will have multi-modal models that's different from saying gpt4 will be multimodal I have a video on the eight more certain upgrades inside GT4 so do check that out but even with those upgrades inside gbt4 the key question remains if such models can already read so well what exactly is left before AGI so I dove deep in the literature and found this graph from the original palm model which palm e is based on look to the right these are a bunch of tasks that the average human rater at least those who work for Amazon Mechanical Turk could beat palmat in 2022 and remember these were just the average rators not the best the caption doesn't specify what the tasks are so I looked deep in the appendix and found the list of tasks that humans did far better on than Palm here is that appendix and it doesn't make much sense when you initially look at it so what I did is I went into the big bench data set and found each of these exact tasks remember these are the tasks that the average human raters do much better at than Palm I wanted to know exactly what they entailed looking at the names they all seem a bit weird and you're going to be surprised at what some of them are take the first one mnist ASCII that's actually representing and recognizing ASCII numerals hmm now I can indeed confirm that Bing is still pretty bad at this in terms of numerals and in terms of letters I'm just not sure how great an accomplishment for Humanity this one is though so I went to the next one which was sequences as you can see below this is keeping track of time in a series of events this is an interesting one perhaps linked to GPT models struggles with mathematics and it's lack of an internal calendar I tried the same question multiple times with Bing and Chaturbate and only once out of about a dozen attempts did it get the question",
        "start": "00:04:01",
        "duration": 256.979,
        "title": "What's Left Before AGI? PaLM-E, 'GPT 4' and Multi-Modality"
    },
    {
        "text": "right you can pause the video and try it yourself but essentially it's only between four and five that he could have been at the swimming pool you can see here the kind of convoluted logic that Bing goes into so really interesting this is a task that the models can't yet do again I was expecting something a bit more profound but let's move on to the next one simple text editing of characters words and sentences that was strange what does it mean text editing can't Bing do that I gave Bing many of these text editing challenges and it did indeed fail most of them it was able to replace the letter t with the letter P so it did okay with characters but it really doesn't seem to know which word in the sentence something is you can let me know in the comments what you think of these kind of errors and why Bing and chat gbt keep making them the next task that humans did much better on was hyperbaton or intuitive adjective order it's questions like which sentence has the correct adjective order an old-fashioned circular leather exercise car sounds okay or a circular exercise old-fashioned leather car what I found interesting though is that even the current version of chattybt could now get this right on other tests it gets it a little off but I think we might as well tick this one off the list the final task I wanted to focus on in Palm appendix is a little more worrying it's Triple H on the wrestler the need to be helpful honest and harmless it's kind of worrying that that's the thing it's currently failing at I think this is closely linked to hallucination and the fact that we cannot fully control the outputs of large language models at this point if you've learned anything please do let me know in the comments or leave a like it really does encourage me to do more such videos all of the papers and pages in this video will be linked in the description anyway hallucinations brought me back to the anthropic safety",
        "start": "00:06:10",
        "duration": 241.26100000000002,
        "title": "What's Left Before AGI? PaLM-E, 'GPT 4' and Multi-Modality"
    },
    {
        "text": "statement and their top priority of mechanistic interpretability which is a fancy way of saying understanding what exactly is going on inside the machine and one of these stated challenges is to recognize whether a model is deceptively aligned playing along with even tests designed to tempt a system into revealing its own misalignment this is very much linked to the Triple H failures we saw a moment ago fine so honesty is still a big challenge but I wanted to know what single significant and quantifiable task AI was not close to yet achieving some thought that that task might be storing long-term memories as it says here but I knew that that Milestone had already been passed this paper from January described augmenting Palm with read write memory so that it can remember everything and process arbitrarily long inputs just imagine a Bing chat equivalent knowing every email at your company every customer records sale invoice the minutes of every meeting Etc the paper goes on to describe a universal turing machine which to the best of my understanding is one can mimic any computation a universal computer if you will indeed the author's state in the conclusion of this paper that the results show that large language models are already computationally Universal as they exist currently provided only that they have access to an unbounded external memory what I found fascinating was that anthropic are so concerned by this accelerating progress that they don't publish capabilities research because we do not wish to advance the rate of AI capabilities progress and I must say that anthropic do know a thing or two about language models having delayed the public deployment of Claude which you can see on screen until it was no longer state of the art they had this model earlier but delayed the deployment Claude by the way is much better than chattybt at writing jokes moving on to",
        "start": "00:08:11",
        "duration": 250.38100000000003,
        "title": "What's Left Before AGI? PaLM-E, 'GPT 4' and Multi-Modality"
    },
    {
        "text": "data though in my video on gpt5 which I do recommend you check out I talk about how important data is to the Improvement of models one graph I left out from that video though suggests that there may be some limits to this straight line Improvement in the performance of models what you're seeing on screen is a paper are released in ancient times which is to say two weeks ago on messa's new llama model essentially it shows performance improvements as more tokens are added to the model by token think scraped web text but notice how the gains level off after a certain point so not every graph you're going to see today is exponential and interestingly the y-axis is different for each task and some of the questions it still struggles with are interesting take s-i-q-a which is social interaction question answering it Peaks out about 50 to 52 percent that's questions like these wherein most humans could easily understand what's going on and find the right answer models really struggle with that even when they're given trillions of tokens or what about natural questions where the model is struggling at about a third correct even Beyond 1.2 trillion tokens I dug deep into the literature to find exactly who proposed natural questions as a test and found this document this is a paper published by Google in 2019 and it gives lots of examples of natural questions essentially they're human-like questions where it's not always clear exactly what we're referring to now you could say that's on us to be clearer with our questions but let's see how Bing does with some of these I asked the guy who plays Mandalorian also did what drugs TV show I deliberately phrased it in a very natural vague way interestingly it gets it wrong initially in the first sentence but then gets it right for the second sentence I tried dozens of these questions you can see another one here author of lotr surname origin that's a",
        "start": "00:10:16",
        "duration": 243.83999999999997,
        "title": "What's Left Before AGI? PaLM-E, 'GPT 4' and Multi-Modality"
    },
    {
        "text": "very naturally phrased question it's surmised that I meant Tolkien the author of Lord of the Rings and I wanted the origin of his surname and it gave it to me another example was Big Ben City first bomb landed WW2 it knew I meant London and while it didn't give me the first bomb that landed in London during World War II it gave me a bomb that was named Big Ben so not bad overall I found it was about 50 50 just like the meta llama model maybe a little better going back to the graph we can see that data does help a lot but it isn't everything however anthropic's theory is that compute can be a rough proxy for further progress and this was a somewhat eye-opening passage we know that the capability jump from gpt2 to gpt3 resulted mostly from about a 250 time increase in compute we would guess that another 50 times increase separates the original gpt3 model and state-of-the-art models in 2023 think Claude or Bing over the next five years we might expect around a 1 000 time increase in the computation used to train the largest models based on Trends in compute cost and spending if the scaling laws hold this would result in a capability jump that is significantly larger than the jump from gbc2 to gpt3 or gbt3 to Claude and ends with anthropic we're deeply familiar with the capabilities of these systems and a jump that is this much larger feels to many of us like it could result in human level performance across most tasks that's AGI and five years is not a long timeline this made me think of Sam Altman's AGI statement where he said at some point it may be important to get independent review before starting to train future systems and for the most advanced efforts to agree to limit the rate of growth of compute used for creating new models like a compute truce if you will even Sam Altman thinks we might need to slow down a bit my question is though would Microsoft or Tesla or Amazon agree with this truth",
        "start": "00:12:18",
        "duration": 284.64,
        "title": "What's Left Before AGI? PaLM-E, 'GPT 4' and Multi-Modality"
    },
    {
        "text": "and go along with it maybe maybe not but remember that five-year timeline the anthropic laid out that chimes with this assessment from the conjecture alignment startup AGI is happening soon significant probability of it happening in less than five years and it gives plenty of examples many of which I have already covered others of course give much more distant timelines and as we've seen AGI is not a well-defined concept in fact it's so not well defined that some people actually argue that it's already here this article for example says 2022 was the year AGI arrived just don't call it that this graph originally from wait but why is quite funny but it points to how short a gap they might be between being better than the average human and being better than Einstein I don't necessarily agree with this but it does remind me of another graph I saw recently it was this one on the number of academic papers being published on machine learning and AI in a paper about exponential knowledge growth the link to this paper like all the others is in the description and it does point to how hard it will be for me and others just to keep up with the latest papers on AI advancements at this point you may have noticed that I haven't given a definitive answer to my original question which was to find the task that is left before AGI I do think there will be tasks such as physically Plumbing a house that even an AGI a generally intelligent entity couldn't immediately accomplish simply because it doesn't have the tools it might be smarter than a human but can't use a hammer but my other Theory to end on is that before AGI there will be a d deeper more subjective debate take the benchmarks on reading comprehension this graph shows how Improvement is being made but I have aced most reading comprehension tests such as the GRE so why is the highest human rater labeled at 80 could it be that progress stores when we get to the",
        "start": "00:14:40",
        "duration": 256.07899999999995,
        "title": "What's Left Before AGI? PaLM-E, 'GPT 4' and Multi-Modality"
    },
    {
        "text": "outer edge of ability when test examples of sufficient quality get so rare in the data set that language models simply cannot perform well on them take this difficult LSAT example I won't read it out because by definition it's quite long and convoluted and yes Bing fails it is this the near-term future where only obscure Feats of logic deeply subjective analyzes of difficult texts and Niche areas of mathematics and science remain Out Of Reach where essentially most people perceive AGI to have already occurred but for a few outlier tests indeed is the ultimate capture test the ability to deliver a laugh out loud joke or deeply understand the plight of Oliver Twist anyway thank you for watching to the end of the video I'm going to leave you with some bleeding edge text to image Generations from mid Journey version 5. whatever happens next with large language models this is the new story of the century in my opinion and I do look forward to covering it but as companies like Microsoft open Ai and Google seem set to make enough money to break capitalism itself I do recommend reading anthropic statement and their research on optimistic intermediate and pessimistic scenarios they also have some persuasive suggestions on rewarding models based on good process rather than simply quick and expedient outcomes check it out and have a wonderful day",
        "start": "00:16:48",
        "duration": 187.66100000000003,
        "title": "What's Left Before AGI? PaLM-E, 'GPT 4' and Multi-Modality"
    }
]