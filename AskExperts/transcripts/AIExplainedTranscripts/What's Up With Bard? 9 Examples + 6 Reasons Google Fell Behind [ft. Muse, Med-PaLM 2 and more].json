[
    {
        "text": "this video was supposed to be about the nine best prompts that you could use with Google's newly released Bard model it's just like problem every time I tried one of these epic ideas gpt4 did it better I really wanted to come out here and say look you can use it for this or for this as you'll see it just didn't work out that way so instead reluctantly I had to change the title now unfortunately it's just a comparison showing how much better gpt4 is compared to Bard a lot of people wanted this comparison after my last video used Bing for comparison this one's going to use open ai's gpt4 but I wasn't satisfied with just showing you the problems with Bard I wanted to find the explanation in the end I didn't find one reason I found six as the why Bard is so far behind and why Google is losing the AI race let's get to the comparison first one is coding and as you can see Bard refuses to do coding they actually mentioned this in the FAQ that Bard won't do coding for you as it says I'm designed solely to process and generate text as you can see it's a fairly basic coding Challenge and Bard won't do it gpt4 had no such qualms and the code worked first time of course I did check it and it worked but this was just a simple challenge to turn letters into numbers next and even worse for Bard it can't summarize PDFs this is going to be such a common use case for Bing using gpt4 by the way it didn't admit that it couldn't summarize the PDF it summarized a completely different PDF and if you check the other drafts none of them summarize the correct PDF of course the gpd4 accessed via open AI also can't do this because it can't access the web it also picked a completely different paper but our old friend Bing could indeed read the PDF and summarize it okay what about summarization when I literally paste in the text that I needed to summarize this is surely the most obvious use case of a",
        "start": "00:00:00",
        "duration": 231.00000000000003,
        "title": "What's Up With Bard? 9 Examples + 6 Reasons Google Fell Behind [ft. Muse, Med-PaLM 2 and more]"
    },
    {
        "text": "language model imagine you want to summarize a meeting via Google meets or shorten an email thread in Gmail it has to get this right I pasted in the same New York Times article into Bard and GP for and I am sad to say that Bard fluffed its lines the link to the article will be in the description but I have read it carefully and it makes numerous mistakes let me scroll down and show you this erroneous summary first it says the FED is expected to raise interest rates but doesn't say by whom second it starts chatting about Full Employment and inflation not only is full employment not mentioned in the article at all it also gets both numbers wrong the unemployment rate in America isn't currently 3.8 and inflation isn't at 7.9 I check these against the latest data and you can check it yourself but both are wrong Bard also keeps going on tangents like stocks are typically considered to be risky Investments than bonds okay that's fine but why are you teaching me Financial advice it was supposed to be summarizing an article honestly it was a pretty unusable summary so bad that to be honest you'd have been better off just not reading it trust me I am not an open AI Fanboy but its model is just better currently notice how a summary it doesn't go on tangents and it clarifies that it's investors who think that there will be a quarter point increase the five bullet points are succinct and accurate this is a pretty colossal loss for Bard what about light content creation and idea generation surely it could do well here just something innocent like create eight new YouTube video ideas with titles and synopses on integrating generative AI into retail if Bard can't be used by analysts maybe it can be used by content creators not really I mean you make your own mind up but these titles are pretty repetitive and Bland I know I can't really complain because my channel name is AI explained but these",
        "start": "00:01:55",
        "duration": 227.04000000000002,
        "title": "What's Up With Bard? 9 Examples + 6 Reasons Google Fell Behind [ft. Muse, Med-PaLM 2 and more]"
    },
    {
        "text": "titles are just unoriginal and the synopsis lack detail I'll let you read these but compare them to Gypsy 4's outputs each title is different and the ideas are much more explored and nuanced okay fine what about email composition and I have to say count me a skeptic on this one I have never ever found that any model let alone Bard can do a decent job at this it's not always that the emails are bad it's just that the time it takes me to teach the model what I want to say in my email I could have just written the email I'm going to make a prediction at this point I don't think using language models to do emails is going to become that common of course feel free to quote me on this in a year's time now you're probably thinking I'm being harsh this is a perfectly fine email I did leave a thumbs up it's just that I would never use Bard for this purpose and I would also never use gpt4 like I don't want it to make up all these extra details about what I'm going to discuss with John it's just too risky to send an email that has any chance of hallucinations I know you guys might think that I really love Bing but it's even worse here it claims that I've added relevant data and graphs no I haven't I never mentioned anything about data and graphs now my boss thinks I'm going to do data and graphs what are you doing Bing and then you're going to say why am I using creative mode well if we use balance mode or precise mode we go back to the bad problem it's an okay email now but look at the length of it I could have just written it out would have been quicker to do the email than the prompt I was beginning to lose hope in Bard so I tried writing assistance I picked a paragraph that someone I know used for a personal statement to get into University of course they were happy for me to share it it's decently written but could be improved significantly I asked Bard rewrite this paragraph with better English make it",
        "start": "00:03:48",
        "duration": 202.62,
        "title": "What's Up With Bard? 9 Examples + 6 Reasons Google Fell Behind [ft. Muse, Med-PaLM 2 and more]"
    },
    {
        "text": "original professional and impactful now Bard did remove some of the errors but it again went on a wild tangent trying to sell a career in data science as if we were some sort of recruiter now I'm not going to be too harsh if you just take the first paragraph it's okay GPT 4's output is better but still has some problems now I think some of you are going to laugh at what happened with Bing it simply refused to do it twice I pretty much had to trick Bing to get it to rewrite this paragraph first it says my mistake I can't give a response to that right now I tried again it said hmm let's try a different topic sorry about that that finally I just asked the exact same thing with different words I said rephrase this text with smoother language it seemed to like that and then did the job I think it's the best output but still has problems anyway this is not a grammar lesson so let's move to science and physics and Bard completely flops it gets this fairly basic physics question wrong so how can it be a tutor for us for a student to effectively learn from a tutor there has to be a degree of trust that the tutor is telling the truth gpt4 by the way gets this one right I even asked Bard to come up with a multiple choice quiz it definitely came up with the quiz problem is quite a few of the answers were wrong I didn't check all of them but look at number seven and number eight the correct answer just isn't there gpt4 does a lot better with really interesting questions in increasing order of difficulty now it does have a some slip UPS look at question four there are two correct answers one is a half one is five over ten but they both simplify to the same thing gpt4 was also able to give these explanations I do think the day of AI tutoring is fast approaching I just don't think it's quite here yet and certainly not with Bard I think the point is pretty much proven now so let's move on to the",
        "start": "00:05:30",
        "duration": 223.07999999999998,
        "title": "What's Up With Bard? 9 Examples + 6 Reasons Google Fell Behind [ft. Muse, Med-PaLM 2 and more]"
    },
    {
        "text": "explanations why has Google fallen so far behind first a lot of its top researchers have left there were eight co-authors at Google for the famous attention is all you need paper on the Transformer architecture that's amazing right they pretty much invented Transformers problem is now all but one of the papers eight co-authors have left one joined openai and others have started their own companies some of which I'll be covering in future videos speaking of which if you're learning anything from this video please don't forget to leave a like and a comment next potential reason is that they don't seem to want to interfere with their lucrative search model as the product lead for bad said I just want to be very clear Bard is not search if you haven't seen my initial review of Bard which pretty much proves that it's terrible at search do check out after this video If Bard is designed for search what is it designed for as the article points out they haven't really provided specific use cases next are they worried about safety and accelerationism or are they looking to buy up a competitor to open AI they invested over 300 million dollars in anthropic the stated goal of that company is to work on AI safety and Alignment so is Google trying to be on the right side of history and place all of its bets on safe AI or are they trying to do to anthropic what Microsoft did to open AI itself I'll be following this particular story quite closely over the coming weeks and months next maybe Google has better models that they genuinely don't want to release because they fear a PR backlash they had the Imogen text to image model that was better than Dali 2 and they didn't release it Google said it was because Imogen encoded harmful stereotypes and representations I dug into the original image and paper and it was indeed much better than Dali 2. Google wasn't bluffing they had a better model and",
        "start": "00:07:21",
        "duration": 220.25999999999993,
        "title": "What's Up With Bard? 9 Examples + 6 Reasons Google Fell Behind [ft. Muse, Med-PaLM 2 and more]"
    },
    {
        "text": "that wasn't the last time in January of this year they released a paper on Muse a text to image Transformer that was better than both Imogen and darli 2. in case anyone thinks they're lying here I think is the proof The Muse model outputs are on the right the image and outputs were in the middle and open ai's Dali 2 outputs are on the left strikes me that Google's Muse is one of the first models to get text right mid-journey even mid Journey version 5 definitely can't do this so why didn't Google release this well I read to the end of the newspaper and they say this it's well known that models like mid-journey and Muse can be leveraged for misinformation harassment and various types of Social and cultural biases due to these important considerations we opt not to release code or a public demo at this point in time let me know what you think in the comments but I think it's more than possible that Google has a language model that's far better than Bard and even far better than Palm perhaps leveraging deepmind's chinchilla model and that they are genuinely keeping it back and not publishing papers on it because they worry about these kind of considerations anyway I do have a final theory about Bard and that theory is that they might have been working on what they regard to be more serious models in December Google released this paper on medpalm it's a language model tailored to help in a medical setting and if you think it's accuracy of 67.6 in answering medical questions was good wait till we hear about the fact they've now released medpalm 2. here is a snippet of Google's presentation on medpalm 2 released just a week ago today we're announcing results from medpalm 2 our new and improved model mad Palm 2 has reached 85 accuracy on the medical exam Benchmark in research this performance is on par with expert test takers it far exceeds the passing",
        "start": "00:09:12",
        "duration": 236.039,
        "title": "What's Up With Bard? 9 Examples + 6 Reasons Google Fell Behind [ft. Muse, Med-PaLM 2 and more]"
    },
    {
        "text": "score and it's an 18 leap over our own state of art results from medpalm medpumm 2 also performed impressively on Indian medical exams and it's the first AI system to exceed the passing score on those challenging questions but finally what does this say about the near-term future of Bard well the more users a model gets the more data it gets and so the more easily a model can be improved as this Forbes article points out Microsoft now has access to the valuable training data that these products generate which is a dangerous Prospect for an incumbent like Google and it's not like Google doesn't know this the CEO of Google admitted that products like this talking about Bard get better the more people use them it's a virtuous cycle but does that mean that it will be a vicious cycle if everyone uses gpt4 instead of Bard with less data does that mean there'll be less Improvement of Google's model only time will tell and I will be there to test it thank you very much for watching and do have a wonderful day",
        "start": "00:11:09",
        "duration": 118.78100000000003,
        "title": "What's Up With Bard? 9 Examples + 6 Reasons Google Fell Behind [ft. Muse, Med-PaLM 2 and more]"
    }
]