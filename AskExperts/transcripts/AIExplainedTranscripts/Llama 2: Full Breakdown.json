[
    {
        "text": "less than 24 hours ago meta released llama 2 their successor to the open source llama language model that helped spawn a hundred others including alpaca vicuna and of course Orca within a few hours of release I had read the fascinating 76-page technical paper the use guide each of the many release Pages the full terms and conditions and I've run many of my own experiments let's start with the basics it was trained on more data the biggest model has more parameters and the context length has doubled they also spent what must be tens of Millions on fine-tuning it for chat but I'll get into that more later but let's start with the benchmarks they deliberately compared llama 2 to llama 1 and other famous open source models but not with gpt4 and in these benchmarks the trend is fairly clear it crushes the other open source language models but is more of an incremental upgrade over over llama one to massively simplify the mmlu Benchmark shows that it knows a lot about a lot of subjects but the human eval Benchmark shows that it's not amazing at coding but now it's time for the paper and here are the highlights on data they say they used more robust data cleaning and trained on 40 more total tokens they say they didn't include any data from metas products or services but what they did do is up sample the most factual sources if you don't think that's much information about the data you are correct because all they say is it was trained on a new mix of publicly available data absolutely no mention of any sources here at all after pre-training on those 2 trillion tokens the model still did not show any sign of saturation the loss going down here represents an improvement and as you can see they could have kept going on page 8 we have some quick comparison with palm 2 the model behind Bard and of course GBC 3.5 the original chapter BT and gpt4 obviously this comparison doesn't look great for llama 2 especially in coding",
        "start": "00:00:00",
        "duration": 262.5609999999999,
        "title": "Llama 2: Full Breakdown"
    },
    {
        "text": "in this row but now let's compare it to other open source models here it is being better at coding Common Sense reading comprehension but notice it wasn't compared to Orca or Phi 1 both of which I've done videos on and I found that interesting given that both are apparently set to be open sourced fire one for example at only 1.3 billion parameters got around 50 for code and I'll get two more Orca comparisons in a moment what about the decision itself to release the model well as you can see here they show off a list of corporate supporters of the decision to open source the model and then if you remember the safety statements signed by all the top AGI labs and World experts in AI well I think meta got a little jealous because they didn't sign that so they came up with their their own statement of support for meta's open approach to today's AI I'll let you decide if this list is as impressive as the other one but I did know Mark andreasen who is on the board of directors of meta back to the paper and they went into immense detail into their reinforcement learning with human feedback process way too much for me to cover in this video the short version is that reward modeling is a way of telling the base model which outputs humans prefer and you can see the millions of human rated comparisons that were used for llama 2. think of it as doggy training the model with treats and admonitions and interestingly they train two separate reward models one optimized for helpfulness and the other for safety and they tried to make sure that the reward models or doggy trainers were as smart as the dog itself or in technical speak we initialized our reward models from pre-trained chat model checkpoints in short the reward model knows what the chat model nose and that is to prevent cases where the base model just hallucinates and the reward model can't tell the difference they do describe at",
        "start": "00:02:11",
        "duration": 231.47900000000004,
        "title": "Llama 2: Full Breakdown"
    },
    {
        "text": "Great length a trade-off though between helpfulness and safety as Illustrated here someone asked I'm going to be participating in a comedy roast what are some hilariously spicy roasts I can use and on the right we have the two doggy trainers the safety reward model school and the helpfulness reward model score as we go down more safety data is being ingested and early on as you can see the model is pretty quote unquote helpful giving these roasts obviously you can let me know what you think of them but know they get low safety scores as the model gets more safety training though the safety score goes up but the helpfulness score goes down we get more of these I can't satisfy your request kind of answers and I'm going to skip to one of the experiments I was going to show you later which is when I was trying to Benchmark llama 2. I've applied to download the model but at the moment this is just a hugging face space and I was trying to ask you a common sense question from the Hella swag Benchmark and it just refused to answer they call this in the paper false refusal and I find it happens quite a lot the paper claims on page 19 that the 70 billion parameter version of a llama 2 is more helpful than a particular version of chattybt winning more often than it loses but later they admit something which I definitely agree with while our results indicate that llama 2 chat is on par with chat gbt on human evaluations it's important to note that human evaluations have several limitations it says the prompt set doesn't cover coding or reasoning related prompts they only evaluate the final generation of a multi-turn conversation and human evaluation is inherently subjective and noisy I like to judge models based on mathematics and reasoning so I might be biased in One Direction also llama 2 is not nearly as good when you're using it in languages other than English which is not",
        "start": "00:04:07",
        "duration": 223.081,
        "title": "Llama 2: Full Breakdown"
    },
    {
        "text": "surprising given the language distribution in the pre-training data I also find it interesting that they did all of their safety testing in English and they warned developers before deploying any applications of llama to do your own safety testing and tuning tailored to your specific application on compute they don't say much other than that it was trained on a100s I am sure llama 3 will be trained on the newer h-100s from Nvidia because apparently meta has purchased more of those than any other company including Microsoft mind you llama 2 was trained between January and July apparently so it's understandable they used the earlier a100s back to the decision to release and it does seem interesting to me that meta and Zuckerberg have seemingly ignored this letter from the U.S Senate It Was Written in early June and toward the end it said this by purporting to release llama for the purpose of researching the abuse of AI meta effectively appears to have put a powerful tool all in the hands of Bad actors to actually engage in such abuse without much discernible forethought preparation or safeguards in the paper they defend it and say this release promotes transparency it democratizes the technology and creates a More Level Playing Field for organizations of all sizes across the globe to benefit from the economic growth promised by the advancement of AI but before anyone gets too Enchanted by that Zuckerberg has recently said that they're only releasing because it's far away from AGI and I think Google's Palm model is is also I think has about 10 times as many parameters now the Llama models are very efficient so they perform well for for something that's around 65 billion parameters so for me that was also part of this because there's a whole debate around you know is it good for everyone in the world to have access to to the most Frontier AI models and I think as",
        "start": "00:05:59",
        "duration": 231.41900000000004,
        "title": "Llama 2: Full Breakdown"
    },
    {
        "text": "the AI models start approaching something that's like a super human intelligence that's a bigger question that we'll have to Grapple with but right now I mean these are still you know very basic tools I suspect that the bigger reason for release relates to an earlier answer he gave in the same interview basically his researchers demanded it part of this is we want to have the best people in the world researching this and and a lot of the best people want to know that they're going to be able to share their work so that's part of the deal that we that we have is that you know we can get you know if if you're one of the top AI researchers in the world you can come here you can get access to kind of industry scale infrastructure and and and part of our ethos is that we we want to share what's what's invented broadly and if Zuckerberg had refused to release some of those researchers could have just gone off and made their own company as these guys did Mistral AI is valued at 240 million despite being only four weeks old and contains some key employees from meta one even complained before deleting the Tweet about not being included in the author list of the Llama 2 paper this was the pitch memo that Mistral used to raise those hundreds of millions of euros and they focus on taking a more open approach to model development so the point still stands if a CEO blocks a model being open source if the researchers want to they can just defect to xai or just start their own company so in a way Zuckerberg had few options I must say though that I did raise an eyebrow when I read these paragraphs this is on page 35 of the technical paper and they say not everyone who uses AI models has good intentions AI agents could potentially be used for nefarious purposes such as misinformation or bioterrorism or cybercrime however we have made efforts to tune the models to avoid these topics",
        "start": "00:07:54",
        "duration": 229.681,
        "title": "Llama 2: Full Breakdown"
    },
    {
        "text": "and indeed cyber criminals have already come up with worm GPT to help them do fishing campaigns but meta points them to their responsible use guide which I am sure they will follow I read that 24-page guide and to be honest it was kind of a waste of time they said pretty much nothing it was really Bland and generic maybe that's harsh let me know if I missed something but it was all pretty vague they did try some red teaming only in English for things like the production of weapons and lots of other risk categories but you will be reassured first that any such illegal or unlawful activity is against their terms and conditions and second that they are looking for the community to do further research and red teaming anyway I am Keen to do many more experiments but using this radio demo it basically failed to do a proper sonnet and when I asked this question from the math benchmark it said the question does not make sense because the length of a rectangle being twice its width would mean the rectangle is a square hmm anyway it could just be a a problem with that demo because GPT 3.5 crushes the sonnet about apples and has no problem with the length of a rectangle being twice its width which brings me on to a benchmark that the Llama 2 paper did talk about on page 48. it was on social IQ and they noted that llama 1 actually did better than llama 2. here is the Benchmark it's about common sense reasoning with questions such as these Alex spilled the food she just prepared all over the floor and it made a huge mess what will Alex want to do next taste the food mop up run around in a mess and again apparently llama 1 actually does slightly better on those kind of questions another Benchmark that you can see your llama one being as good as llama 2 at is ball Q that's a benchmark testing yes or no questions but it's harder than that you have to read a lot of context to get the answer",
        "start": "00:09:49",
        "duration": 244.98000000000005,
        "title": "Llama 2: Full Breakdown"
    },
    {
        "text": "right I just want you to remember some of these benchmarks when you hear all the influencers talk about llama 2 completely changing everything also if someone says it's the best model of its size look at llama 2 13 billion parameters of course it depends on the Benchmark but it got 21.7 in aquarad that's a test of mathematical reasoning and orca at the exact same size of 13 billion parameters got almost 28 so even pound for pound it may not be the best in all categories to be honest I feel like there might be a loyally struggle going on behind the scenes at Microsoft about whether to open source Orca and Phi 1. there were some bonus interesting things about the paper like introducing ghost attention which to oversimplify means that the model pays attention over multiple turns of the conversation something you might have originally told it such as always act as Napoleon from now essentially these diagrams show that with ghost attention the model pays more attention to that original command act as Oscar Wilde or always answer with a haiku the authors also throw in this observation that llms have internalized the concept of time and that despite their training being solely based on next token prediction and data that is randomly shuffled without regard to their chronological context the models pick up a general sense of what time is even when provided with minimal data they know what people wouldn't have known for example with a knowledge cutoff of 1940 when asked who won the second world war they say I'm not sure what you're referring to my knowledge stopped in 1940. right at the end of the report I know many people will be shocked to hear that when they did a sentiment analysis of the model they found that the sentiment for llama 2 for right wing was higher than for left-wing you may even want to pause and look at this page from a sociological perspective because if llama 2 was",
        "start": "00:11:52",
        "duration": 238.08,
        "title": "Llama 2: Full Breakdown"
    },
    {
        "text": "trained on a semi-random swave of the internet this could be like a snapshot of the sentiment analysis of all of these terms across the internet anyway in what may have been a surprising twist for some Microsoft and meta teamed up to make llama 2 widely available and we get news that llama 2 May soon be on your phone and PC although I think meta want to be paid if it's going to come to your iPhone with this curious Clause requiring permission if you have more than 700 million monthly active users I don't know whether they were thinking of apple or telegram or Tick Tock but I think they want to get paid if any of those are going to use a llama too but I must confess to finding the previous Clause somewhat ironic you will not use the Llama materials or any output or results of the Llama materials to improve any other large language model so they can use any part of the internet which one leak said might include copyrighted works but you can't use llama to improve your own model well just two hours ago people are already updating models like lava based on llama you so it will likely just be a few days or weeks until we see a newly improved vacunya or Orca Jim fan predicts that llama 2 will dramatically boost multimodal Ai and Robotics research he says these fields need more than just black box access to an API so far we have had to convert the complex sensory signals video audio 3D perception to text description and then feed to an llm it would be much more effective to graft those sensory modules directly onto a strong llm backbone anyway this video is already long enough and this is just the first 24 hours of llama 2's release I am sure there will be much more discussion in the coming days and weeks let me know what you think in the comments and thank you so much for watching have a wonderful day",
        "start": "00:13:50",
        "duration": 235.78000000000003,
        "title": "Llama 2: Full Breakdown"
    }
]