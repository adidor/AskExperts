[
    {
        "text": "there have been 16 surprising and or fascinating moments from Sam Altman's World Tour I could have done a video on each of them after watching over 10 hours of interviews I decided you know what let's just show you everything in one video from ai's designing new AIS to Fresh Chachi PT leaks shooting railguns to open source here's all 16 things I learned in no particular order let's start with Sam Altman's warning about ai's designing their own architecture we get to make the decisions about how they work I think it'd be a mistake to just say all right human out of the loop hand this over do whatever you want change your own architecture go do all these things I think it's very important that the future of humanity is determined by humanity and that is like an active choice we can make seems like a good idea but satsukova could see one of their models designing the next model we are definitely very concerned about super intelligence it will be possible to build a computer a computer cluster GPU farm that is just smarter than any person that can do science and engineering much much faster than even a large team of really experienced scientists and engineers and that is crazy that is going to be unbelievably extremely impactful it could engineer the next version of the system AI building AI that's just crazy let's return to Abu Dhabi where Sam Altman said he enjoys the power that being CEO of openai brings but also mentioned strange decisions he might have to make I mean I have like lots of selfish reasons for doing this and as you said I get like all of the Power of running open AI but I can't think of like anything more fulfilling to work on I don't think it's like particularly altruistic because it would be if I like didn't already have a bunch of money yeah the money is going to like pile up faster than I can spend it anyway I like",
        "start": "00:00:00",
        "duration": 224.15899999999996,
        "title": "Sam Altman's World Tour, in 16 Moments"
    },
    {
        "text": "being non-conflicted on openai because I think the chance that we have to make a very strange decision someday um is non-trivial speaking of big decisions samuelman hinted twice once in Jordan and once in India of possible regrets he might have had over firing the starting gun in the AI race we're definitely going to have some huge regrets uh 20 years from now I hope all we can say is that we did far far far more good than bad and I think we will I think that's true but the downside here is is pretty big and I think we feel that weight every day honestly I think if we're gonna regret something it may be that we already pushed the button like we've already launched this revolution it's somewhat out of our hands I think it's going to be great but like this is going to happen now right like this we've we're out of the the world is like out of the gates I I guess the thing that I lose the most sleepover is that we already have done something really bad I don't think we have but the hypothetical that we by launching Chachi PT into the world shot the industry out of a railgun and we now don't get to have much impact anymore and there's gonna be an acceleration towards making these systems which again I think will be used for tremendous good and and I think we're going to address all the problems but maybe there's something in there that was really hard and complicated in a way we didn't understand and you know we've now already kicked this off but back to Tel Aviv where both samuelman and openai's chief scientist Ilya satskova agreed that the risks from Super intelligence were not science fiction so the last question the super intelligent AI That's out of control yeah that'd be pretty bad yeah so it's like it would be",
        "start": "00:01:53",
        "duration": 213.54099999999994,
        "title": "Sam Altman's World Tour, in 16 Moments"
    },
    {
        "text": "it would be a big mistake to build the super intelligence AI that we don't know how to control I think the world should treat that not as a you know haha never going to come sci-fi risk but something that we may have to confront in the next decade which is not very long on a lighter note Sam Altman didn't seem that perturbed not just about a deep fake of himself but also on society getting used to misinformation I want to play a clip uh maybe you guys can put on a clip of something I recently heard Sam speak somewhere and we can talk about it a bit could you uh play the clip please hi my name is Sam and I'm happy to be here today thank you all for joining I also wanted to say that the gentleman on stage with me is incredibly good looking and I also want to say that you should be very careful with videos generated with artificial intelligence technology okay so you didn't say that recently but nonetheless I think it raises a real question right when you know this video if you look closely you can see the lips aren't perfectly synced but like you said this stuff is only going to get better and exponentially better yeah so that was like deeply in The Uncanny Valley it's very strange to watch but we're not that far away from something that looks perfect there's a lot of fear right now about the impact this is going to have on elections and on our society and how we ever trust media that we see I have some fear there but I think when it comes to like a video like that I think as a society we're gonna rise to the occasion we're going to learn very quickly that we don't trust videos unless we trust the the sort of provenance if people are saying something really important they'll cryptographically sign it indeed throughout the world tour salmon repeatedly stated that he didn't believe there should be any regulation of",
        "start": "00:03:44",
        "duration": 197.64000000000001,
        "title": "Sam Altman's World Tour, in 16 Moments"
    },
    {
        "text": "current models everybody wants great education productivity gains discovery of new science all of the stuff that's going to happen and no one wants to destroy the world no one wants to do things not even that bad but still bad I totally believe it is possible to not stifle Innovation and to address the big risks I think it would be a mistake to go regulate the current models of today and in Poland his co-founder wajac zaremba agreed saying the risks of super intelligence were 10 years away also I would say that the fear is that fear of AI of the future not the AI of today if the trajectory that we are on will continue then in the decade or so there will be build systems which are as powerful as today corporations but if I could speak to Sam Oldman I would bring his attention to this paper published this week this is a study out of Harvard and MIT and it involved some non-scientist students working for one hour in that hour they were able to get chat Bots to suggest four potential pandemic pathogens explain how they can be generated from synthetic DNA using reverse genetics supplied the names of DNA synthesis companies unlikely to screen orders and identify detailed protocols and how to troubleshoot them and they say that collectively these results suggest that llms will make pandemic class agents widely accessible even to people they say with little or no lab training and then there's this these results strongly suggest that the existing evaluation and training process for large language models is inadequate to prevent them from providing malicious actors with accessible expertise relevant to inflicting Mass death and that more immediately if unmitigated llm chatbots render pandemic class agents more accessible even to people without training in the Life Sciences the number of individuals capable of killing tens of millions of people will dramatically increase they recommend that at a",
        "start": "00:05:23",
        "duration": 253.861,
        "title": "Sam Altman's World Tour, in 16 Moments"
    },
    {
        "text": "minimum new llms larger than gpt3 should undergo evaluation by Third parties skilled in assessing catastrophic biological risks before controlled access is given to the general public notice they said larger than gpt3 so that strongly contradicts Sam wantman's assertion that current models like gpt4 shouldn't have any regulation they say that even open source communities should welcome safeguards because a single instance of misuse and mass death would trigger a backlash including the imposition of extremely harsh regulations one specific recommendation was that if biotech and information security expert were able to identify the set of Publications most relevant to causing Mass death and companies like open Ai and Google curated their training data sets to remove those Publications then future models trained on the curated data would be far less capable of providing anyone intent on harm with the recipes for the creation or enhancement of pathogens this seems like an absolutely obvious move to me and I think Ilya satskova would agree we are talking about as time goes by and the capability keeps increasing you know and eventually it goes all the way to here right right now we are here today that's where we are that's what we're going to get to when you get to this point then yeah it's very powerful technology it can be used for amazing applications you can say cure all disease on the flip side you can say create a disease much more worse than anything that existed before that'd be bad moving on to the chat gbt Elite it seems like we're going to get a new workspace where we can customize our interaction with chattybt giving it files and a profile with any information that you'd like chat gbt to remember about you and your preferences this was hinted out on the world tour when one of Sam Altman's",
        "start": "00:07:29",
        "duration": 224.51899999999998,
        "title": "Sam Altman's World Tour, in 16 Moments"
    },
    {
        "text": "guests Johannes Heidecker from openai research talked about customizing models we are trying to make our models both better at following certain guardrails that should never be overwritten not with jailbreaks not if you ask nicely not if you threaten it and we're also trying to make our models better at being customizable making them listen more to additional instructions of what kind of behavior the user or the developer wants on a lighter note the leaders of openai were asked in Seoul the capital of South Korea about the mixing of AI and religion do you expect AI to replace the role of religious organizations like church I I think I think that it's a good question how all sort of human societies will integrate Ai and we've already seen people building AI pastors for example and so the constituents can ask questions of this pastor the cite Bible verses and it can can give advice but now back to Poland where Sam Altman called open source Unstoppable realizing that open source is Unstoppable and shouldn't be stopped and so this stuff is going to be out there and as a society we have to adapt speaking of stopping AI samuelman was asked about his own loved ones and in response he gave a utopic vision of the future and called the current world barbaric if you truly believe that AI imposes a danger to humankind why keep developing it aren't you afraid for your own dear ones and family I think it's a super fair and good question and the most Troublesome part of our jobs is that we we have to balance this like incredible promise in this technology that I think humans really need and we can talk about why in a second with confronting that these very serious risks why to build it number one I do think that when we look back at the standard of living and what we tolerate for people today it will look even worse than when we look back",
        "start": "00:09:22",
        "duration": 236.88000000000005,
        "title": "Sam Altman's World Tour, in 16 Moments"
    },
    {
        "text": "at how people lived 500 or a thousand years ago and we'll say like man can you imagine that people lived in poverty can you imagine people suffered from disease can you imagine that everyone didn't have a phenomenal education were able to live their lives however they wanted it's going to look barbaric I think everyone in the future is going to have better lives than the best people of today I think there's like a moral duty to figure out how to do that I also think this is like Unstoppable like this is the progress of Technology it won't it won't work to stop it and so we have to figure out how to manage the risk it doesn't seem to be a hundred percent sure on this front though and here is an interview he gave with the guardian when he was in London for his world tour speaking of superintelligence said it's not that it's not stoppable if governments around the world decided to act in concert to limit AI development as they have in other fields such as human cloning or bioweapon research they may be able to but then he repeated but that would be to give up all that is possible I think that this will be the most tremendous Leap Forward in quality of life for people that we've ever had I did try to get tickets for the London leg of His World Tour but they were sold out within half an hour oh well samuelman does think that behavior will change however when these AGI Labs stare existential risk in the face one of the things we talked about is what's a structure that would let us warmly Embrace regulation that would hurt us the most and now that the time has come for that we're out here advocating around the world for regulation that will impact us the most so of course we'll comply with it I think it's more easy to get good behavior out of people when they are staring existential risk in the face and so I think all of the people at the Leading Edge here these different",
        "start": "00:11:21",
        "duration": 201.11999999999998,
        "title": "Sam Altman's World Tour, in 16 Moments"
    },
    {
        "text": "companies now feel this and you will see a different Collective response than you saw from the social media companies and in terms of opportunities both samuelman and Ilya satsukver talked about solving climate change I don't want to say this because climate change is so serious and so hard of a problem but I think once we have a really powerful super intelligence addressing climate change will not be particularly difficult for a system like that we can even explain how here's how soft climate change you need a very large amount of carbon cup of efficient carbon capture you need the energy for the carbon capture you need the technology to build it and you need to build a lot of it if you can accelerate the scientific progress which is something that the powerful AI could do we could get to a very Advanced carbon capture much faster it could get to a very cheap power much faster it could get to cheaper manufacturing much faster now combine those three cheap power cheap manufacturing Advanced carbon capture now you build lots of them and now you sucked out all this all the excess CO2 from the atmosphere you know if you think about a system where you can say tell me how to make a lot of clean energy cheaply tell me how to efficiently capture carbon and then tell me how to build a factory to do this at planetary scale if you can do that you can do a lot of other things too yeah with one addition that not only you ask you to tell it you ask it to do it that would indeed be amazing but think of the power we would be giving to an AI if it was able to just do it just create those carbon capture factories if we did make that decision one thing that would help would be reducing hallucinations I think we will get the hallucination problem to a much much better place it will take us my colleagues William I I think it'll take us a year and a half two years something like that but at that point we won't still talk about",
        "start": "00:13:01",
        "duration": 206.75999999999996,
        "title": "Sam Altman's World Tour, in 16 Moments"
    },
    {
        "text": "these Sam Altman talked about that in New Delhi that time frame of 18 months to two years is ambitious and surprising but now on to jobs which Samuel was asked about on every leg of the tour on this front though I do think it was Ilya satsukovar who gave the more honest answer economic dislocation indeed like we already know that there are jobs that are being impacted or they're being affected in other words some chunks of the jobs can be done you know if you're a programmer you don't write functions anymore co-pilot writes them for you if you're an artist though it's a bit different because a big chunk of the artists economic activity has been taken by some of the image generators and while new jobs will be created it's going to be a long period of economic uncertainty there is an argument to be made that even when we have full human level AI full AGI people will still have economic activity to do I don't know whether that's the case but in either event we will need to have something that will allow for a soft soften the blow to allow for a smoother transition either to the totally new profession that will exist or even if not then we want government the social systems will need to keep Kane I do think the changes in the job market will be dramatic and will be following the story closely one thing I definitely agree with Samuel Manon though is the Deep almost philosophical change that this solving of intelligence has brought to humanity so I grew up implicitly thinking that intelligence was this like really special human thing and kind of somewhat magical and I now think that it's sort of a fundamental property of matter and that's that's definitely a change to my world view the history of scientific discovery is that humans are less and less at the center you know we used to think that like sun rotated around us",
        "start": "00:14:45",
        "duration": 218.16099999999997,
        "title": "Sam Altman's World Tour, in 16 Moments"
    },
    {
        "text": "and then maybe at least we were if not that we were like going to be the center of the Galaxy and there wasn't this big universe and then Multiverse like really is kind of weird and depressing and if intelligence isn't special like again we're just like further and further away from like main character energy but that's all right that's sort of like a nice thing to realize actually it's a bit like a copernican and darwinian Revolution all rolled in one I'll give the final word to Greg Brockman in Seoul who talked about the unpredictability of scaling up models 10 times right that is the biggest theme in the history of AI is that it's full of surprises every time you think you know something you scale it up 10x turns out you knew nothing um and so I think that we as a Humanity as species are really exploring This Together being all in it together and knowing nothing sounds about right but thank you for watching to the end I know that samuelman has a couple more stops I think it's Jakarta and Melbourne on the world tour and I'll be watching those of course but for now thank you and have a wonderful day",
        "start": "00:16:34",
        "duration": 117.58000000000003,
        "title": "Sam Altman's World Tour, in 16 Moments"
    }
]