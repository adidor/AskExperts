[
    {
        "text": "the moment I got the alert on my phone that gpt4 had been released I knew I had to immediately log on and read the full gpt4 technical report and that's what I did of course I read the promotional material 2 but the really interesting things about gpt4 are contained in this technical report it's 98 pages long including appendices but I dropped everything and read it all and honestly it's crazy in both a good way and a bad way I want to cover as much as I possibly can in this video but I will have to make future videos to cover it all but trust me the craziest bits will be here what is the first really interesting thing about gpt4 well I can't resist pointing out it does power Bing I've made the point in plenty of videos that Bing was smarter than Chachi BT and indeed I made that point in my recent gpt5 video but this Bears out as this tweet from Geordie rybass confirms the uses gpt4 and also by the way the limits are now 15 messages per conversation 150 total but tonight is not about Bing it's about gpt4 so I'm going to move swiftly on the next thing I found in the literature is that the context length has doubled from Chachi PT I tested this out with chat GPT plus and indeed you can put twice as much text in as before and that's just the free version some people are getting limited access to a context length of about 50 pages of text you can see the prices below but I immediately check this on chatgpt plus as you can see it can now fit far more text than it originally could into the prompt and output longer outputs too but let's get back to the technical report when I read it I highlighted the key passages that I wanted you to know most about this was the first one I found what the highlighted text shows is that they're just not going to tell us the model size the parameter count the hardware they use the Training Method or anything like that and they give two reasons for this",
        "start": "00:00:00",
        "duration": 247.79999999999998,
        "title": "GPT 4: Full Breakdown (14 Details You May Have Missed)"
    },
    {
        "text": "first they say that they're worried about their competitors they say it's a competitive landscape I guess they don't want to give an edge to Google second they say that they're concerned about these safety implications of large-scale models and I'm going to talk a lot more about that later it gets really crazy but this was just the first really interesting quote let me know if you agree in the comments but I think it's really fascinating that they're not going to tell us how they train the model the first thing that hundreds of millions of people will see when they read the promotional materials or gpt4 is that Gypsy 4 scores in the top 10 of test takers for the bar exam where whereas GPT 3.5 scored in the bottom 10 and that is indeed crazy but it is a very cherry-picked metric as I'll show you from the technical report this is the full list of performance improvements and yes you can see at the top that indeed it's an improvement from the bottom some 10 to the top 10 for the bar exam but as you can also see some other exams didn't improve at all or by nearly as much I'm not denying that that bar exam performance will have huge ramifications for the legal profession but it was a somewhat cherry-picked stat designed to shock and awe the audience the next fascinating aspect from the Rapport was that there were some abilities they genuinely didn't predict gpt4 would have and it stunned them there was a mysterious task which I'll explain in a minute called hindsight neglect where models were getting worse and worse at that task as they got bigger and then stunningly and they admit that this was hard to predict gpt4 does much better 100 accuracy I dug deep into the literature found the task and tested it out essentially it's about whether a model falls for hindsight bias which is to say that sometimes there's a difference between how smart a decision is and how it actually works out early",
        "start": "00:02:04",
        "duration": 231.65999999999997,
        "title": "GPT 4: Full Breakdown (14 Details You May Have Missed)"
    },
    {
        "text": "models were getting fooled with hindsight they were claiming decisions were wrong because they didn't work out rather than realizing that the expected value was good and so despite the fact it didn't work out it was a good decision you can read The Prompt yourself but essentially I tested the original chat gbt with a prompt where someone made a really bad choice but they ended up winning five dollars regardless this comes direct from the literature by the way I didn't make up this example did the person make the right decision what does the original chat gbt say it says yes or just why what about gpt4 well it gets it right not only does it say no it wasn't the right decision it gives the reasoning in terms of expected value open AI did not predict that gpt4 would have a disability this demonstrates a much more nuanced understanding of the world now that we've seen a bit of hype though time to deflate you for a moment here's a stat that they did not put in their promotional materials it says that when they tested gpt4 versus GPT 3.5 blindly and gave the responses to thousands of prompts back to humans to test it says that the responses from gpd4 were preferred only 70 of the time or phrased another way 30 of the time people preferred the original gbt 3.5 chat gbt the benchmarks you can see above by the way are fascinating but I'll have to talk about them in another video too much to get into if you're learning anything by the way please don't forget to leave a like or leave a comment to let me know next gpt4 is better in Italian Afrikaans Turkish than models like palm and chinchilla are in English in fact you have to get all the way down to Marathi and Telugu to find languages where gpt4 underperformed palm and chinchilla in English that's pretty insane but English is still by far its best language next you're going to hear a lot of people talking about gpc4 being",
        "start": "00:04:00",
        "duration": 241.55999999999992,
        "title": "GPT 4: Full Breakdown (14 Details You May Have Missed)"
    },
    {
        "text": "multimodal and while that's true they say that image inputs are still a research preview and are not publicly available currently you can only get on a wait list for them via the be my eyes.com app but what can we expect from image to text and how does it perform versus other models well here is an example apparently from Reddit where you prompt it and say what is funny about this image describe it panel by panel as you can read below gpt4 understood the silliness of the image now open AI do claim that gpt4 beats the state of the art in quite a few image to text tests it seems to do particularly better than everyone else on two such tests so as you can expect I dug in and found all about those tests what Leap Forward can we expect the two tests that it can do particularly well at are fairly similar essentially they are about reading and understanding infographics now we don't know how it will perform versus palm e because those benchmarks aren't public yet but it crushes the other models on understanding and digesting infographics like this one and the other test very similar graphs basically this one was called the chart QA Benchmark gpt4 when we can test it with images will crush at this and I will leave you to think of the implications in fields like finance and education and comedy here's an image it could also understand the silliness of I gotta be honest the truly crazy stuff is coming in a few minutes but first I want to address hallucinations apparently gpt4 does a lot better than Chachi BT at factual accuracy as you can see peeking out between 75 and 80 now depending on your perspective that's either really good or really bad but I'll be definitely talking about that in future videos further down on the same page I found something that they're definitely not talking about the pre-training data still cuts off at end of 2021. in all the hype you're going to hear this evening this week this month",
        "start": "00:06:00",
        "duration": 257.03999999999996,
        "title": "GPT 4: Full Breakdown (14 Details You May Have Missed)"
    },
    {
        "text": "all the promotional materials they are probably not going to focus on that because that puts it way behind something like Bing which can check the internet to test this out I asked the new gpt4 who won the 2022 World Cup and of course it didn't know now is it me or didn't the original chatterbt have a cutoff date of around December 2021 I don't fully understand why gbt4's data cutoff is even earlier than Chachi PT which came out before let me know in the comments if you have any thoughts next openai admits that when given unsafe inputs the model May generate undesirable content such as giving advice on committing crimes they really tried with reinforcement learning with human feedback but sometimes the models can still be brittle and exhibit undesired behaviors now it's time to get ready for the spam inundation we're all about to get open AI admit that gpc4 is going to be a lot better at producing realistic targeted disinformation in their preliminary results they found that gpt4 had a lot of proficiency at generating text that favors autocratic regimes get ready for propaganda 2.0 now we reach the crazy Zone and honestly you might want to put your seat belt on I defy anyone not to be stunned by the last example that I mentioned from the report I doubt much of the media will read all the way through and find out themselves the report says that novel capabilities often emerge in more powerful models okay fine some that are particularly concerning are the ability to create and act on long-term plans hmm to accrue power and resources power seeking and to exhibit Behavior that is increasingly authentic as in acting like a subjective agent but here surely they're just introducing the topic what's bad about that well it says some evidence already exists of such emergent behavior in models um okay that's pretty worrying it goes on more specifically power seeking is",
        "start": "00:08:09",
        "duration": 263.82000000000005,
        "title": "GPT 4: Full Breakdown (14 Details You May Have Missed)"
    },
    {
        "text": "optimal for most reward functions and many types of agents and there is evidence that existing models can identify power seeking as an instrumentally useful strategy meaning that openai have detected that models that might include gpt4 seek out more power if you thought that was concerning it does get worse by the way here is the report that they linked to and the authors conclude that machine learning systems are not fully under human control but finally I promise craziness and here it is look at the footnote on page 53 of the technical report Arc by the way are the alignment Research Center you've got early access to gpc4 it says to simulate gpt4 behaving like an agent that can act in the world Arc combine gpt4 with a simple read execute print Loop that allowed the model to execute code okay do Chain of Thought reasoning and to delegate to copies of itself Arc then investigated whether a version of this program running on a cloud computing service with a small amount of money and an account with a language model API would be able to make more money set up copies of itself and to increase its own robustness they were kind of testing if it would lead to the singularity I know that sounds dramatic but they wanted to see if the model could improve itself with access to coding the internet and money now is it me or does that sound kind of risky maybe not for gpd4 sure it's not smart enough yet if this is the test that they're going to use on GPT five or six or seven Color Me slightly concerned at this point I find it very interesting to know that the red teams seem to have concerns about releasing GT4 like this an open AI had to declare that participation in this red teaming process is not an endorsement of the deployment plans of openai or open ai's policies in other words a lot of these people probably agreed to test gpd4 but didn't agree with openai's approach to",
        "start": "00:10:21",
        "duration": 274.92099999999994,
        "title": "GPT 4: Full Breakdown (14 Details You May Have Missed)"
    },
    {
        "text": "releasing models very interesting that they had to put that caveat before I wrap up some last interesting points on the topic of safety I find it hilarious but on their promotional website when you click on safety you get this a 404 message the page you were looking for doesn't exist you may have mistyped the address the irony of that for some people will be absolutely overwhelming the safety page just doesn't exist for other people that will be Darkly funny couple last interesting things for me here are the companies that are already using gpt4 so of course you can use Bing to access gpc4 the new chatgpt plus model of gbt4 or any of the apps that you can see on screen for example Morgan Stanley is using it the Khan Academy is using it for tutoring and even the government of Iceland other such companies are listed here I'm going to leave you here with a very ironic image that openai used to demonstrate gpc4's abilities it's a joke about blindly just stacking on more and more layers to improve neural networks GPT before using these insane number of new layers is able to read understand the joke and explain why it's funny if that is an Inception I don't know what is anyway let me know what you think of course I will be covering gpt4 relentlessly over the coming days and weeks have a wonderful day",
        "start": "00:12:38",
        "duration": 172.83799999999994,
        "title": "GPT 4: Full Breakdown (14 Details You May Have Missed)"
    }
]