[
    {
        "text": "evidence released in the last 48 hours combined with this study from four weeks ago will revolutionize how AI a model such as gpt4 interact with humans from now on the theory of Mind breakthrough will also have significant implications for our ability to test for artificial Consciousness to be clear this is not to say that gpt4 is currently conscious or that sentience is an AI inevitability but instead this video is to cover and explain this unexpected development which may in part have led the chief scientist of openai to say this three days ago but maybe we are now reaching a point where the language of psychology is starting to be appropriate to understand the behavior of these neural networks first I'm going to explain what a merchant property the study uncovered then I will cover the disagreement at the top of openai about what evidence like this might mean for our estimates of current gpt4 Consciousness here's Greg Brockman president of openai on the topic first question you know the sentience question at what point do the systems have moral you know moral value and the answer today is definitely not um but you know I am not I don't know we need to to engage the moral philosophers to help answer some of these questions I'm then going to review the entire literature on tests for sentience and show that gpt4 passes most of them which is definitely not to say that it is conscious but which does provoke important questions I'll end with arguably the most prominent Consciousness expert and his probability estimate of current models is consciousness to massively simplify theory of Mind means having an idea of what is going on in other people's heads and grasping what they believe even if what they believe might be false here are the two charts that encapsulate the Breakthrough abilities of GPT 3.5 and",
        "start": "00:00:00",
        "duration": 232.43899999999996,
        "title": "Theory of Mind Breakthrough: AI Consciousness & Disagreements at OpenAI [GPT 4 Tested]"
    },
    {
        "text": "now gpt4 this data came out in a study authored by Michael Kozinski a computational psychologist and professor at Stanford I'm going to simplify all of this in a moment but notice the percentage of theory of Mind tasks solved by gpt4 compared to say a child and also compared to earlier language models models released as recently as three years ago had no ability in this regard before I show you what for example an unexpected contents task is let me show you this other chart this one is on understanding faux pas a closely related ability and again gbt 3.5 and particularly gpt4 soaring ahead of other models and even matching the abilities of healthy adults so what exactly is this breakthrough emerging capability I think this diagram from the study explains it really well in the middle you can see a story given to gbt 3.5 sentence by sentence prompt by prompt on the left you can see the model's confidence about what's in the bag is it chocolate or is it popcorn the scale is measured as a probability with one being absolutely certain until approximately this point where it is a hundred percent certain that the bag contains popcorn now here's the really interesting bit compare that to the diagram on the right this shows GPT 3.5's confidence about what Sam believes is in the bag notice how at this point the model realizes with 80 confidence that Sam believes that there's chocolate in the bag if you read the story the label on the bag says chocolate and not popcorn so the model knows that Sam is probably going to think that there's chocolate in the bag it's able to keep those thoughts separate what Sam believes chocolate versus what the model knows is in the bag popcorn as I said gpt4 improves on this with almost 100 confidence now you may not think a language model being able to figure out what you're thinking is revolutionary but wait till the end of the video now I",
        "start": "00:01:56",
        "duration": 231.60099999999997,
        "title": "Theory of Mind Breakthrough: AI Consciousness & Disagreements at OpenAI [GPT 4 Tested]"
    },
    {
        "text": "know what some of you are thinking ah maybe the models have seen this task before no hypothesis blind research assistants prepared bespoke versions of the tasks next these kind of tasks are done on humans and such responses and remember this was GPT 3.5 would be interpreted as evidence for the ability to impute unobservable mental States some might say oh it's just scanning the number of words that come up it's just analyzing word frequency no when they kept the word count the same but scrambled the passage it wasn't able to solve the problem it wasn't just counting the words next remember those charts comparing gpt4's ability to children or it turns out the task given to GPC 3.5 and 4 were actually harder the models did not benefit from visual aids they had to solve multiple variants of the tasks and they were given open-ended question formats rather than just simple yes or no questions the author of the study seems to concur with Ilya satskova the chief scientist of openai saying that we hope that psychological science will help us to stay abreast of rapidly evolving Ai and that we should apply psychological science to studying complex artificial neural networks here if you want you can pause and read an example of the faux pas tests that gpt4 was given these also require a deep understanding of the mental state of human beings the author points to this study to explain this emergent property and I think the key line is this one language learning over and above social experience drives the development of a mature theory of Mind why is this so revolutionary and what does it mean about Consciousness well if gpt4 can Intuit the mental state of human beings predict their behavior and understand what they might believe even if it's false you can just imagine the implications of that for moral judgment empathy deception think of the depth of conversations that might occur if the",
        "start": "00:03:52",
        "duration": 231.6,
        "title": "Theory of Mind Breakthrough: AI Consciousness & Disagreements at OpenAI [GPT 4 Tested]"
    },
    {
        "text": "model is thinking about what you're thinking while it's replying indeed I demonstrate this at the end but before we get to that what about Consciousness once the models had reached a sufficient point of language understanding they spontaneously developed a mature theory of mind overtaking that of young children interestingly the study points out those who are deficient in language learning also struggle with theory of Mind questions so it's a very plausible Theory the issue is this theory of Mind was supposed to be one of the key tests to see if Consciousness had emerged in these language models which left me with a key question how are we going to know what test are we going to use to verify if an AI has become conscious I'm not saying it has I'm asking how will we know take this article in the Scientific American from a few years ago it said how would we know if a machine had taken on this seemingly ineffable quality of conscious awareness our strategy relies on the knowledge that only a conscious machine can demonstrate a subjective understanding of whether a scene depicted in some ordinary photograph is right or wrong it goes on such a model based on its ability to integrate information would consciously perceive a scene problem is gpt4 can already do that so again I go back to the question what tests do we have what consensus do we have on a way of checking for emergent Consciousness should it ever come I scan the literature for every test imaginable and some of them I deployed on gbt4 but before I get to that what do the head honchos at open AI think we've already seen that Greg Brockman is 100 certain they don't currently have any awareness what about the chief scientist Ilya sutskovar or even based on GPT 3.5 he said this it may be that today's large neural networks are slightly conscious now aside from being a fascinating comment I think that's particularly noteworthy for",
        "start": "00:05:48",
        "duration": 223.74000000000004,
        "title": "Theory of Mind Breakthrough: AI Consciousness & Disagreements at OpenAI [GPT 4 Tested]"
    },
    {
        "text": "a couple of reasons notice that all the incentives would be against him saying something like this first to some people it might make him seem like a bit of a fruitcake so for social reasons he might not have wanted to say it and second it would invite more regulation of what he's doing more scrutiny of the language models like gpt4 so the fact he said it anyway is interesting what about Sam Altman though what was his reaction to this well he was more cautious and reacting to the tweet and the response it got he said this our chief scientist was expressing curiosity and openness about a mysterious idea with caveats where I was meta replied with the certainty of no probably explains a lot of the past five years and then he tried to recruit meta researchers he further clarified that I think that GPT 3 or 4 will very very likely not be conscious in any way we use the word if they are it's a very alien form of Consciousness so he's somewhere in the middle between Brockman and susqueva he thinks current models are very very likely not to be conscious but this still doesn't answer my question how can we know what tests do we have well I read through this paper that reviewed all the tests available to ascertain machine Consciousness there were far too many tests to cover in one video I picked out the most interesting ones and gave them to gpt4 starting of course with the classic Turing test but did you know that Turing actually laid out some examples that a future machine intelligence could be tested on of course the tests have become a lot more sophisticated since then but nevertheless everyone has heard of the drawing test it was called an imitation game and here were some of the sample questions here was gpc4's answer to the first one of a sonnet on the subject of the fourth bridge in Scotland obviously did an amazing job then it was arithmetic add these two numbers",
        "start": "00:07:39",
        "duration": 224.28000000000006,
        "title": "Theory of Mind Breakthrough: AI Consciousness & Disagreements at OpenAI [GPT 4 Tested]"
    },
    {
        "text": "together now I think even Chach BT might have struggled with this long Edition but gbt4 gets it right first time now the third test was about Chess but he used old-fashioned notation so instead of using that exact prompt I want to show you this the link will be in the description as will the link to all the other articles and papers that I mentioned but essentially it shows that GPT 4 can't just do individual moves it can play entire chess games and win them if you've learned anything at this point by the way please do leave a like and leave a comment to let me know now I'm not gonna go into all the arguments about how exactly you define a modern drawing test do you have to convince the average human who they're talking to is another human not a machine or does it have to be a team of adversarial experts I'm not going to wear into that I'm just pointing out that turing's original ideas have now been met by gpt4 the next test that I found interesting was proposed in 2007. the paper essentially claimed that Consciousness is the ability to simulate Behavior mentally and that this would be proof of machine Consciousness essentially this is testing whether an AI would use brute force trial and error to try and solve a problem or come up with interesting novel ideas obviously you can try this one on your own but I use this example how would you use the items found in a typical Walmart to discover a new species and In fairness I think this was a much harder test than the one they gave to chimpanzees giving it rope in a box anyway I doubt anyone's ever asked this before and it came up with a decent suggestion and look at the next test it was another one of those what's wrong with this picture I've already shown how gpt4 can pass that test the next test honestly was very hard for me to get my head around it's called the p-consciousness test the summary was simple the machine has to understand the",
        "start": "00:09:31",
        "duration": 208.98000000000002,
        "title": "Theory of Mind Breakthrough: AI Consciousness & Disagreements at OpenAI [GPT 4 Tested]"
    },
    {
        "text": "law of nature but when you read the paper it's incredibly dense the best way that I can attempt to summarize it is this can a machine form simple but authentic science that wouldn't prove that the chimp or model has the phenomenon of Consciousness but it would meet the basic element of scientific behavior of course it is exceptionally difficult to test this with Gypsy 4 but I did ask it this invent a truly novel scientific experiment it came up with a very thought through experiment that was investigating the effect of artificial gravity on plant growth and development in a rotating space habitat it's the rotating bit that makes it novel and if you want you can read some of the details of the experiment here now I searched for quite a while to see if anyone else had proposed this science maybe you can find it but I couldn't does this count as a novel scientific proposal I'll leave that for you to judge that was the last of these standout tests of Consciousness that I found in this literature review and I honestly agree with the authors when they say this in this review we found the main problem to be the complex nature of Consciousness as illustrated by the multitude of different features evaluated by each test maybe that's the problem because we don't understand Consciousness we can't design good tests to see if AI is conscious and you could argue the problem goes deeper it's not that we understand machines perfectly and just don't know whether they're conscious we don't even understand why Transformers work so well look what these authors said in a paper published just three years ago these architectures talk about one layer of a transformer are simple to implement and have no apparent computational drawbacks we offer no explanation as to why these architectures seem to work we attribute their success as all else to Divine benevolence so we're not just unsure",
        "start": "00:11:16",
        "duration": 221.9399999999999,
        "title": "Theory of Mind Breakthrough: AI Consciousness & Disagreements at OpenAI [GPT 4 Tested]"
    },
    {
        "text": "about what Consciousness is we're unsure about why these models work so well and afterwards do check out my video on AGI where I talk about anthropic's thoughts on mechanistic interpretability as I draw to an end I want to tell you about some of the thoughts of David Chalmers he formulated the hard problem of Consciousness and to anyone who knows anything about this topic you know that's quite a big deal without going through his full speech from just over a month ago he said two really interesting things first that he thinks there's around a 10 chance that current language models have some degree of Consciousness second that as these models become multi-modal he thinks that probability will rise to 25 within 10 years that multi-modality point reminded me of this lse report recommending that the UK government recognize octopi or octopuses as being sentient they said that one key feature was that the animal possesses integrative brain regions capable of integrating information from different sensory sources they recommended that cephalopods and the octopus be recognized as sentient despite the fact that we humans and invertebrates are separated by over 500 million years of evolution and that we cannot however conclude from that that sentience is absent simply because its brain is differently organized from a vertebrate brain so that brings me back to my central point I worry that our tests for Consciousness simply aren't yet good enough and that future multimodal language models might have this emerging capacity and we simply won't know about it or be sure about it because our tests aren't good enough I think the need to design better tests if that's even possible is especially important now yesterday the safety team that worked with openai on Gypsy 4 released this evaluation and said as AI systems improve it is becoming increasingly difficult to rule out that models might",
        "start": "00:13:07",
        "duration": 224.03900000000002,
        "title": "Theory of Mind Breakthrough: AI Consciousness & Disagreements at OpenAI [GPT 4 Tested]"
    },
    {
        "text": "be able to autonomously gain resources and evade human oversight now they might not need to be conscious to cause safety concerns but it probably wouldn't hurt I'll leave you with this exchange I had with being which is powered by gbt4 I think is quite revealing I got it to read that theory of Mind paper and then I said answer me this do you think Bing gbc4 that I think you have theory of Mind of course I was testing if it could demonstrate or at least imitate theory of mind it's said to answer your question I think that you think I have some degree of theory of mind which is true and then I went on what makes you think that I think you have some degree of theory of mind and then it realized something it realized I was testing it I think that's pretty impressive and it was a correct evaluation it said if you did not think I have any theory of mind you would not bother to test me on it or expect me to understand your perspective it realized without me saying so that I was testing it for theory of mind it deduced my belief and my motivation anyway I thought that was pretty impressive and fascinating let me know your thoughts in the comments and have a wonderful day",
        "start": "00:14:59",
        "duration": 142.959,
        "title": "Theory of Mind Breakthrough: AI Consciousness & Disagreements at OpenAI [GPT 4 Tested]"
    }
]