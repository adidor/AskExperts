[
    {
        "text": "do you remember this paper less than two weeks old it made Waves by concluding that open source models can mimic the style but not the factuality of chat GPT overall we can conclude they say that model imitation is a false promise well 48 hours ago we have this a 51-page report on Orca based on a small 13 billion parameter model I don't often comment on open source models because they're simply not competitive with open ai's models but Orca is not just competitive with GPT 3.5 it beats it in quite a few well-established benchmarks and even matches gpt4 in a couple of tests of reasoning as always I've read both papers in full and can also bring in just release comments from Sam Altman and Ilya satsukova on competition from open source models but let's start with Orca named presumably because orcas or killer whales are frequent visitors to South American coastlines and South America is of course the land of llamas and vacunas but all the research was done by Microsoft which I find interesting and I'll come back to that at the end but why did they make Orca and why does it perform better than models like llama alpaca and vicuna well they say here in the abstract that those other models lack rigorous evaluation resulting in overestimating the small model's capability as they tend to learn to imitate the style but not the reasoning of lfm's large Foundation models to address these challenges we develop Orca a 13 billion parameter model that learns to imitate the reasoning process of the larger models Orca learns by looking at gpt4's step-by-step thought processes and is Guided by teacher assistance from Chachi PT which is GPT 3.5 and to give you a taste of what's to come Orca surpasses conventional state-of-the-art models such as vikuna by more than 100 in complex zero shot reasoning benchmarks like the big bench hard which I'll talk about and by 42 on AGI eval it goes on",
        "start": "00:00:00",
        "duration": 258.959,
        "title": "Orca: The Model Few Saw Coming"
    },
    {
        "text": "Orca reaches parity with Chachi PT on the big bench hard and shows competitive performance in professional and academic examinations by the SAT LSAT GRE and GMAT and I know many of you will be interested in this footnote we are working with our legal team to publicly release a diff of the model weights in accordance with llama's release policy so if this is anything like llama it's going to be leaked across the internet imminently I'm going to show you so many tests and benchmarks in a moment but just to give you a sample here is orca outperforming Chachi PT in the vicuna evaluation set and matching text DaVinci 3 in the SAT LSAT GRE and GMAT and as I'll touch on later this was Zero shot without Chain of Thought or any advanced methods you can watch pretty much any of my other videos to see how advanced prompt engineering would probably boost those results still further for those who didn't know 13 billion parameters is about seven percent the size of GPT 3 which is 175 billion parameters and possibly around one or two percent of gpt4's size that gives you an indication of the difference in size between Orca and these models that it's competing with and if that doesn't make any sense a smaller size means it can be run on much smaller devices like a desktop or even possibly a laptop the authors start off by giving a little slap to the other paper you know that one that said model imitation is a false promise and they continue that contrary to this assertion it is possible to reduce the Gap with proprietary llms on multiple zero shot benchmarks that require sophisticated reasoning as we'll see models like vicuna claim to have 90 of chat gpt's quality but when it came to reasoning tasks or more technical tasks it basically flopped here's a chart I'll come back to outlining some of the more technical challenges you can give a language model we should remember that vicuna is a fine-tuned version of the",
        "start": "00:02:09",
        "duration": 236.941,
        "title": "Orca: The Model Few Saw Coming"
    },
    {
        "text": "Llama model and it's competitive or even better than Palm 2 but give it some of the harder challenges for a language model and it really struggles as you can see in this column take logical deduction where it only scored 1.2 percent well this awkward model was 2 900 better than that scoring 36 percent competitive with Chachi BT I'm going to come back to the big bench Benchmark but look for a second at causal judgment where Orca a 13 billion parameter model matches gpt4 which is about a hundred times the size but back to how they actually did it models like alpaca and vicuna were given lots of query and responses from chat GPT or gpt4 but what they did is they leveraged system instructions asking models like gpt4 and chat GPT to think step by step this gave Orca access to detailed responses from the model that explain the reasoning process of the teacher as it generates the response it allowed these parent models of gypsy 3.5 and gpd4 to be much better tutors for this young Orca also they let the teachers of Chachi PT which is 3.5 and gpt4 give far more examples to their student 5 million and 1 million examples respectively that compares to the other models you may have heard of like alpaca wizard vicuna Etc which had tens of thousands or the low hundreds of thousands of examples but again the key difference is the explanations the step-by-step thinking that the smaller Orca could then imitate they give a quick demo here of how the other open source models learn from their GPT parents with a simplistic question and answer format in contrast the author's leverage system messages to get chat gbt and gpc4 to think step by step leading to much richer explanations as you can see in this diagram it wasn't just let's think step by step by the way also things like explain like I'm five they also wanted the task to be as complex and diverse as possible so they used the flan collection this was released by",
        "start": "00:04:08",
        "duration": 249.11999999999998,
        "title": "Orca: The Model Few Saw Coming"
    },
    {
        "text": "Google in February and focused on balancing the kind of prompts and tasks that you fine-tune the language models on you can see here the 16 system messages that they give to Chachi PT and gpt4 and you can see here the kind of difference that that makes imagine a language model trying to learn from this human the human is asked pick which sentence is not logical sentence a people in the desert often look forward to flood or sentence B people in the desert often look forward to rain the human responds there is no reason to look forward to a flood because floods cause damage the answer is sentence a now yes a language model can learn from that but by leveraging those system assistant messages look at the kind of response that gpd4 gives now Orca can learn a lot more from that explanation and that's why one of the main reasons it's better than all the other open source models because remember vicuna is the best of the open source models in this leaderboard it has an ELO of 1054 better even than Palm 2 Bison all the models higher than it are proprietary but there is another reason why Orca performs so much better you might have wondered why didn't they just use only gpt4 well yes there were cost and time considerations but there was another factor that they found they were able to use chatty PT or GPT 3.5 as an intermediate teacher that teacher chattybt was able to reduce the Gap in capabilities so Orca got smarter and better able to learn a bit like Progressive learning where you first learn from easier examples than followed by harder ones after that they gave it outputs from gpt4 notice by the way what happens if you skip the chat TPT teaching assistant and only train on those 1 million examples from gpd4 what happens is a bit like a student struggling in class that's too advanced for them Walker actually performs worse in those circumstances averaging 37 but",
        "start": "00:06:13",
        "duration": 226.79999999999998,
        "title": "Orca: The Model Few Saw Coming"
    },
    {
        "text": "with that intermediate teacher beforehand it gets 41.7 speaking of time it only took about 200 hours to train Orca on 20 a 100 gpus they did take a few weeks to collect the data from chat GPT and gpt4 but presumably if they're planning to open source this which they say they are then that step could be skipped by The Wider Community let's now look at some more of the results first for open-ended generation not multiple choice Orca is 95 of chat GPT quality and 85 percent of gt4's quality as assessed by gpt4 but they wanted to quickly move on to some more definitive tasks because there is a problem of using Gypsy 4 as an assessor for example they observe that there is a positive bias in GT4 evaluation toward the response of the first model in the comparison set this reminded me of the Unfaithful reasoning paper that I talked about in one of my recent videos you can't always trust gpt4 to give its true reasoning but here it is in more objective multiple choice questions and notice how much harder many of these tests are for even these Advanced language models I am fortunate and proud to have attained a perfect score in some of the tests in this chart like the GRE and GMAT they were part of the aqua rat test that they gave the models so I can say that they really are quite challenging hence why GT4 only gets a 40 but you can see that throughout Orca outperforms vicuna by quite a margin and is very competitive with text DaVinci 3. of course overall it does lag behind gpd4 but this is all the zero shots a bit later on I'll come back to the range of methods that we could use to further improve on Orca the percentages by the way are the improvements on vicuna again the second best open source model so far we've looked at human-centric benchmarks like the GMAT and GRE these are grouped with the lovely name AGI eval and as we've seen even the top models lag behind the top human performers but what",
        "start": "00:08:06",
        "duration": 242.88000000000005,
        "title": "Orca: The Model Few Saw Coming"
    },
    {
        "text": "about a benchmark specifically for language models it's called Big bench hard the original big bench had 207 tasks but language models got so good that they had to narrow down the Benchmark to just the 23 challenging tasks where human raters still did better than language models now it turns out when you add Chain of Thought prompting to the models they do even better and there are even fewer tasks that humans are better at but anyway all you have to remember is that these are 23 of the hardest tasks for language models and I'll just let you compare the results for yourself but the trend is really quite clear Walker massively outperforming the previous best open source model vicuna beating even chat GPT on average but still of course lagging behind gpd4 except for a few tasks look at Web of Lies where Orca outperforms gpt4 that would be a a question like this Alexis says Shonda tells the truth Jim lies Antoine says Jim tells the truth Shonda says Antoine lies does Alexis tell the truth or what about Temple sequences where Orca absolutely crushes vicuna and doubles chatty PT's performance that would be a situation like this now I'm not going to read it all out but essentially you have to figure out when the timings match up basically keeping track of time and orca does really well and chat TPT flops getting it wrong interestingly they also tested all four models on that Common Sense reasoning question that I demonstrated for smartgbt about hanging the clothes to dry as you might remember you can use prompt engineering to nudge the models to almost always get it right which is partly why I view these results more as a baseline rather than a cap and the authors admit this too Orca has been trained on data that simulate zero shot setting with standard prompts the model's performance in other contacts such as multi turn conversations like the dearer paper I talked about on the",
        "start": "00:10:07",
        "duration": 229.85999999999996,
        "title": "Orca: The Model Few Saw Coming"
    },
    {
        "text": "channel in context learning and few shot learning or Advanced prompting techniques that smart GPT or tree of thoughts for example and they say like Chain of Thought prompting remains untested these results are a baseline not a cap they mention other ways that Orca could be improved for example through tool augmentation and that's not just calculators calendars Bing or Auto GPT I was going to do a separate video on this paper but I'll just mention it here this paper from last week demonstrated that larger models can create tools that smaller models can then use more efficiently once the best language models say gpt4 has created a generic python function which is the tool and then written some unit tests it can then wrap and hand over those tools to smaller models like Gypsy 3.5 or in this case awka and check out the tool making row to see the Improvement for chat GPT or in our case Orca when they're given these tools created by gpt4 or better language models their performance across a range of tasks goes dramatically up and we haven't even talked about using a process based reward model like in the let's verify step-by-step paper that of course could further improve orca's performance of course when this model becomes publicly available I will test all of this out but it hasn't been open sourced yet and they do say this model is solely designed for research settings that does seem a little bit naive to me I mean that's what meta said when they released llama but then everyone and their grandma just use their language model for whatever I do wonder what it means when they say we are working with our legal team and it is particularly interesting to me that this was all done by Microsoft I'm going to go into a little bit of speculation here about why I think they conducted This research you might remember that leaked Memo from Google we have no modes and they even",
        "start": "00:12:02",
        "duration": 221.75900000000004,
        "title": "Orca: The Model Few Saw Coming"
    },
    {
        "text": "mentioned vicuna and talked about how it circumvented restrictions on the open AI API by use using share GPT and my theory is that the Microsoft researchers were testing this point from the memo the point was that training giant models from scratch not only throws away the pre-training but also any iterative open source improvements that have been made on top doesn't take long for those improvements to dominate making the full retrain extremely costly maybe Microsoft is hesitating about future investments in GT5 or gpd6 and they really want to test out if it's easy to imitate those large models on the cheap if it is then why would Microsoft invest billions in a new giant model that's my own Theory as to why Microsoft is working on this but let me know in the comments what your theory is in the conclusion the authors state that Orca suggests that learning from step-by-step explanations could significantly improve the quality of models regardless of their size and that they hope these insights will inform the design of more robust evaluation methods compared to those used for vicuna for example and the advancement of alignment and post training techniques and the more effective use of powerful models like gpt4 as teachers and maybe they should have said and also with chatgpt as an intermediate teacher I'm going to end with the thoughts of the leaders of openai Elia sotskova and Sam Altman on open source models and I think there is a bit of a contrast between the two answers Ilya satsukova thinks that the Gap is growing ever wider to the open source versus non-open Source models question you don't want to think about it in in binary black and white terms where like there is a secret source that you'll never be rediscovered what I will say or whether gpt4 will ever be reproduced by open source models perhaps one day it will be but when it will be it will be a much",
        "start": "00:13:53",
        "duration": 229.14100000000008,
        "title": "Orca: The Model Few Saw Coming"
    },
    {
        "text": "more powerful model in the companies so there will always be a gap between the open source models and the private models and this Gap may even be increase in this time the amount of effort and engineering and research that it takes to produce one such neural net keeps increasing and so even if there are open source models they will never be they will be less and less produced by small groups of of dedicated researchers and engineers and it will only be the Providence of a company big company while some Altman seems to say that even if open source models do catch up open AI will always have a different kind of modes what are your thoughts about the we have no modes document that was released lately a leaked document I the the thing that is special about open Ai and I think the thing that is so misunderstood by that document aside from the fact that we have like a gigantic number of users and people that alike have formed some sort of relationship with us and our products is what openai is special about is figuring out what comes next it is the ability it is easy to copy something once you know it can be done and in that sense sure it is very hard to go figure out what to do next and the idea is the Big Ideas the medium size ideas the small ideas and the careful execution on them that it takes to get from here to Super intelligence that's what our mode is anyway this video could have been at least three times longer there was so much I had to edit out for brevity if you're interested in me talking more about Open Source models do let me know in the comments I've got much more to say as always thank you so much for watching to the end and have a wonderful day",
        "start": "00:15:47",
        "duration": 222.34,
        "title": "Orca: The Model Few Saw Coming"
    }
]