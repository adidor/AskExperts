[
    {
        "text": "just this week we have had open AI tell us that super intelligence might need to be made safe within four years competing lab leaders say it's decades away and expert warnings that AI might have runaway power within two years let's try to unpack those disparate timelines see what might speed up the timing or slow it down show what super intelligence might mean and end with some interesting clips that capture the moment we're in but the first timeline is from Mustafa Solomon head of inflection AI this week if it's so risky why don't you stop I think that the point of raising concerns is that we can see a moment at some point in the future probably over a decade or two decades time Horizon when slowing down is likely going to be the safe and ethical thing to do 10 years is not a long time I find it fascinating that he talks about two decades from now when inflection AI his company have just built the world's second highest performing supercomputer and even as they admit that's three times as much compute as was used to train all of gpt4 telling the public that we have a decade or two before we have to worry about safety seems extremely conservative to me but what do we even mean by transformative AI or super intelligence well here is just one projection of current scaling laws out to 2030 from Jacob steinhardt of Berkeley and here of course we're talking about just six and a half years away if we look at projections of future compute and data availability and the velocity of current Improvement which of course might not hold forever some experts claim that we'll need new Innovations beyond the Transformer but if current projections of future compute and data availability scale up here's the kind of thing that we're talking about being superhuman at tasks including coding hacking mathematics protein engineering doing 1.8 million years of work in 2.4 months learning 4 2 500 human equivalent years",
        "start": "00:00:00",
        "duration": 245.34099999999995,
        "title": "Time Until Superintelligence: 1-2 Years, or 20? Something Doesn't Add Up"
    },
    {
        "text": "in just one day and by training on different modalities such as molecular structures low-level machine code astronomical images and brain scans it might have a strong intuitive grasp of domains where we have limited experience including forming Concepts that we do not have indeed some research released this week show that gpt4 already crushes some benchmarks for creative thinking and the median forecast for being better than all but the very best humans at coding is 2027 and here we have a median forecast of 2028 for AI winning a gold medal at the international math Olympiad the number that I'm looking out for is getting a hundred percent on the mmlu that's a test of 57 different subject matters and I've actually been discussing with some of the creators of the mmlu that we might not even know the full potential of gpt4 on this test officially it's 86.4 percent so we've heard 20 years and six and a half years well how about two this article comes from the Boston Globe that did a feature piece on Dan Hendricks and the center for AI safety they were behind that one sentence letter that was signed by almost all of the AGI lab leaders and World experts on AI the journalists are Stan Hendricks how much time we have to tame Ai and he said well how long till it can build a bio weapon how long till it can hack it seems plausible that all of that is within a year and within two he says AI could have so much runaway power that it can't be pulled back seems a pretty massive contrast to Mustafa Suleiman talking about a decade or two from now I'm going to come back to this article quite a few times but now I want to move on to open ai's recent statement this week they released this introducing super alignment we need scientific and Technical breakthroughs to steer and control AI systems much smarter than us I can just see now all the comments from people saying saying that that's going to be physically impossible but moving",
        "start": "00:02:02",
        "duration": 240.12000000000003,
        "title": "Time Until Superintelligence: 1-2 Years, or 20? Something Doesn't Add Up"
    },
    {
        "text": "on to solve this problem within four years we're starting a new team co-led by Ilya satskova and Jan Leica and dedicating 20 of the compute we've secured today to this effort that is quite a remarkable statement to their credit they've made themselves accountable in a way that they didn't have to and that others haven't and they're deploying one of the legends of deep learning Ilya sotskova to help them achieve this goal they say that super intelligence will be the most impactful technology Humanity has ever invented and I agree with that and it could help us solve many of the world's most important problems absolutely but the vast power of super intelligence could also be very dangerous and could lead to the disempowerment of humanity or even human extinction they go on while super intelligence seems far off now we believe it could arrive this decade notice they don't say in a decade they say this decade they go on currently we don't have a solution for stereo or controlling a potentially super intelligent AI they can't prevent it from going rogue and are current techniques for aligning AI rely on humans ability to supervise AI but humans won't be able to reliably supervise AI systems that are much smarter than us and so our current alignment techniques will not scale to Super intelligence I'm going to go into more detail about their plan for aligning super intelligence in another video but here is the high level overview essentially they want to automate alignment or Safety Research build an AI alignment researcher I've read each of these papers and posts and some of them are very interesting including automated red teaming and using a model to look inside the internals of another model but the point of including this post in this video was the timeline of four years twenty percent of their compute is millions and",
        "start": "00:04:02",
        "duration": 222.17999999999998,
        "title": "Time Until Superintelligence: 1-2 Years, or 20? Something Doesn't Add Up"
    },
    {
        "text": "millions and millions of dollars and four years is a strict deadline and one of the most interest interesting aspects of this post came in one of the footnotes they say solving the problem includes providing evidence and arguments that convince the machine learning and safety community that it has been solved that is an extremely high bar to set yourself they go on if we fail to have a very high level of confidence in our Solutions we hope our findings let us and the community plan appropriately that's probably one of the most interesting sentences I've read for quite a while if we fail to have a very high level of confidence in our Solutions we hope our findings let us and the community plan appropriately in other words if they can't make their models safe they're going to have contingency plans and they want the community to have plans as well and it is a really interesting number isn't it four years not even around five years or just end of the decade and it does make me wonder what Ilya satskaver thinks is coming within four years to have such a deadline now apparently the prediction markets give them only a 15 chance of succeeding and the head of alignment at open AI said he's excited to beat these odds so we've heard about one to two years and about four years but what might slow those timelines down the other day I read this fascinating paper coincidentally co-authored by Jacob steinhardt on jailbreaking large language models the paper showed that you could basically jailbreak gpt4 and Claude a hundred percent of the time using a variety of techniques and that is fascinating to me as we approach the one year anniversary of the creation of gpt4 and the relevance to Super intelligence is that if the creators of these models can't stop them being used to commit crimes then you would think that they might have to dedicate more and more of their efforts in stopping",
        "start": "00:05:54",
        "duration": 223.199,
        "title": "Time Until Superintelligence: 1-2 Years, or 20? Something Doesn't Add Up"
    },
    {
        "text": "jailbreaks versus working on capabilities for obvious reasons I'm not going to go into too much detail on jailbreaking here but here is Claude plus from anthropic telling me how to hotwire a car and to be honest that's just the most innocent one and yes it did also work on gpt4 I did find one of the reasons why it does work quite interesting though that reason is about competing objectives where it's compulsion to predict the next word successfully overrides its safety training and so because those two facets of smartness clash inside the model it's not an issue that can be fixed with more data and more scale what else might slow down the work on super intelligence well lawsuits and possible criminal sanctions Yuval Noah Harari recently said that AI firms should face prison over the creation of fake humans and he was saying this to the United Nations he called for sanctions including prison sentences to apply to tech company Executives who fail to guard against fake profiles on their social media platforms of course those Executives might well blame the AI companies themselves but Harare said that the proliferation of fake humans could lead to a collapse in public trust and democracy now it's possible for the first time in history to create fake people billions of fake people if this is allowed to happen it will do to society what fake money threatened to do to the financial system if you can't know who is a real human trust will collapse what's another famous roadblock to Super intelligence hallucinations I've already talked in another video about how salmon thinks that won't be an issue in 18 to 24 months but here again is Mustafa Suleman on the issue of hallucinations yesterday he said soon llms will know when they don't know they'll know when to say I don't know or instead ask another AI or ask a human or use a different tool or a different",
        "start": "00:07:46",
        "duration": 220.8009999999999,
        "title": "Time Until Superintelligence: 1-2 Years, or 20? Something Doesn't Add Up"
    },
    {
        "text": "knowledge base this will be a hugely transformative moment and on that I agree hallucinations are probably one of the biggest hurdles stopping most people from using llms more commonly it's not about knowing more it's about when these models bullcrap less or the moment when they don't bull crap at all but what about things that could actually speed up the timelines to Super intelligence going back to the Boston Globe ask school one thing could be competition for military Supremacy which has already produced a startling turn to Automation and that's not just Robotics and autonomous drones that's the llms that might control them here is a snippet of a trailer for a Netflix show released today [Music] AI is a dual edged sword a flip of a switch and the technology becomes lethal there is no place that is Ground Zero for this conversation more than military applications forces that are supported by AI will absolutely crush and Destroy forces without militaries are racing to develop AI faster than their adversaries the AI unless it's told to fear death will not fear death there is no second place in Warren if you're going up against an AI pilot you don't stand a chance if language models prove useful in war the amount of investment that's going to go into them will Skyrocket of course investment doesn't always equal Innovation but it usually does and one of the other things that could speed up timelines is the automation of the economy for detail on why it might check out the paper linked above and in the description but the high level overview is this as AI grows more capable and ubiquitous companies will be forced essentially to hand over increasingly high level decisions to AIS in order to keep up with their Rivals if an AI as CEO does a better job for stockholders",
        "start": "00:09:35",
        "duration": 229.97999999999996,
        "title": "Time Until Superintelligence: 1-2 Years, or 20? Something Doesn't Add Up"
    },
    {
        "text": "how long can a company resist employee them and of course it doesn't just have to be white collar work as Andre carpathy said welcome to the Matrix for apples but the thing is whether we're talking about one year or four years or six Super intelligence is coming pretty soon and it is interesting to me that so much of society is carrying on as if it's not coming take these 50 year long mortgages that are available in the UK how can anyone plan out 50 years from now in a world where we might have super intelligence in five of course I do think we all need to start defining terms a bit better and I've tried to do that on this channel with AGI and super intelligence I don't think it's quite good enough to give vague reassurances of a decade or two from now how we're going to react when super intelligence arrives is anyone's guess we might be crushed by the sense of inferiority as Douglas hofstetter recently said or some of us might become like Curious children speaking to a wise adult just the other day I got a foreshadowing of my own reaction by speaking to Pi the model from inflection AI it is designed to be extremely human-like and the conversations can be quite startling and personal of course just imagine when they're super intelligent and multimodal anyway let me know your thoughts in the comments and as always have a wonderful day",
        "start": "00:11:34",
        "duration": 164.981,
        "title": "Time Until Superintelligence: 1-2 Years, or 20? Something Doesn't Add Up"
    }
]