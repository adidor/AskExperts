[
    {
        "text": "in the last few days Sam Altman the CEO of openai has publicly stated how much money he expects the company to make and how he intends to distribute it many people will assume he is bluffing but I think GT4 shows that he's not this video will cover his plans his predictions of massive inequality and open ai's new paper on job impacts together with just released studies that back it all up but let's start with money this week in the New York Times he said that his Grand idea is that openai will capture much of the world's wealth through the creation of AGI and then redistribute this wealth to the people and yes he mentioned several figures a hundred billion dollars one trillion even a hundred trillion dollars if openai make even a fraction of these figures Sam Altman will become one of the most important people on the planet that's not to say that he would become that rich The Wall Street Journal this week reported that he has no direct Financial stake in the business but deciding where trillions of dollars of wealth go does make you incredibly powerful so where does he want all the money to go well he seems to have two main ideas plus a third one that I'll touch on at the end his first idea is Ubi or Universal basic income we also have funded the largest and most comprehensive Universal basic income study as sponsored by open Ai and I think it's like an area we should just be be looking into how exactly would that work well he laid out his theory in this blog post and he began it with this he says he's reminded every day about the magnitude of socioeconomic change that is coming sooner than most people believe he said that the price of many kinds of Labor which drives the costs of goods and services will fall towards zero once sufficiently powerful AI joins the workforce he said that that was great for people buying products but not so much for those working to earn a wage so where would their money come from he",
        "start": "00:00:00",
        "duration": 220.32000000000005,
        "title": "Do We Get the $100 Trillion AI Windfall? Sam Altman's Plans, Jobs & the Falling Cost of Intelligence"
    },
    {
        "text": "proposed something called the American Equity Fund it would be capitalized by taxing companies that were above a certain valuation 2.5 percent of their market value each year and it would also be funded by taxing 2.5 percent of the value of all privately held Land by his calculation that will be worth around 13 500 in about twenty Thirty and he said that that money would have much greater purchasing power than it does now because technology would have greatly reduced the cost of goods and services it does raise the question for me though about those countries that aren't the home of massive AI companies where are they going to get the wealth from on Lex Friedman's podcast he admitted it wasn't a full solution I think it is a component of something we should pursue it is not a full solution I think people work for lots of reasons besides money he thinks much more will be needed because the cost of intelligence could fall to almost zero my basic model of the next decade is that the marginal cost of intelligence and the marginal cost of energy are going to Trend rapidly towards zero like surprisingly far so what is his other main idea simply use the money to fund science are you planning to take the proceeds that presumably you're presuming you're going to make some day and you're going to give them back to society I mean is that yeah whether we do that just by like saying here's cash for everyone totally possible or whether we do that by saying like gonna like invest all of this in a non-profit that does a bunch of science because scientific progress is how we all make progress unsure but yeah we would like to operate for for the good of society even with these two ideas he admits there's still a big problem as he put it recently he sees a lot of people getting very rich in the short to medium term but others might not fare as well if it is as divergent as I think it could be for like some people doing",
        "start": "00:01:50",
        "duration": 209.76000000000005,
        "title": "Do We Get the $100 Trillion AI Windfall? Sam Altman's Plans, Jobs & the Falling Cost of Intelligence"
    },
    {
        "text": "incredibly well and others not I think Society just won't tolerate it this time samuelman isn't the only one making predictions open AI itself released this paper around 10 days ago it calculated that with access to a large language model about 15 of all work tasks in the US could be completed significantly faster at the same level of quality but crucially when incorporating software and tooling built on top of llms this share increases to around 50 percent of all tasks that is a colossal impact For Better or Worse just with gpd4 plus software on page 17 of the paper it had this table which I think captures a lot of the interesting analysis let me briefly explain what it shows we have a column of example occupations in the middle and the the education that is required for each of them and the job preparation but the numbers on the right are where it gets interesting these are the percentages of exposure graded Alpha Beta And Zeta the human assessment of exposure is titled H and the M is for the machine assessment they actually got gpt4 to do an assessment too notice that for the most part gbt4 agrees with the human assessors so what are these three grades Alpha is the proportion of tasks in these occupations affected by current language models alone without any further advances or Integrations beta represents the percentage of tasks exposed in a realistic scenario of language models plus a bit of software integration and a few advances you could think of it as their median prediction finally Zeta is a bit like their most extreme scenario with full adoption of software plus advances of llms by the way we're not talking gc5 here or text video just basic software integration like a longer context window or text to image the trend that immediately stuck out for me was how when you go up the educational levels and these salary ranges the effects of these large language models on task exposure goes up",
        "start": "00:03:35",
        "duration": 232.50000000000003,
        "title": "Do We Get the $100 Trillion AI Windfall? Sam Altman's Plans, Jobs & the Falling Cost of Intelligence"
    },
    {
        "text": "and up and up until you reach master's degree or higher levels then it seems to dip down a little maybe this is why Sam Altman predicted inequality the people on the very Cutting Edge of science would still get paid well probably better than ever but there may be a further hollowing out of the middle class with working class occupations left largely untouched the paper also touches on why so few people might be currently focused on language models I don't know about you but have you noticed that feeling where it seems to be us being super interested in this technology with most people not being that interested well here might be one reason why currently only three percent of U.S workers have over half of their tasks exposed to llms but that's only when considering existing language and code capabilities without additional software or modalities so not that many people are seeing a massive change in their work but it says that when we account for other generative models and complementary Technologies are human estimates indicate that up to 49 of workers could have half or more of their tasks exposed to llms whether this means doubling the amount of work done or halving the number of workers doing it I'll talk more about later in the video but maybe this was the dramatic economic impact that Ilya satsukver once predicted on Lex Friedman what do you think is the bar for impressing us do you think that bar will continuously be moved definitely I think when you start to see really dramatic economic impact that's when I think that's in some sense the next barrier because right now if you think about the work in AI it's really confusing it's really hard to know what to make of all these advances the paper also points out that the growing economic effect of llms is expected to persist and increase even if we hold the development of new capabilities today they refer to recent",
        "start": "00:05:31",
        "duration": 217.199,
        "title": "Do We Get the $100 Trillion AI Windfall? Sam Altman's Plans, Jobs & the Falling Cost of Intelligence"
    },
    {
        "text": "study bodies revealing the potential of llms to program and control other digital tools such as apis search engines and even other generative AI systems in my previous video on the self-improvement in GT4 I mentioned hugging GPT but I am doing a lot of research on the new Microsoft Jarvis model and auto gbt I'm hoping to bring to you soon but interestingly there were some tasks that neither Gypsy 4 nor the human assessors could quite agree on in terms of the impact that llms would have even gpd4 couldn't quite figure out if meetings and negotiations would carry on or to what extent counseling or other jobs that involve empathy would be affected and the paper concludes with this the power of relatively simple user interface improvements on top of models like Gypsy 4 was evident in the rollout of chat GPT wherein versions of the underlying language model had been previously available via API usage skyrocketed after the release of the chat GPT internet it's a great Point once these models are made easy to use that could change everything the paper then picks up on a particular survey that shows worker adoption of llms here is the survey with the rather dramatic headline of one in four companies have already replaced workers with Chachi BT I don't think that assertion is fully backed up by the evidence but they did survey 1 000 U.S Business Leaders and there were some interesting findings on the question of replacing workers it says that when asked if Chaturbate will lead to any workers being laid off by the end of 2023 33 of Business Leaders say definitely while 26 say probably others are a bit more optimistic Goldman Sachs said this this economic analysis was published only a few days ago and they say about seven percent of workers will be fully displaced over the next 10 years but that most are able to find new employment in only slightly less",
        "start": "00:07:20",
        "duration": 231.60099999999994,
        "title": "Do We Get the $100 Trillion AI Windfall? Sam Altman's Plans, Jobs & the Falling Cost of Intelligence"
    },
    {
        "text": "productive positions they also predicted that generative AI will raise overall labor productivity growth by around 1.5 percentage points per year which effectively doubles the rate going back to Sam Altman last week he was asked about this augmentation versus replacement question so in terms of really replace jobs is that a worry for you it is uh I'm trying to think of like a big category that I believe can be massively impacted I guess I would say customer service is a category that I could see there are just way fewer jobs relatively soon I'm not even certain about that but I could believe it whatever call center employees are doing now I found that last comment on call Center's quite interesting given that the gc4 technical report talked about using language models for upskilling in call centers so does this mean immense productivity in the short term but replacement in the long term a couple days ago Sam Altman put it like this I always try to be honest and say in the very long term I don't know what's going to happen here and no one does and I I'd like to at least acknowledge that in the short term it certainly seems like there was a huge overhang of the amount of output the world 1 and if people are way more effective they're just doing way more we've seen this first with codeine and people that got Early Access to co-pilot reported this and now that the tools are much better people report it even more yep but we're now in this sort of gpt4 era seen it in all sorts of other jobs as as well where you give people better tools and they just do more stuff better stuff the productivity point is backed up by experiments like this when developers were split into two groups half that used openai's co-pilot and half that didn't not only did more of those who use copilot finish 78 to 70 they finished in less than half the time this paper from a few weeks ago shows that when white collar professionals",
        "start": "00:09:16",
        "duration": 211.92000000000004,
        "title": "Do We Get the $100 Trillion AI Windfall? Sam Altman's Plans, Jobs & the Falling Cost of Intelligence"
    },
    {
        "text": "were given a language model like chatbt the time they took to do writing tasks dropped massively compared to the control group you can see that they took less than 20 minutes versus almost 30. and when the assisted group and control group were blindly graded you can see that the mean grade was higher for those who use the language models but surely if productivity goes up that means higher wages for those jobs well not necessarily a couple of days ago Sam Altman laid out how it might be more efficient to use one worker to do the tasks of two or three there's a huge cost premium on work that has to be split across two people there's the communication overhead there's the the miscommunication there's everything else and if you can make one person twice as productive you don't do as much as two people could do maybe you do as much as three and a half or four people could do and for many kinds of tasks but is there anything that might slow this economic impact down I think there might be a few things starting with politics this survey from Youth Of America was released only three days ago and while I think it is a somewhat leading question it does show that over 69 of Americans would support a six-month pause on some kinds of AI development and if we see dramatic negative economic impact I expect that figure would go higher politicians would then be in incentivized to slow down tax and or regulate AI development indeed two days ago President Biden tweeted this when it comes to AI we must both support responsible Innovation and ensure appropriate guard rails and also don't forget if you live in a country where English is not the main spoken language gpt4 isn't as good notice that in many languages found in India GT4 is worse performing than the previous model GPT 3.5 is in English this is just one reason why Goldman Sachs predicted different levels of Automation in",
        "start": "00:11:01",
        "duration": 223.02,
        "title": "Do We Get the $100 Trillion AI Windfall? Sam Altman's Plans, Jobs & the Falling Cost of Intelligence"
    },
    {
        "text": "different countries the next Factor could be cultural pushback when Levi's wanted to test AI generated clothing models and they said their reason was to increase diversity that announcement was met with backlash they then had to back down slightly and say that they're not replacing the job of any model if people vote with their wallets for human-made goods and services that could have a massive impact and there is another big factor people seem to intrinsic quickly prefer human-made output to machine generated output this piece came out recently from wired and in it they test the brain chemical reaction to human-made Art and computer made art these were the same pictures it's just that sometimes people were told they were made by humans and other times they were told they were made by computers it says a clear winner emerged people not only claimed to prefer the identical human made pictures their brain's pleasure sensors actually lit up more brightly so human goods and services may have the edge simply by virtue of being made by humans but I want to end the video where I began it with samuelman's piece in the New York Times some of you may have noticed that I said Sam Altman had a third idea of how to distribute the wealth that I would mention at the end well he admitted if AGI does create all that wealth he is not sure how the company will redistribute it money could mean something very different in this new world but what's the idea he said I I feel like the AGI can help with that maybe GPT 5 will decide where the money made using Gypsy 5 will go thank you so much for watching to the end and have a wonderful day",
        "start": "00:12:53",
        "duration": 201.94,
        "title": "Do We Get the $100 Trillion AI Windfall? Sam Altman's Plans, Jobs & the Falling Cost of Intelligence"
    }
]