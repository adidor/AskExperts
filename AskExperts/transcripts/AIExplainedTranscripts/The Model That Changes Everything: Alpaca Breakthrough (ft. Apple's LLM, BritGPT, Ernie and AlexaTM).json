[
    {
        "text": "a little on the 72 hours ago a language model was released that could end up being as consequential as gpt4 now I know you were thinking that's a bowl claim but let's see if you agree with it after watching what happened I will explain as best as I can what was released and how revelations in the last 24 hours from Apple Amazon Britain and Baidu make it particularly significant the model was Stanford's alpaca and here is the key line alpaca behaves qualitatively similarly to open ai's text DaVinci 3 while being surprisingly small and easy and cheap to reproduce at under 600 now that is cool but how does that change the world well first it wasn't supposed to get this cheap this fast just six weeks ago or five weeks before they released the model Arc Investment Management put out this prediction that the 2020 cost of GPT 3 at 4.6 million dollars would take until 2030 to fall to something as insignificant as 30 dollars if Stanford have done what they claim then 99 of this cost reduction has happened within five weeks of this prediction being published not eight years as AI researcher Elie Isa yudkowski puts it I don't think people realize what a big deal it is that Stanford retrained a llama model by cheaply fine-tuning it now I'm going to explain all of this in a moment it then goes on I'm not sure I can convey how much this is a brand new idiom of AI as a technology now Stanford claimed their model performs comparably to DaVinci 3 which is GPT 3.5 of course I'm going to test and analyze this in a moment but how could it be that a 600 model can compete with chat gbt well do you remember how meta open sourced their llama models about two weeks ago Stanford used the weakest of these open source models these seven billion parameter one and then essentially they recruited GPT 3.5 to train that meta model how could they possibly do this well they used self-instruct and I dug",
        "start": "00:00:00",
        "duration": 274.4389999999999,
        "title": "The Model That Changes Everything: Alpaca Breakthrough (ft. Apple's LLM, BritGPT, Ernie and AlexaTM)"
    },
    {
        "text": "into the literature to find the original paper on self-instruct this was released in December of last year and I'm going to give you the 30 second summary of how it works essentially you start off with some human-made examples of Exemplar prompts and outputs these are fed into the language model and then you ask it to generate thousands more such instances you filter out the bad ones and then put all the good examples back into the language model then it understands the instructions much better and produces thousands more examples as the paper says this is Almost Human annotation free and remember this stat it only leaves a five percent Gap behind instruct GPT what is instruct gbt well it's the Breakthrough that led to chat GPT in the first place look at the original gpt3 if you gave a prompt like explain the moon landing to a six-year-old in a few sentences you've got this gobbledygook here after months of onerous human training called reinforcement learning with human feedback he was able to follow instructions much better and produce an outcome like this but this relied on so much human labeling and human ranking of outputs from best to worst Stanford and the self-instruct breakthroughs showed that you could cut all of those costs so in summary they used an open source meta model and got GPT 3.5 to train it one Advanced model teaching another as yudkowski points out these models have enough pseudo-intelligence that they can stare at other models and imitate them indeed openai may have even predicted that this was possible in their terms of service it says you may not use output from the services like Chachi BT to develop models that compete with openai so they knew it was possible and even Stanford admit that this breakthrough enables more people including Bad actors to create new cheap models yutkowski also points out that one of the reasons reasons why chat GPT and gpd4 are so",
        "start": "00:02:17",
        "duration": 234.11999999999995,
        "title": "The Model That Changes Everything: Alpaca Breakthrough (ft. Apple's LLM, BritGPT, Ernie and AlexaTM)"
    },
    {
        "text": "good is that they rest on proprietary data and that that was supposed to give them a competitive moat which is now revealed people can quite cheaply steal just before I test and demonstrate our packer in action let me summarize how it works using the self-instruct process you get GPT 3.5 similar to chat gbt to create thousands and thousands in this case 52 000 instruction following examples automatically filtered by quality Stanford then used an open source model indeed the weakest of the Llama models and trained it using those examples the end result alpaca so let's see in action and compare it to Chachi PT and gbt4 oh and just quickly you know that training of the Llama model with those 52 000 examples it only took three hours and cost less than a hundred dollars the first example I'm going to show you does not come from me I found it in this academic paper Linked In the description and it's a task which requires understanding detailed and dissonant scenarios applying appropriate legal precedence and choosing the correct explanation the correct answer if you want to read through it or not is B alpaca gets this question right or I should say it gets it right about 80 of the time you can keep clicking generate and sometimes you do get the answer D but about 80 of the time four times in five you get the correct answer B how about chatty BT well every time I've tried it it's gotten the wrong answer of c and gpt4 shocking even to me it also gets it wrong and picks C now before you get too excited I am not saying that it is better than or even as good as gbc4 or chat GPT it's not but remember it's only 7 billion parameters and 600 worth take this example I asked it for an example of an animal that begins with the same letter as the capital city of France and it said elephant no idea where it got that now In fairness chapter BT gave me lion and gbc4 gave me ferret but there are other questions",
        "start": "00:04:14",
        "duration": 238.081,
        "title": "The Model That Changes Everything: Alpaca Breakthrough (ft. Apple's LLM, BritGPT, Ernie and AlexaTM)"
    },
    {
        "text": "where alpaca definitely flops for example this math question which Chach BT and gbt4 uniformly get right alpaca simply gets it wrong every time I tried asking it in lots of different ways with Chain of Thought prompting but no every time it gets it wrong it's definitely not better than those models but by the end of the video you'll see why it's revolutionary anyway at this point if you're learning anything please don't forget to leave a like or a comment to let me know basic addition and subtraction it does better and yes it can crank out poems solve some hella swag Common Sense problems and generate literary analogies but at this point I want to remind you of three things first that it was using the weakest of the Llama open source models they could have used these 65 billion parameter model for a bit more cost I'm sure the results would have been even more impressive next you remember it was trained by examples generated using the DaVinci 3 Model well that cost them about 0 0.03 dollars per 1000 tokens but as 48 hours ago they could have used the gpt4 API at a very similar cost so it wasn't the best open source model and it wasn't trained by the best GPT model I am genuinely curious as to what the results would have been if it had been trained by the 65 billion parameter model using a gpt4 API maybe someone's going to do that maybe even this week but just before we get on to Apple Amazon Britain and Baidu I just want to restate this was all done for 600 or less they even say there were training efficiencies they could have done for example using the h100 gpus that would have further reduced the cost the question is if it's so easy and cheap to imitate a larger model what's going to happen when Apple released their large language model it was only revealed yesterday in the New York Times that they are indeed working on one and don't forget they have far more money than the other companies",
        "start": "00:06:13",
        "duration": 230.39899999999994,
        "title": "The Model That Changes Everything: Alpaca Breakthrough (ft. Apple's LLM, BritGPT, Ernie and AlexaTM)"
    },
    {
        "text": "mentioned Amazon recently stated that they have been working on similar Tech to chat gbt for a long time and looking in the literature as early as mid last year they had a model called Alexa TM that outperformed gpt3 and as you may already know but I do demonstrated their Ernie bot today although they didn't allow anyone else to use it apparently it's better in the Chinese language than even gpt4 but because they didn't release a paper and we can't check it we simply don't know and of course we can't forget Google who just two days ago announced the Palm API what would have happened if Stanford's model had used that one I'm sure we will soon find out but to take us back to the start I have one overriding observation and two questions first these models weren't supposed to get this cheap this fast that is going to upend the economics of large language models my questions are these does this mean that all incentive is gone for Microsoft or Google to pour in billions of dollars producing these Cutting Edge models if anyone can just easily reproduce them will they react by making the models even more closed and disallowing gpt5 from having an API we don't know but as even Nation States enter this quote-unquote arms race spending hundreds of millions of pounds in this case to build great GPT are these companies and governments drifting into a war on two fronts where they compete with each other but also with Outsiders who are trying to cheaply imitate their models if you've learned anything in this video please do leave a like and leave a comment but either way have a wonderful day",
        "start": "00:08:08",
        "duration": 200.861,
        "title": "The Model That Changes Everything: Alpaca Breakthrough (ft. Apple's LLM, BritGPT, Ernie and AlexaTM)"
    }
]