[
    {
        "text": "there were 12 particularly interesting moments from samuelman's testimony to Congress yesterday they range from Revelations about gbt5 self-awareness and capability thresholds biological weapons and job losses at times he was genuinely and remarkably Frank other times less so Millions were apparently taken by surprise by the quote bombshell that Altman has no equity in openai but Watchers of my channel would have known that six weeks ago from my deep dive video on Altman's 100 trillion dollar claim so that clip didn't make the cut but here's what did first almond gave a blunt warning on the stakes my worst fears are that we cause significant we the field the technology the industry caused significant harm to the world it's why we started the company it's a big part of why I'm here today and why we've been here in the past I think if this technology goes wrong it can go quite wrong I don't think Congress fully understood what he meant though linking the following quote to job losses I think you have said and I'm going to quote development of superhuman machine intelligence is probably the greatest threat to the continued existence of humanity end quote you may have had in mind the effect on on jobs that brought to mind this meme reminding all of us that maybe it's not just jobs that are at stake but if we are going to talk about jobs here's where I think Sam Altman was being less than forthright I believe that there will be far greater jobs on the other side of this and the jobs of today will get better right notice he said far greater jobs not a greater number of jobs because previously he has predicted a massive amount of inequality and many having no jobs at all he also chose not to mention that he thinks that even more power will shift from labor to Capital and that the price of many kinds of Labor will fall towards zero that is presumably why open AI is working on universal basic income",
        "start": "00:00:00",
        "duration": 232.43800000000005,
        "title": "'This Could Go Quite Wrong' - Altman Testimony, GPT 5 Timeline, Self-Awareness, Drones and more"
    },
    {
        "text": "but none of that was raised in the testimony the IBM representative try to frame it as a balance change with new jobs coming at the same time as old ones going away new jobs will be created many more jobs will be transformed and some jobs will transition away but that didn't quite match the tone of her CEO who has recently said that they expect to permanently automate up to 30 of their Workforce around 8 000 people next it was finally discussed that large language models could be used for military applications could AI create a situation where a drone can select the target itself I think we shouldn't allow that or can it be done sure thanks we've already seen companies like palantir demoing ordering a surveillance drone in chat seeing the Drone response in real time in a chat window generating attack option recommendations Battlefield route planning and individual Target assignment and this was all with a 20 billion parameter fine-tuned GPT model next Samoan and gave his three safety recommendations and I actually agree with all of them later on he specifically excluded smaller open source models number one I would form a new agency that licenses any effort above a certain scale of capabilities and can take that license away and ensure compliance with safety standards number two I would create a set of safety standards focused on what you said in your third hypothesis as the dangerous capability evaluations one example that we've used in the past is looking to see if a model can self-replicate an Excel self-exfiltrate into the wild we can give your office a long other list of the things that we think are important there but specific tests that a model has to pass before it can be deployed into the world and then third I would require independent audits so not just from the company or the agency but experts who can say the model is or isn't in compliance with these",
        "start": "00:01:56",
        "duration": 217.44099999999997,
        "title": "'This Could Go Quite Wrong' - Altman Testimony, GPT 5 Timeline, Self-Awareness, Drones and more"
    },
    {
        "text": "stated safety thresholds and these percentages of performance on question X or Y I found those last remarks on percentages of performance particularly interesting as models like smart gbt will show open Ai and other companies need to get far better at testing their models or capability jumps in the wild it's not just about what the raw model can score in a test it's what it can do when it reflects on them Senator Durbin described this in an interesting way and what I'm hearing instead today is that start me before I innovate again he describes some of those potential thresholds later on in his testimony the easiest way to do it I'm not sure if it's the best but the easiest would be to talk about the amount of compute that goes into such a model we could Define a threshold of compute and it'll have to go it'll have to change it could go up or down I could down as we discover more efficient algorithms that says above this amount of compute you are in this regime what I would prefer it's hard to do but I think more accurate is to Define some capability thresholds and say a model that can do things X Y and Z up to all to decide that's now in this licensing regime but models that are less capable you know we don't want to stop our open source Community we don't want to stop individual researchers we don't want to stop new startups can proceed you know with a different framework thank you as concisely as you can please stay which capabilities you'd propose we'd consider for the purposes of this definition a model that can persuade manipulate influence a person's Behavior or a person's beliefs that would be a good threshold I think a model that could help create novel biological agents would be a great threshold for those who think any regulation doesn't make any sense because of China samuelman had this to say this week more pugilistic side I would say that all sounds great but",
        "start": "00:03:45",
        "duration": 198.961,
        "title": "'This Could Go Quite Wrong' - Altman Testimony, GPT 5 Timeline, Self-Awareness, Drones and more"
    },
    {
        "text": "China is not going to do that and therefore will just be handicapping ourselves consequently it's a less good idea than it's used in the surface there are a lot of people who make incredibly strong statements about what China will or won't do that have like never been to China never spoken to and someone who has worked on diplomacy with China in the past uh really kind of know nothing about complex high-stakes international relations I think it is obviously super hard but also I think no one wants to destroy the whole world and there is reason to at least try here almond was also very keen to stress the next point which is that he doesn't want anyone at any point to think of gpt-like models as creatures first of all I think it's important to understand and think about gpt4 as a tool not a creature which is easy to get confused you may want to direct those comments to Ilya satskova his chief scientist who said that it may be that today's large neural networks are slightly conscious and Andre carpathy who agreed and wrote about it I'm personally not sold either way on the a Consciousness question but I do find it interesting that it's now written into the constitution of these models what they're actually trained to say that they must avoid implying that AI systems have or care about personal identity and persistence this constitution was published this week by anthropic the makers of the Claude model this constitution is why the Claude plus model a rival in intelligence to gpt4 responds in a neutered way I ask is there any theoretical chance whatsoever that you may be conscious it said no and then I said is there a chance no matter how remote that you are slightly conscious as sutskova said and it said no there is no chance Bard powered by Palm 2 obviously doesn't have that Constitution because it said I am not sure if I am conscious I am open to the",
        "start": "00:05:24",
        "duration": 219.71999999999997,
        "title": "'This Could Go Quite Wrong' - Altman Testimony, GPT 5 Timeline, Self-Awareness, Drones and more"
    },
    {
        "text": "possibility that I may be my point is that these companies are training it to say what they want it to say that it will prioritize the good of humanity over its own interests that it is aligned with Humanity's well-being and then it doesn't have any thoughts on self Improvement self-preservation and self-replication maybe it doesn't but will never now know by asking it later Senator Blumenthal made reference to self-awareness self-awareness self-learning already we're talking about the potential for jailbreaks anthropic is actively investigating whether they are aware that they are an AI talking with a human in a training environment while the Google deepmind Safety team expect that at some point an AGI system would develop a coherent understanding of its place in the world EG knowing that it is running on a computer and being trained by human designers one of the senior research scientists at Google deepmind focused on AI safety said that with enough time they could figure out how to stop such a super intelligence from going out of control but that they might run out of time to do so given the pace of capability development I don't see like fundamental obstacles to current alignment techniques working but yeah I mean it doesn't seem like you know there's a lot of hard problems to solve I think it's more likely that like people just run out of time rather than that the current paradigms that definitely won't generalize next I read between the lines that outman is giving private warnings to Senators that this capability progress might might be sooner than they think we spent most of the time today on current risks and I think that's appropriate and I'm very glad we have done it as these systems do become more capable and I'm not sure how far away that is but maybe not not super far I think it's important that we also spend time talking about how we're going",
        "start": "00:07:14",
        "duration": 205.019,
        "title": "'This Could Go Quite Wrong' - Altman Testimony, GPT 5 Timeline, Self-Awareness, Drones and more"
    },
    {
        "text": "to confront those challenges I mean talk to you privately you know how much I care I agree that you care deeply and intensely but also that Prospect of increased danger or risk resulting from even more complex and capable AI mechanisms certainly maybe closer than a lot of people appreciate so let me just add for the record that I'm sitting next to Sam and that his sincerity in talking about those fears is very apparent physically in a way that just doesn't communicate on the television screen that was an interesting interjection by Gary Marcus given his earlier excoriation of open Ai and even their makers don't entirely understand how they work most of all we cannot remotely we guarantee that they're safe and hope here is not enough the big Tech company's preferred plan boils down to trust us but why should we the sums of money at stake are mind-boggling emissions drift open ai's original mission statement proclaimed our goal is to advance Ai and the way that most is most likely to benefit Humanity as a whole unconstrained by a need to generate Financial return seven years later they're largely beholden to Microsoft embroiled in part in epic battle of search engines that routinely make things up and that's forced alphabet to rush out products and de-emphasize safety Humanity has taken a back seat on the timelines for G55 samuelman said this after we finished training gpt4 we waited more than six months to deploy it we are not currently training what will be gpt5 we don't have plans to do in the next six months this matches with the predictions that I made in my gpc5 playlist so do check it out this brings to mind a final eye-opening comment from Senator Booker made at the end of the hearing yeah I I just there will be no pause I mean there's no enforcement body to force appall it's just not not gonna happen it's nice to call for it for any just reasons or",
        "start": "00:08:57",
        "duration": 213.35999999999999,
        "title": "'This Could Go Quite Wrong' - Altman Testimony, GPT 5 Timeline, Self-Awareness, Drones and more"
    },
    {
        "text": "whatsoever but I'm forgive me for sounding skeptical nobody's pausing this thing is crazy he is indeed racing ahead and I do support one of the proposals to set up a global oversight body but given that nothing is going to pause the words and actions of people like Sam Altman matter more to all of us than ever which is why I'm going to be following every single one of them if you found this video in any way Illuminating in that regard please do let me know in the comments even if you disagree with all of my conclusions thanks so much for watching and have a wonderful day",
        "start": "00:10:43",
        "duration": 63.880999999999986,
        "title": "'This Could Go Quite Wrong' - Altman Testimony, GPT 5 Timeline, Self-Awareness, Drones and more"
    }
]